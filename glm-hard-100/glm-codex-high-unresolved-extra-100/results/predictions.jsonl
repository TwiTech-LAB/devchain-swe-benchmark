{"instance_id": "sphinx-doc__sphinx-10614", "model_name_or_path": "devchain", "model_patch": "diff --git a/sphinx/ext/inheritance_diagram.py b/sphinx/ext/inheritance_diagram.py\nindex 6e3985512..be3af091c 100644\n--- a/sphinx/ext/inheritance_diagram.py\n+++ b/sphinx/ext/inheritance_diagram.py\n@@ -33,6 +33,8 @@ from __future__ import annotations\n import builtins\n import hashlib\n import inspect\n+import os\n+import posixpath\n import re\n from collections.abc import Iterable\n from importlib import import_module\n@@ -413,7 +415,16 @@ def html_visit_inheritance_diagram(self: HTML5Translator, node: inheritance_diag\n     for child in pending_xrefs:\n         if child.get('refuri') is not None:\n             if graphviz_output_format == 'SVG':\n-                urls[child['reftitle']] = \"../\" + child.get('refuri')\n+                # For SVG, links need to be relative to the _images/ directory\n+                # (where the SVG file is located), not relative to the current\n+                # document. refuri is relative to the current document, so we\n+                # need to prepend the document's directory path.\n+                doc_dir = os.path.dirname(self.builder.current_docname)\n+                if doc_dir:\n+                    url = posixpath.join('..', doc_dir, child.get('refuri'))\n+                else:\n+                    url = posixpath.join('..', child.get('refuri'))\n+                urls[child['reftitle']] = url\n             else:\n                 urls[child['reftitle']] = child.get('refuri')\n         elif child.get('refid') is not None:\ndiff --git a/test_svg_nested/_build/.buildinfo b/test_svg_nested/_build/.buildinfo\nnew file mode 100644\nindex 000000000..540ad8eb1\n--- /dev/null\n+++ b/test_svg_nested/_build/.buildinfo\n@@ -0,0 +1,4 @@\n+# Sphinx build info version 1\n+# This file hashes the configuration used when building these files. When it is not found, a full rebuild will be done.\n+config: 2196bd718197c0a48d25e02b2cd5fef6\n+tags: 645f666f9bcd5a90fca523b33c5a78b7\ndiff --git a/test_svg_nested/_build/.doctrees/environment.pickle b/test_svg_nested/_build/.doctrees/environment.pickle\nnew file mode 100644\nindex 000000000..445fb2710\nBinary files /dev/null and b/test_svg_nested/_build/.doctrees/environment.pickle differ\ndiff --git a/test_svg_nested/_build/.doctrees/index.doctree b/test_svg_nested/_build/.doctrees/index.doctree\nnew file mode 100644\nindex 000000000..0b53856c3\nBinary files /dev/null and b/test_svg_nested/_build/.doctrees/index.doctree differ\ndiff --git a/test_svg_nested/_build/.doctrees/subdir/index.doctree b/test_svg_nested/_build/.doctrees/subdir/index.doctree\nnew file mode 100644\nindex 000000000..ca9e5778b\nBinary files /dev/null and b/test_svg_nested/_build/.doctrees/subdir/index.doctree differ\ndiff --git a/test_svg_nested/_build/_sources/index.rst.txt b/test_svg_nested/_build/_sources/index.rst.txt\nnew file mode 100644\nindex 000000000..78b073e36\n--- /dev/null\n+++ b/test_svg_nested/_build/_sources/index.rst.txt\n@@ -0,0 +1,7 @@\n+============================\n+Test Root Index\n+============================\n+\n+This is the root index.\n+\n+.. inheritance-diagram:: dict str list\ndiff --git a/test_svg_nested/_build/_sources/subdir/index.rst.txt b/test_svg_nested/_build/_sources/subdir/index.rst.txt\nnew file mode 100644\nindex 000000000..c0a877365\n--- /dev/null\n+++ b/test_svg_nested/_build/_sources/subdir/index.rst.txt\n@@ -0,0 +1,7 @@\n+============================\n+Subdir Index\n+============================\n+\n+This is in a subdirectory.\n+\n+.. inheritance-diagram:: dict str list\ndiff --git a/test_svg_nested/_build/_static/alabaster.css b/test_svg_nested/_build/_static/alabaster.css\nnew file mode 100644\nindex 000000000..e3174bf93\n--- /dev/null\n+++ b/test_svg_nested/_build/_static/alabaster.css\n@@ -0,0 +1,708 @@\n+@import url(\"basic.css\");\n+\n+/* -- page layout ----------------------------------------------------------- */\n+\n+body {\n+    font-family: Georgia, serif;\n+    font-size: 17px;\n+    background-color: #fff;\n+    color: #000;\n+    margin: 0;\n+    padding: 0;\n+}\n+\n+\n+div.document {\n+    width: 940px;\n+    margin: 30px auto 0 auto;\n+}\n+\n+div.documentwrapper {\n+    float: left;\n+    width: 100%;\n+}\n+\n+div.bodywrapper {\n+    margin: 0 0 0 220px;\n+}\n+\n+div.sphinxsidebar {\n+    width: 220px;\n+    font-size: 14px;\n+    line-height: 1.5;\n+}\n+\n+hr {\n+    border: 1px solid #B1B4B6;\n+}\n+\n+div.body {\n+    background-color: #fff;\n+    color: #3E4349;\n+    padding: 0 30px 0 30px;\n+}\n+\n+div.body > .section {\n+    text-align: left;\n+}\n+\n+div.footer {\n+    width: 940px;\n+    margin: 20px auto 30px auto;\n+    font-size: 14px;\n+    color: #888;\n+    text-align: right;\n+}\n+\n+div.footer a {\n+    color: #888;\n+}\n+\n+p.caption {\n+    font-family: inherit;\n+    font-size: inherit;\n+}\n+\n+\n+div.relations {\n+    display: none;\n+}\n+\n+\n+div.sphinxsidebar {\n+    max-height: 100%;\n+    overflow-y: auto;\n+}\n+\n+div.sphinxsidebar a {\n+    color: #444;\n+    text-decoration: none;\n+    border-bottom: 1px dotted #999;\n+}\n+\n+div.sphinxsidebar a:hover {\n+    border-bottom: 1px solid #999;\n+}\n+\n+div.sphinxsidebarwrapper {\n+    padding: 18px 10px;\n+}\n+\n+div.sphinxsidebarwrapper p.logo {\n+    padding: 0;\n+    margin: -10px 0 0 0px;\n+    text-align: center;\n+}\n+\n+div.sphinxsidebarwrapper h1.logo {\n+    margin-top: -10px;\n+    text-align: center;\n+    margin-bottom: 5px;\n+    text-align: left;\n+}\n+\n+div.sphinxsidebarwrapper h1.logo-name {\n+    margin-top: 0px;\n+}\n+\n+div.sphinxsidebarwrapper p.blurb {\n+    margin-top: 0;\n+    font-style: normal;\n+}\n+\n+div.sphinxsidebar h3,\n+div.sphinxsidebar h4 {\n+    font-family: Georgia, serif;\n+    color: #444;\n+    font-size: 24px;\n+    font-weight: normal;\n+    margin: 0 0 5px 0;\n+    padding: 0;\n+}\n+\n+div.sphinxsidebar h4 {\n+    font-size: 20px;\n+}\n+\n+div.sphinxsidebar h3 a {\n+    color: #444;\n+}\n+\n+div.sphinxsidebar p.logo a,\n+div.sphinxsidebar h3 a,\n+div.sphinxsidebar p.logo a:hover,\n+div.sphinxsidebar h3 a:hover {\n+    border: none;\n+}\n+\n+div.sphinxsidebar p {\n+    color: #555;\n+    margin: 10px 0;\n+}\n+\n+div.sphinxsidebar ul {\n+    margin: 10px 0;\n+    padding: 0;\n+    color: #000;\n+}\n+\n+div.sphinxsidebar ul li.toctree-l1 > a {\n+    font-size: 120%;\n+}\n+\n+div.sphinxsidebar ul li.toctree-l2 > a {\n+    font-size: 110%;\n+}\n+\n+div.sphinxsidebar input {\n+    border: 1px solid #CCC;\n+    font-family: Georgia, serif;\n+    font-size: 1em;\n+}\n+\n+div.sphinxsidebar #searchbox input[type=\"text\"] {\n+    width: 160px;\n+}\n+\n+div.sphinxsidebar .search > div {\n+    display: table-cell;\n+}\n+\n+div.sphinxsidebar hr {\n+    border: none;\n+    height: 1px;\n+    color: #AAA;\n+    background: #AAA;\n+\n+    text-align: left;\n+    margin-left: 0;\n+    width: 50%;\n+}\n+\n+div.sphinxsidebar .badge {\n+    border-bottom: none;\n+}\n+\n+div.sphinxsidebar .badge:hover {\n+    border-bottom: none;\n+}\n+\n+/* To address an issue with donation coming after search */\n+div.sphinxsidebar h3.donation {\n+    margin-top: 10px;\n+}\n+\n+/* -- body styles ----------------------------------------------------------- */\n+\n+a {\n+    color: #004B6B;\n+    text-decoration: underline;\n+}\n+\n+a:hover {\n+    color: #6D4100;\n+    text-decoration: underline;\n+}\n+\n+div.body h1,\n+div.body h2,\n+div.body h3,\n+div.body h4,\n+div.body h5,\n+div.body h6 {\n+    font-family: Georgia, serif;\n+    font-weight: normal;\n+    margin: 30px 0px 10px 0px;\n+    padding: 0;\n+}\n+\n+div.body h1 { margin-top: 0; padding-top: 0; font-size: 240%; }\n+div.body h2 { font-size: 180%; }\n+div.body h3 { font-size: 150%; }\n+div.body h4 { font-size: 130%; }\n+div.body h5 { font-size: 100%; }\n+div.body h6 { font-size: 100%; }\n+\n+a.headerlink {\n+    color: #DDD;\n+    padding: 0 4px;\n+    text-decoration: none;\n+}\n+\n+a.headerlink:hover {\n+    color: #444;\n+    background: #EAEAEA;\n+}\n+\n+div.body p, div.body dd, div.body li {\n+    line-height: 1.4em;\n+}\n+\n+div.admonition {\n+    margin: 20px 0px;\n+    padding: 10px 30px;\n+    background-color: #EEE;\n+    border: 1px solid #CCC;\n+}\n+\n+div.admonition tt.xref, div.admonition code.xref, div.admonition a tt {\n+    background-color: #FBFBFB;\n+    border-bottom: 1px solid #fafafa;\n+}\n+\n+div.admonition p.admonition-title {\n+    font-family: Georgia, serif;\n+    font-weight: normal;\n+    font-size: 24px;\n+    margin: 0 0 10px 0;\n+    padding: 0;\n+    line-height: 1;\n+}\n+\n+div.admonition p.last {\n+    margin-bottom: 0;\n+}\n+\n+div.highlight {\n+    background-color: #fff;\n+}\n+\n+dt:target, .highlight {\n+    background: #FAF3E8;\n+}\n+\n+div.warning {\n+    background-color: #FCC;\n+    border: 1px solid #FAA;\n+}\n+\n+div.danger {\n+    background-color: #FCC;\n+    border: 1px solid #FAA;\n+    -moz-box-shadow: 2px 2px 4px #D52C2C;\n+    -webkit-box-shadow: 2px 2px 4px #D52C2C;\n+    box-shadow: 2px 2px 4px #D52C2C;\n+}\n+\n+div.error {\n+    background-color: #FCC;\n+    border: 1px solid #FAA;\n+    -moz-box-shadow: 2px 2px 4px #D52C2C;\n+    -webkit-box-shadow: 2px 2px 4px #D52C2C;\n+    box-shadow: 2px 2px 4px #D52C2C;\n+}\n+\n+div.caution {\n+    background-color: #FCC;\n+    border: 1px solid #FAA;\n+}\n+\n+div.attention {\n+    background-color: #FCC;\n+    border: 1px solid #FAA;\n+}\n+\n+div.important {\n+    background-color: #EEE;\n+    border: 1px solid #CCC;\n+}\n+\n+div.note {\n+    background-color: #EEE;\n+    border: 1px solid #CCC;\n+}\n+\n+div.tip {\n+    background-color: #EEE;\n+    border: 1px solid #CCC;\n+}\n+\n+div.hint {\n+    background-color: #EEE;\n+    border: 1px solid #CCC;\n+}\n+\n+div.seealso {\n+    background-color: #EEE;\n+    border: 1px solid #CCC;\n+}\n+\n+div.topic {\n+    background-color: #EEE;\n+}\n+\n+p.admonition-title {\n+    display: inline;\n+}\n+\n+p.admonition-title:after {\n+    content: \":\";\n+}\n+\n+pre, tt, code {\n+    font-family: 'Consolas', 'Menlo', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', monospace;\n+    font-size: 0.9em;\n+}\n+\n+.hll {\n+    background-color: #FFC;\n+    margin: 0 -12px;\n+    padding: 0 12px;\n+    display: block;\n+}\n+\n+img.screenshot {\n+}\n+\n+tt.descname, tt.descclassname, code.descname, code.descclassname {\n+    font-size: 0.95em;\n+}\n+\n+tt.descname, code.descname {\n+    padding-right: 0.08em;\n+}\n+\n+img.screenshot {\n+    -moz-box-shadow: 2px 2px 4px #EEE;\n+    -webkit-box-shadow: 2px 2px 4px #EEE;\n+    box-shadow: 2px 2px 4px #EEE;\n+}\n+\n+table.docutils {\n+    border: 1px solid #888;\n+    -moz-box-shadow: 2px 2px 4px #EEE;\n+    -webkit-box-shadow: 2px 2px 4px #EEE;\n+    box-shadow: 2px 2px 4px #EEE;\n+}\n+\n+table.docutils td, table.docutils th {\n+    border: 1px solid #888;\n+    padding: 0.25em 0.7em;\n+}\n+\n+table.field-list, table.footnote {\n+    border: none;\n+    -moz-box-shadow: none;\n+    -webkit-box-shadow: none;\n+    box-shadow: none;\n+}\n+\n+table.footnote {\n+    margin: 15px 0;\n+    width: 100%;\n+    border: 1px solid #EEE;\n+    background: #FDFDFD;\n+    font-size: 0.9em;\n+}\n+\n+table.footnote + table.footnote {\n+    margin-top: -15px;\n+    border-top: none;\n+}\n+\n+table.field-list th {\n+    padding: 0 0.8em 0 0;\n+}\n+\n+table.field-list td {\n+    padding: 0;\n+}\n+\n+table.field-list p {\n+    margin-bottom: 0.8em;\n+}\n+\n+/* Cloned from\n+ * https://github.com/sphinx-doc/sphinx/commit/ef60dbfce09286b20b7385333d63a60321784e68\n+ */\n+.field-name {\n+    -moz-hyphens: manual;\n+    -ms-hyphens: manual;\n+    -webkit-hyphens: manual;\n+    hyphens: manual;\n+}\n+\n+table.footnote td.label {\n+    width: .1px;\n+    padding: 0.3em 0 0.3em 0.5em;\n+}\n+\n+table.footnote td {\n+    padding: 0.3em 0.5em;\n+}\n+\n+dl {\n+    margin-left: 0;\n+    margin-right: 0;\n+    margin-top: 0;\n+    padding: 0;\n+}\n+\n+dl dd {\n+    margin-left: 30px;\n+}\n+\n+blockquote {\n+    margin: 0 0 0 30px;\n+    padding: 0;\n+}\n+\n+ul, ol {\n+    /* Matches the 30px from the narrow-screen \"li > ul\" selector below */\n+    margin: 10px 0 10px 30px;\n+    padding: 0;\n+}\n+\n+pre {\n+    background: #EEE;\n+    padding: 7px 30px;\n+    margin: 15px 0px;\n+    line-height: 1.3em;\n+}\n+\n+div.viewcode-block:target {\n+    background: #ffd;\n+}\n+\n+dl pre, blockquote pre, li pre {\n+    margin-left: 0;\n+    padding-left: 30px;\n+}\n+\n+tt, code {\n+    background-color: #ecf0f3;\n+    color: #222;\n+    /* padding: 1px 2px; */\n+}\n+\n+tt.xref, code.xref, a tt {\n+    background-color: #FBFBFB;\n+    border-bottom: 1px solid #fff;\n+}\n+\n+a.reference {\n+    text-decoration: none;\n+    border-bottom: 1px dotted #004B6B;\n+}\n+\n+/* Don't put an underline on images */\n+a.image-reference, a.image-reference:hover {\n+    border-bottom: none;\n+}\n+\n+a.reference:hover {\n+    border-bottom: 1px solid #6D4100;\n+}\n+\n+a.footnote-reference {\n+    text-decoration: none;\n+    font-size: 0.7em;\n+    vertical-align: top;\n+    border-bottom: 1px dotted #004B6B;\n+}\n+\n+a.footnote-reference:hover {\n+    border-bottom: 1px solid #6D4100;\n+}\n+\n+a:hover tt, a:hover code {\n+    background: #EEE;\n+}\n+\n+\n+@media screen and (max-width: 870px) {\n+\n+    div.sphinxsidebar {\n+    \tdisplay: none;\n+    }\n+\n+    div.document {\n+       width: 100%;\n+\n+    }\n+\n+    div.documentwrapper {\n+    \tmargin-left: 0;\n+    \tmargin-top: 0;\n+    \tmargin-right: 0;\n+    \tmargin-bottom: 0;\n+    }\n+\n+    div.bodywrapper {\n+    \tmargin-top: 0;\n+    \tmargin-right: 0;\n+    \tmargin-bottom: 0;\n+    \tmargin-left: 0;\n+    }\n+\n+    ul {\n+    \tmargin-left: 0;\n+    }\n+\n+\tli > ul {\n+        /* Matches the 30px from the \"ul, ol\" selector above */\n+\t\tmargin-left: 30px;\n+\t}\n+\n+    .document {\n+    \twidth: auto;\n+    }\n+\n+    .footer {\n+    \twidth: auto;\n+    }\n+\n+    .bodywrapper {\n+    \tmargin: 0;\n+    }\n+\n+    .footer {\n+    \twidth: auto;\n+    }\n+\n+    .github {\n+        display: none;\n+    }\n+\n+\n+\n+}\n+\n+\n+\n+@media screen and (max-width: 875px) {\n+\n+    body {\n+        margin: 0;\n+        padding: 20px 30px;\n+    }\n+\n+    div.documentwrapper {\n+        float: none;\n+        background: #fff;\n+    }\n+\n+    div.sphinxsidebar {\n+        display: block;\n+        float: none;\n+        width: 102.5%;\n+        margin: 50px -30px -20px -30px;\n+        padding: 10px 20px;\n+        background: #333;\n+        color: #FFF;\n+    }\n+\n+    div.sphinxsidebar h3, div.sphinxsidebar h4, div.sphinxsidebar p,\n+    div.sphinxsidebar h3 a {\n+        color: #fff;\n+    }\n+\n+    div.sphinxsidebar a {\n+        color: #AAA;\n+    }\n+\n+    div.sphinxsidebar p.logo {\n+        display: none;\n+    }\n+\n+    div.document {\n+        width: 100%;\n+        margin: 0;\n+    }\n+\n+    div.footer {\n+        display: none;\n+    }\n+\n+    div.bodywrapper {\n+        margin: 0;\n+    }\n+\n+    div.body {\n+        min-height: 0;\n+        padding: 0;\n+    }\n+\n+    .rtd_doc_footer {\n+        display: none;\n+    }\n+\n+    .document {\n+        width: auto;\n+    }\n+\n+    .footer {\n+        width: auto;\n+    }\n+\n+    .footer {\n+        width: auto;\n+    }\n+\n+    .github {\n+        display: none;\n+    }\n+}\n+\n+\n+/* misc. */\n+\n+.revsys-inline {\n+    display: none!important;\n+}\n+\n+/* Hide ugly table cell borders in ..bibliography:: directive output */\n+table.docutils.citation, table.docutils.citation td, table.docutils.citation th {\n+  border: none;\n+  /* Below needed in some edge cases; if not applied, bottom shadows appear */\n+  -moz-box-shadow: none;\n+  -webkit-box-shadow: none;\n+  box-shadow: none;\n+}\n+\n+\n+/* relbar */\n+\n+.related {\n+    line-height: 30px;\n+    width: 100%;\n+    font-size: 0.9rem;\n+}\n+\n+.related.top {\n+    border-bottom: 1px solid #EEE;\n+    margin-bottom: 20px;\n+}\n+\n+.related.bottom {\n+    border-top: 1px solid #EEE;\n+}\n+\n+.related ul {\n+    padding: 0;\n+    margin: 0;\n+    list-style: none;\n+}\n+\n+.related li {\n+    display: inline;\n+}\n+\n+nav#rellinks {\n+    float: right;\n+}\n+\n+nav#rellinks li+li:before {\n+    content: \"|\";\n+}\n+\n+nav#breadcrumbs li+li:before {\n+    content: \"\\00BB\";\n+}\n+\n+/* Hide certain items when printing */\n+@media print {\n+    div.related {\n+        display: none;\n+    }\n+}\n\\ No newline at end of file\ndiff --git a/test_svg_nested/_build/_static/basic.css b/test_svg_nested/_build/_static/basic.css\nnew file mode 100644\nindex 000000000..4157edf27\n--- /dev/null\n+++ b/test_svg_nested/_build/_static/basic.css\n@@ -0,0 +1,925 @@\n+/*\n+ * basic.css\n+ * ~~~~~~~~~\n+ *\n+ * Sphinx stylesheet -- basic theme.\n+ *\n+ * :copyright: Copyright 2007-2023 by the Sphinx team, see AUTHORS.\n+ * :license: BSD, see LICENSE for details.\n+ *\n+ */\n+\n+/* -- main layout ----------------------------------------------------------- */\n+\n+div.clearer {\n+    clear: both;\n+}\n+\n+div.section::after {\n+    display: block;\n+    content: '';\n+    clear: left;\n+}\n+\n+/* -- relbar ---------------------------------------------------------------- */\n+\n+div.related {\n+    width: 100%;\n+    font-size: 90%;\n+}\n+\n+div.related h3 {\n+    display: none;\n+}\n+\n+div.related ul {\n+    margin: 0;\n+    padding: 0 0 0 10px;\n+    list-style: none;\n+}\n+\n+div.related li {\n+    display: inline;\n+}\n+\n+div.related li.right {\n+    float: right;\n+    margin-right: 5px;\n+}\n+\n+/* -- sidebar --------------------------------------------------------------- */\n+\n+div.sphinxsidebarwrapper {\n+    padding: 10px 5px 0 10px;\n+}\n+\n+div.sphinxsidebar {\n+    float: left;\n+    width: 230px;\n+    margin-left: -100%;\n+    font-size: 90%;\n+    word-wrap: break-word;\n+    overflow-wrap : break-word;\n+}\n+\n+div.sphinxsidebar ul {\n+    list-style: none;\n+}\n+\n+div.sphinxsidebar ul ul,\n+div.sphinxsidebar ul.want-points {\n+    margin-left: 20px;\n+    list-style: square;\n+}\n+\n+div.sphinxsidebar ul ul {\n+    margin-top: 0;\n+    margin-bottom: 0;\n+}\n+\n+div.sphinxsidebar form {\n+    margin-top: 10px;\n+}\n+\n+div.sphinxsidebar input {\n+    border: 1px solid #98dbcc;\n+    font-family: sans-serif;\n+    font-size: 1em;\n+}\n+\n+div.sphinxsidebar #searchbox form.search {\n+    overflow: hidden;\n+}\n+\n+div.sphinxsidebar #searchbox input[type=\"text\"] {\n+    float: left;\n+    width: 80%;\n+    padding: 0.25em;\n+    box-sizing: border-box;\n+}\n+\n+div.sphinxsidebar #searchbox input[type=\"submit\"] {\n+    float: left;\n+    width: 20%;\n+    border-left: none;\n+    padding: 0.25em;\n+    box-sizing: border-box;\n+}\n+\n+\n+img {\n+    border: 0;\n+    max-width: 100%;\n+}\n+\n+/* -- search page ----------------------------------------------------------- */\n+\n+ul.search {\n+    margin: 10px 0 0 20px;\n+    padding: 0;\n+}\n+\n+ul.search li {\n+    padding: 5px 0 5px 20px;\n+    background-image: url(file.png);\n+    background-repeat: no-repeat;\n+    background-position: 0 7px;\n+}\n+\n+ul.search li a {\n+    font-weight: bold;\n+}\n+\n+ul.search li p.context {\n+    color: #888;\n+    margin: 2px 0 0 30px;\n+    text-align: left;\n+}\n+\n+ul.keywordmatches li.goodmatch a {\n+    font-weight: bold;\n+}\n+\n+/* -- index page ------------------------------------------------------------ */\n+\n+table.contentstable {\n+    width: 90%;\n+    margin-left: auto;\n+    margin-right: auto;\n+}\n+\n+table.contentstable p.biglink {\n+    line-height: 150%;\n+}\n+\n+a.biglink {\n+    font-size: 1.3em;\n+}\n+\n+span.linkdescr {\n+    font-style: italic;\n+    padding-top: 5px;\n+    font-size: 90%;\n+}\n+\n+/* -- general index --------------------------------------------------------- */\n+\n+table.indextable {\n+    width: 100%;\n+}\n+\n+table.indextable td {\n+    text-align: left;\n+    vertical-align: top;\n+}\n+\n+table.indextable ul {\n+    margin-top: 0;\n+    margin-bottom: 0;\n+    list-style-type: none;\n+}\n+\n+table.indextable > tbody > tr > td > ul {\n+    padding-left: 0em;\n+}\n+\n+table.indextable tr.pcap {\n+    height: 10px;\n+}\n+\n+table.indextable tr.cap {\n+    margin-top: 10px;\n+    background-color: #f2f2f2;\n+}\n+\n+img.toggler {\n+    margin-right: 3px;\n+    margin-top: 3px;\n+    cursor: pointer;\n+}\n+\n+div.modindex-jumpbox {\n+    border-top: 1px solid #ddd;\n+    border-bottom: 1px solid #ddd;\n+    margin: 1em 0 1em 0;\n+    padding: 0.4em;\n+}\n+\n+div.genindex-jumpbox {\n+    border-top: 1px solid #ddd;\n+    border-bottom: 1px solid #ddd;\n+    margin: 1em 0 1em 0;\n+    padding: 0.4em;\n+}\n+\n+/* -- domain module index --------------------------------------------------- */\n+\n+table.modindextable td {\n+    padding: 2px;\n+    border-collapse: collapse;\n+}\n+\n+/* -- general body styles --------------------------------------------------- */\n+\n+div.body {\n+    min-width: inherit;\n+    max-width: 800px;\n+}\n+\n+div.body p, div.body dd, div.body li, div.body blockquote {\n+    -moz-hyphens: auto;\n+    -ms-hyphens: auto;\n+    -webkit-hyphens: auto;\n+    hyphens: auto;\n+}\n+\n+a.headerlink {\n+    visibility: hidden;\n+}\n+\n+a:visited {\n+    color: #551A8B;\n+}\n+\n+h1:hover > a.headerlink,\n+h2:hover > a.headerlink,\n+h3:hover > a.headerlink,\n+h4:hover > a.headerlink,\n+h5:hover > a.headerlink,\n+h6:hover > a.headerlink,\n+dt:hover > a.headerlink,\n+caption:hover > a.headerlink,\n+p.caption:hover > a.headerlink,\n+div.code-block-caption:hover > a.headerlink {\n+    visibility: visible;\n+}\n+\n+div.body p.caption {\n+    text-align: inherit;\n+}\n+\n+div.body td {\n+    text-align: left;\n+}\n+\n+.first {\n+    margin-top: 0 !important;\n+}\n+\n+p.rubric {\n+    margin-top: 30px;\n+    font-weight: bold;\n+}\n+\n+img.align-left, figure.align-left, .figure.align-left, object.align-left {\n+    clear: left;\n+    float: left;\n+    margin-right: 1em;\n+}\n+\n+img.align-right, figure.align-right, .figure.align-right, object.align-right {\n+    clear: right;\n+    float: right;\n+    margin-left: 1em;\n+}\n+\n+img.align-center, figure.align-center, .figure.align-center, object.align-center {\n+  display: block;\n+  margin-left: auto;\n+  margin-right: auto;\n+}\n+\n+img.align-default, figure.align-default, .figure.align-default {\n+  display: block;\n+  margin-left: auto;\n+  margin-right: auto;\n+}\n+\n+.align-left {\n+    text-align: left;\n+}\n+\n+.align-center {\n+    text-align: center;\n+}\n+\n+.align-default {\n+    text-align: center;\n+}\n+\n+.align-right {\n+    text-align: right;\n+}\n+\n+/* -- sidebars -------------------------------------------------------------- */\n+\n+div.sidebar,\n+aside.sidebar {\n+    margin: 0 0 0.5em 1em;\n+    border: 1px solid #ddb;\n+    padding: 7px;\n+    background-color: #ffe;\n+    width: 40%;\n+    float: right;\n+    clear: right;\n+    overflow-x: auto;\n+}\n+\n+p.sidebar-title {\n+    font-weight: bold;\n+}\n+\n+nav.contents,\n+aside.topic,\n+div.admonition, div.topic, blockquote {\n+    clear: left;\n+}\n+\n+/* -- topics ---------------------------------------------------------------- */\n+\n+nav.contents,\n+aside.topic,\n+div.topic {\n+    border: 1px solid #ccc;\n+    padding: 7px;\n+    margin: 10px 0 10px 0;\n+}\n+\n+p.topic-title {\n+    font-size: 1.1em;\n+    font-weight: bold;\n+    margin-top: 10px;\n+}\n+\n+/* -- admonitions ----------------------------------------------------------- */\n+\n+div.admonition {\n+    margin-top: 10px;\n+    margin-bottom: 10px;\n+    padding: 7px;\n+}\n+\n+div.admonition dt {\n+    font-weight: bold;\n+}\n+\n+p.admonition-title {\n+    margin: 0px 10px 5px 0px;\n+    font-weight: bold;\n+}\n+\n+div.body p.centered {\n+    text-align: center;\n+    margin-top: 25px;\n+}\n+\n+/* -- content of sidebars/topics/admonitions -------------------------------- */\n+\n+div.sidebar > :last-child,\n+aside.sidebar > :last-child,\n+nav.contents > :last-child,\n+aside.topic > :last-child,\n+div.topic > :last-child,\n+div.admonition > :last-child {\n+    margin-bottom: 0;\n+}\n+\n+div.sidebar::after,\n+aside.sidebar::after,\n+nav.contents::after,\n+aside.topic::after,\n+div.topic::after,\n+div.admonition::after,\n+blockquote::after {\n+    display: block;\n+    content: '';\n+    clear: both;\n+}\n+\n+/* -- tables ---------------------------------------------------------------- */\n+\n+table.docutils {\n+    margin-top: 10px;\n+    margin-bottom: 10px;\n+    border: 0;\n+    border-collapse: collapse;\n+}\n+\n+table.align-center {\n+    margin-left: auto;\n+    margin-right: auto;\n+}\n+\n+table.align-default {\n+    margin-left: auto;\n+    margin-right: auto;\n+}\n+\n+table caption span.caption-number {\n+    font-style: italic;\n+}\n+\n+table caption span.caption-text {\n+}\n+\n+table.docutils td, table.docutils th {\n+    padding: 1px 8px 1px 5px;\n+    border-top: 0;\n+    border-left: 0;\n+    border-right: 0;\n+    border-bottom: 1px solid #aaa;\n+}\n+\n+th {\n+    text-align: left;\n+    padding-right: 5px;\n+}\n+\n+table.citation {\n+    border-left: solid 1px gray;\n+    margin-left: 1px;\n+}\n+\n+table.citation td {\n+    border-bottom: none;\n+}\n+\n+th > :first-child,\n+td > :first-child {\n+    margin-top: 0px;\n+}\n+\n+th > :last-child,\n+td > :last-child {\n+    margin-bottom: 0px;\n+}\n+\n+/* -- figures --------------------------------------------------------------- */\n+\n+div.figure, figure {\n+    margin: 0.5em;\n+    padding: 0.5em;\n+}\n+\n+div.figure p.caption, figcaption {\n+    padding: 0.3em;\n+}\n+\n+div.figure p.caption span.caption-number,\n+figcaption span.caption-number {\n+    font-style: italic;\n+}\n+\n+div.figure p.caption span.caption-text,\n+figcaption span.caption-text {\n+}\n+\n+/* -- field list styles ----------------------------------------------------- */\n+\n+table.field-list td, table.field-list th {\n+    border: 0 !important;\n+}\n+\n+.field-list ul {\n+    margin: 0;\n+    padding-left: 1em;\n+}\n+\n+.field-list p {\n+    margin: 0;\n+}\n+\n+.field-name {\n+    -moz-hyphens: manual;\n+    -ms-hyphens: manual;\n+    -webkit-hyphens: manual;\n+    hyphens: manual;\n+}\n+\n+/* -- hlist styles ---------------------------------------------------------- */\n+\n+table.hlist {\n+    margin: 1em 0;\n+}\n+\n+table.hlist td {\n+    vertical-align: top;\n+}\n+\n+/* -- object description styles --------------------------------------------- */\n+\n+.sig {\n+\tfont-family: 'Consolas', 'Menlo', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', monospace;\n+}\n+\n+.sig-name, code.descname {\n+    background-color: transparent;\n+    font-weight: bold;\n+}\n+\n+.sig-name {\n+\tfont-size: 1.1em;\n+}\n+\n+code.descname {\n+    font-size: 1.2em;\n+}\n+\n+.sig-prename, code.descclassname {\n+    background-color: transparent;\n+}\n+\n+.optional {\n+    font-size: 1.3em;\n+}\n+\n+.sig-paren {\n+    font-size: larger;\n+}\n+\n+.sig-param.n {\n+\tfont-style: italic;\n+}\n+\n+/* C++ specific styling */\n+\n+.sig-inline.c-texpr,\n+.sig-inline.cpp-texpr {\n+\tfont-family: unset;\n+}\n+\n+.sig.c   .k, .sig.c   .kt,\n+.sig.cpp .k, .sig.cpp .kt {\n+\tcolor: #0033B3;\n+}\n+\n+.sig.c   .m,\n+.sig.cpp .m {\n+\tcolor: #1750EB;\n+}\n+\n+.sig.c   .s, .sig.c   .sc,\n+.sig.cpp .s, .sig.cpp .sc {\n+\tcolor: #067D17;\n+}\n+\n+\n+/* -- other body styles ----------------------------------------------------- */\n+\n+ol.arabic {\n+    list-style: decimal;\n+}\n+\n+ol.loweralpha {\n+    list-style: lower-alpha;\n+}\n+\n+ol.upperalpha {\n+    list-style: upper-alpha;\n+}\n+\n+ol.lowerroman {\n+    list-style: lower-roman;\n+}\n+\n+ol.upperroman {\n+    list-style: upper-roman;\n+}\n+\n+:not(li) > ol > li:first-child > :first-child,\n+:not(li) > ul > li:first-child > :first-child {\n+    margin-top: 0px;\n+}\n+\n+:not(li) > ol > li:last-child > :last-child,\n+:not(li) > ul > li:last-child > :last-child {\n+    margin-bottom: 0px;\n+}\n+\n+ol.simple ol p,\n+ol.simple ul p,\n+ul.simple ol p,\n+ul.simple ul p {\n+    margin-top: 0;\n+}\n+\n+ol.simple > li:not(:first-child) > p,\n+ul.simple > li:not(:first-child) > p {\n+    margin-top: 0;\n+}\n+\n+ol.simple p,\n+ul.simple p {\n+    margin-bottom: 0;\n+}\n+\n+aside.footnote > span,\n+div.citation > span {\n+    float: left;\n+}\n+aside.footnote > span:last-of-type,\n+div.citation > span:last-of-type {\n+  padding-right: 0.5em;\n+}\n+aside.footnote > p {\n+  margin-left: 2em;\n+}\n+div.citation > p {\n+  margin-left: 4em;\n+}\n+aside.footnote > p:last-of-type,\n+div.citation > p:last-of-type {\n+    margin-bottom: 0em;\n+}\n+aside.footnote > p:last-of-type:after,\n+div.citation > p:last-of-type:after {\n+    content: \"\";\n+    clear: both;\n+}\n+\n+dl.field-list {\n+    display: grid;\n+    grid-template-columns: fit-content(30%) auto;\n+}\n+\n+dl.field-list > dt {\n+    font-weight: bold;\n+    word-break: break-word;\n+    padding-left: 0.5em;\n+    padding-right: 5px;\n+}\n+\n+dl.field-list > dd {\n+    padding-left: 0.5em;\n+    margin-top: 0em;\n+    margin-left: 0em;\n+    margin-bottom: 0em;\n+}\n+\n+dl {\n+    margin-bottom: 15px;\n+}\n+\n+dd > :first-child {\n+    margin-top: 0px;\n+}\n+\n+dd ul, dd table {\n+    margin-bottom: 10px;\n+}\n+\n+dd {\n+    margin-top: 3px;\n+    margin-bottom: 10px;\n+    margin-left: 30px;\n+}\n+\n+.sig dd {\n+    margin-top: 0px;\n+    margin-bottom: 0px;\n+}\n+\n+.sig dl {\n+    margin-top: 0px;\n+    margin-bottom: 0px;\n+}\n+\n+dl > dd:last-child,\n+dl > dd:last-child > :last-child {\n+    margin-bottom: 0;\n+}\n+\n+dt:target, span.highlighted {\n+    background-color: #fbe54e;\n+}\n+\n+rect.highlighted {\n+    fill: #fbe54e;\n+}\n+\n+dl.glossary dt {\n+    font-weight: bold;\n+    font-size: 1.1em;\n+}\n+\n+.versionmodified {\n+    font-style: italic;\n+}\n+\n+.system-message {\n+    background-color: #fda;\n+    padding: 5px;\n+    border: 3px solid red;\n+}\n+\n+.footnote:target  {\n+    background-color: #ffa;\n+}\n+\n+.line-block {\n+    display: block;\n+    margin-top: 1em;\n+    margin-bottom: 1em;\n+}\n+\n+.line-block .line-block {\n+    margin-top: 0;\n+    margin-bottom: 0;\n+    margin-left: 1.5em;\n+}\n+\n+.guilabel, .menuselection {\n+    font-family: sans-serif;\n+}\n+\n+.accelerator {\n+    text-decoration: underline;\n+}\n+\n+.classifier {\n+    font-style: oblique;\n+}\n+\n+.classifier:before {\n+    font-style: normal;\n+    margin: 0 0.5em;\n+    content: \":\";\n+    display: inline-block;\n+}\n+\n+abbr, acronym {\n+    border-bottom: dotted 1px;\n+    cursor: help;\n+}\n+\n+.translated {\n+    background-color: rgba(207, 255, 207, 0.2)\n+}\n+\n+.untranslated {\n+    background-color: rgba(255, 207, 207, 0.2)\n+}\n+\n+/* -- code displays --------------------------------------------------------- */\n+\n+pre {\n+    overflow: auto;\n+    overflow-y: hidden;  /* fixes display issues on Chrome browsers */\n+}\n+\n+pre, div[class*=\"highlight-\"] {\n+    clear: both;\n+}\n+\n+span.pre {\n+    -moz-hyphens: none;\n+    -ms-hyphens: none;\n+    -webkit-hyphens: none;\n+    hyphens: none;\n+    white-space: nowrap;\n+}\n+\n+div[class*=\"highlight-\"] {\n+    margin: 1em 0;\n+}\n+\n+td.linenos pre {\n+    border: 0;\n+    background-color: transparent;\n+    color: #aaa;\n+}\n+\n+table.highlighttable {\n+    display: block;\n+}\n+\n+table.highlighttable tbody {\n+    display: block;\n+}\n+\n+table.highlighttable tr {\n+    display: flex;\n+}\n+\n+table.highlighttable td {\n+    margin: 0;\n+    padding: 0;\n+}\n+\n+table.highlighttable td.linenos {\n+    padding-right: 0.5em;\n+}\n+\n+table.highlighttable td.code {\n+    flex: 1;\n+    overflow: hidden;\n+}\n+\n+.highlight .hll {\n+    display: block;\n+}\n+\n+div.highlight pre,\n+table.highlighttable pre {\n+    margin: 0;\n+}\n+\n+div.code-block-caption + div {\n+    margin-top: 0;\n+}\n+\n+div.code-block-caption {\n+    margin-top: 1em;\n+    padding: 2px 5px;\n+    font-size: small;\n+}\n+\n+div.code-block-caption code {\n+    background-color: transparent;\n+}\n+\n+table.highlighttable td.linenos,\n+span.linenos,\n+div.highlight span.gp {  /* gp: Generic.Prompt */\n+  user-select: none;\n+  -webkit-user-select: text; /* Safari fallback only */\n+  -webkit-user-select: none; /* Chrome/Safari */\n+  -moz-user-select: none; /* Firefox */\n+  -ms-user-select: none; /* IE10+ */\n+}\n+\n+div.code-block-caption span.caption-number {\n+    padding: 0.1em 0.3em;\n+    font-style: italic;\n+}\n+\n+div.code-block-caption span.caption-text {\n+}\n+\n+div.literal-block-wrapper {\n+    margin: 1em 0;\n+}\n+\n+code.xref, a code {\n+    background-color: transparent;\n+    font-weight: bold;\n+}\n+\n+h1 code, h2 code, h3 code, h4 code, h5 code, h6 code {\n+    background-color: transparent;\n+}\n+\n+.viewcode-link {\n+    float: right;\n+}\n+\n+.viewcode-back {\n+    float: right;\n+    font-family: sans-serif;\n+}\n+\n+div.viewcode-block:target {\n+    margin: -1px -10px;\n+    padding: 0 10px;\n+}\n+\n+/* -- math display ---------------------------------------------------------- */\n+\n+img.math {\n+    vertical-align: middle;\n+}\n+\n+div.body div.math p {\n+    text-align: center;\n+}\n+\n+span.eqno {\n+    float: right;\n+}\n+\n+span.eqno a.headerlink {\n+    position: absolute;\n+    z-index: 1;\n+}\n+\n+div.math:hover a.headerlink {\n+    visibility: visible;\n+}\n+\n+/* -- printout stylesheet --------------------------------------------------- */\n+\n+@media print {\n+    div.document,\n+    div.documentwrapper,\n+    div.bodywrapper {\n+        margin: 0 !important;\n+        width: 100%;\n+    }\n+\n+    div.sphinxsidebar,\n+    div.related,\n+    div.footer,\n+    #top-link {\n+        display: none;\n+    }\n+}\n\\ No newline at end of file\ndiff --git a/test_svg_nested/_build/_static/custom.css b/test_svg_nested/_build/_static/custom.css\nnew file mode 100644\nindex 000000000..2a924f1d6\n--- /dev/null\n+++ b/test_svg_nested/_build/_static/custom.css\n@@ -0,0 +1 @@\n+/* This file intentionally left blank. */\ndiff --git a/test_svg_nested/_build/_static/doctools.js b/test_svg_nested/_build/_static/doctools.js\nnew file mode 100644\nindex 000000000..d06a71d75\n--- /dev/null\n+++ b/test_svg_nested/_build/_static/doctools.js\n@@ -0,0 +1,156 @@\n+/*\n+ * doctools.js\n+ * ~~~~~~~~~~~\n+ *\n+ * Base JavaScript utilities for all Sphinx HTML documentation.\n+ *\n+ * :copyright: Copyright 2007-2023 by the Sphinx team, see AUTHORS.\n+ * :license: BSD, see LICENSE for details.\n+ *\n+ */\n+\"use strict\";\n+\n+const BLACKLISTED_KEY_CONTROL_ELEMENTS = new Set([\n+  \"TEXTAREA\",\n+  \"INPUT\",\n+  \"SELECT\",\n+  \"BUTTON\",\n+]);\n+\n+const _ready = (callback) => {\n+  if (document.readyState !== \"loading\") {\n+    callback();\n+  } else {\n+    document.addEventListener(\"DOMContentLoaded\", callback);\n+  }\n+};\n+\n+/**\n+ * Small JavaScript module for the documentation.\n+ */\n+const Documentation = {\n+  init: () => {\n+    Documentation.initDomainIndexTable();\n+    Documentation.initOnKeyListeners();\n+  },\n+\n+  /**\n+   * i18n support\n+   */\n+  TRANSLATIONS: {},\n+  PLURAL_EXPR: (n) => (n === 1 ? 0 : 1),\n+  LOCALE: \"unknown\",\n+\n+  // gettext and ngettext don't access this so that the functions\n+  // can safely bound to a different name (_ = Documentation.gettext)\n+  gettext: (string) => {\n+    const translated = Documentation.TRANSLATIONS[string];\n+    switch (typeof translated) {\n+      case \"undefined\":\n+        return string; // no translation\n+      case \"string\":\n+        return translated; // translation exists\n+      default:\n+        return translated[0]; // (singular, plural) translation tuple exists\n+    }\n+  },\n+\n+  ngettext: (singular, plural, n) => {\n+    const translated = Documentation.TRANSLATIONS[singular];\n+    if (typeof translated !== \"undefined\")\n+      return translated[Documentation.PLURAL_EXPR(n)];\n+    return n === 1 ? singular : plural;\n+  },\n+\n+  addTranslations: (catalog) => {\n+    Object.assign(Documentation.TRANSLATIONS, catalog.messages);\n+    Documentation.PLURAL_EXPR = new Function(\n+      \"n\",\n+      `return (${catalog.plural_expr})`\n+    );\n+    Documentation.LOCALE = catalog.locale;\n+  },\n+\n+  /**\n+   * helper function to focus on search bar\n+   */\n+  focusSearchBar: () => {\n+    document.querySelectorAll(\"input[name=q]\")[0]?.focus();\n+  },\n+\n+  /**\n+   * Initialise the domain index toggle buttons\n+   */\n+  initDomainIndexTable: () => {\n+    const toggler = (el) => {\n+      const idNumber = el.id.substr(7);\n+      const toggledRows = document.querySelectorAll(`tr.cg-${idNumber}`);\n+      if (el.src.substr(-9) === \"minus.png\") {\n+        el.src = `${el.src.substr(0, el.src.length - 9)}plus.png`;\n+        toggledRows.forEach((el) => (el.style.display = \"none\"));\n+      } else {\n+        el.src = `${el.src.substr(0, el.src.length - 8)}minus.png`;\n+        toggledRows.forEach((el) => (el.style.display = \"\"));\n+      }\n+    };\n+\n+    const togglerElements = document.querySelectorAll(\"img.toggler\");\n+    togglerElements.forEach((el) =>\n+      el.addEventListener(\"click\", (event) => toggler(event.currentTarget))\n+    );\n+    togglerElements.forEach((el) => (el.style.display = \"\"));\n+    if (DOCUMENTATION_OPTIONS.COLLAPSE_INDEX) togglerElements.forEach(toggler);\n+  },\n+\n+  initOnKeyListeners: () => {\n+    // only install a listener if it is really needed\n+    if (\n+      !DOCUMENTATION_OPTIONS.NAVIGATION_WITH_KEYS &&\n+      !DOCUMENTATION_OPTIONS.ENABLE_SEARCH_SHORTCUTS\n+    )\n+      return;\n+\n+    document.addEventListener(\"keydown\", (event) => {\n+      // bail for input elements\n+      if (BLACKLISTED_KEY_CONTROL_ELEMENTS.has(document.activeElement.tagName)) return;\n+      // bail with special keys\n+      if (event.altKey || event.ctrlKey || event.metaKey) return;\n+\n+      if (!event.shiftKey) {\n+        switch (event.key) {\n+          case \"ArrowLeft\":\n+            if (!DOCUMENTATION_OPTIONS.NAVIGATION_WITH_KEYS) break;\n+\n+            const prevLink = document.querySelector('link[rel=\"prev\"]');\n+            if (prevLink && prevLink.href) {\n+              window.location.href = prevLink.href;\n+              event.preventDefault();\n+            }\n+            break;\n+          case \"ArrowRight\":\n+            if (!DOCUMENTATION_OPTIONS.NAVIGATION_WITH_KEYS) break;\n+\n+            const nextLink = document.querySelector('link[rel=\"next\"]');\n+            if (nextLink && nextLink.href) {\n+              window.location.href = nextLink.href;\n+              event.preventDefault();\n+            }\n+            break;\n+        }\n+      }\n+\n+      // some keyboard layouts may need Shift to get /\n+      switch (event.key) {\n+        case \"/\":\n+          if (!DOCUMENTATION_OPTIONS.ENABLE_SEARCH_SHORTCUTS) break;\n+          Documentation.focusSearchBar();\n+          event.preventDefault();\n+      }\n+    });\n+  },\n+};\n+\n+// quick alias for translations\n+const _ = Documentation.gettext;\n+\n+_ready(Documentation.init);\ndiff --git a/test_svg_nested/_build/_static/documentation_options.js b/test_svg_nested/_build/_static/documentation_options.js\nnew file mode 100644\nindex 000000000..b57ae3b83\n--- /dev/null\n+++ b/test_svg_nested/_build/_static/documentation_options.js\n@@ -0,0 +1,14 @@\n+var DOCUMENTATION_OPTIONS = {\n+    URL_ROOT: document.getElementById(\"documentation_options\").getAttribute('data-url_root'),\n+    VERSION: '',\n+    LANGUAGE: 'en',\n+    COLLAPSE_INDEX: false,\n+    BUILDER: 'html',\n+    FILE_SUFFIX: '.html',\n+    LINK_SUFFIX: '.html',\n+    HAS_SOURCE: true,\n+    SOURCELINK_SUFFIX: '.txt',\n+    NAVIGATION_WITH_KEYS: false,\n+    SHOW_SEARCH_SUMMARY: true,\n+    ENABLE_SEARCH_SHORTCUTS: true,\n+};\n\\ No newline at end of file\ndiff --git a/test_svg_nested/_build/_static/file.png b/test_svg_nested/_build/_static/file.png\nnew file mode 100644\nindex 000000000..a858a410e\nBinary files /dev/null and b/test_svg_nested/_build/_static/file.png differ\ndiff --git a/test_svg_nested/_build/_static/graphviz.css b/test_svg_nested/_build/_static/graphviz.css\nnew file mode 100644\nindex 000000000..8d81c02ed\n--- /dev/null\n+++ b/test_svg_nested/_build/_static/graphviz.css\n@@ -0,0 +1,19 @@\n+/*\n+ * graphviz.css\n+ * ~~~~~~~~~~~~\n+ *\n+ * Sphinx stylesheet -- graphviz extension.\n+ *\n+ * :copyright: Copyright 2007-2023 by the Sphinx team, see AUTHORS.\n+ * :license: BSD, see LICENSE for details.\n+ *\n+ */\n+\n+img.graphviz {\n+    border: 0;\n+    max-width: 100%;\n+}\n+\n+object.graphviz {\n+    max-width: 100%;\n+}\ndiff --git a/test_svg_nested/_build/_static/language_data.js b/test_svg_nested/_build/_static/language_data.js\nnew file mode 100644\nindex 000000000..250f5665f\n--- /dev/null\n+++ b/test_svg_nested/_build/_static/language_data.js\n@@ -0,0 +1,199 @@\n+/*\n+ * language_data.js\n+ * ~~~~~~~~~~~~~~~~\n+ *\n+ * This script contains the language-specific data used by searchtools.js,\n+ * namely the list of stopwords, stemmer, scorer and splitter.\n+ *\n+ * :copyright: Copyright 2007-2023 by the Sphinx team, see AUTHORS.\n+ * :license: BSD, see LICENSE for details.\n+ *\n+ */\n+\n+var stopwords = [\"a\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\", \"if\", \"in\", \"into\", \"is\", \"it\", \"near\", \"no\", \"not\", \"of\", \"on\", \"or\", \"such\", \"that\", \"the\", \"their\", \"then\", \"there\", \"these\", \"they\", \"this\", \"to\", \"was\", \"will\", \"with\"];\n+\n+\n+/* Non-minified version is copied as a separate JS file, is available */\n+\n+/**\n+ * Porter Stemmer\n+ */\n+var Stemmer = function() {\n+\n+  var step2list = {\n+    ational: 'ate',\n+    tional: 'tion',\n+    enci: 'ence',\n+    anci: 'ance',\n+    izer: 'ize',\n+    bli: 'ble',\n+    alli: 'al',\n+    entli: 'ent',\n+    eli: 'e',\n+    ousli: 'ous',\n+    ization: 'ize',\n+    ation: 'ate',\n+    ator: 'ate',\n+    alism: 'al',\n+    iveness: 'ive',\n+    fulness: 'ful',\n+    ousness: 'ous',\n+    aliti: 'al',\n+    iviti: 'ive',\n+    biliti: 'ble',\n+    logi: 'log'\n+  };\n+\n+  var step3list = {\n+    icate: 'ic',\n+    ative: '',\n+    alize: 'al',\n+    iciti: 'ic',\n+    ical: 'ic',\n+    ful: '',\n+    ness: ''\n+  };\n+\n+  var c = \"[^aeiou]\";          // consonant\n+  var v = \"[aeiouy]\";          // vowel\n+  var C = c + \"[^aeiouy]*\";    // consonant sequence\n+  var V = v + \"[aeiou]*\";      // vowel sequence\n+\n+  var mgr0 = \"^(\" + C + \")?\" + V + C;                      // [C]VC... is m>0\n+  var meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\";    // [C]VC[V] is m=1\n+  var mgr1 = \"^(\" + C + \")?\" + V + C + V + C;              // [C]VCVC... is m>1\n+  var s_v   = \"^(\" + C + \")?\" + v;                         // vowel in stem\n+\n+  this.stemWord = function (w) {\n+    var stem;\n+    var suffix;\n+    var firstch;\n+    var origword = w;\n+\n+    if (w.length < 3)\n+      return w;\n+\n+    var re;\n+    var re2;\n+    var re3;\n+    var re4;\n+\n+    firstch = w.substr(0,1);\n+    if (firstch == \"y\")\n+      w = firstch.toUpperCase() + w.substr(1);\n+\n+    // Step 1a\n+    re = /^(.+?)(ss|i)es$/;\n+    re2 = /^(.+?)([^s])s$/;\n+\n+    if (re.test(w))\n+      w = w.replace(re,\"$1$2\");\n+    else if (re2.test(w))\n+      w = w.replace(re2,\"$1$2\");\n+\n+    // Step 1b\n+    re = /^(.+?)eed$/;\n+    re2 = /^(.+?)(ed|ing)$/;\n+    if (re.test(w)) {\n+      var fp = re.exec(w);\n+      re = new RegExp(mgr0);\n+      if (re.test(fp[1])) {\n+        re = /.$/;\n+        w = w.replace(re,\"\");\n+      }\n+    }\n+    else if (re2.test(w)) {\n+      var fp = re2.exec(w);\n+      stem = fp[1];\n+      re2 = new RegExp(s_v);\n+      if (re2.test(stem)) {\n+        w = stem;\n+        re2 = /(at|bl|iz)$/;\n+        re3 = new RegExp(\"([^aeiouylsz])\\\\1$\");\n+        re4 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n+        if (re2.test(w))\n+          w = w + \"e\";\n+        else if (re3.test(w)) {\n+          re = /.$/;\n+          w = w.replace(re,\"\");\n+        }\n+        else if (re4.test(w))\n+          w = w + \"e\";\n+      }\n+    }\n+\n+    // Step 1c\n+    re = /^(.+?)y$/;\n+    if (re.test(w)) {\n+      var fp = re.exec(w);\n+      stem = fp[1];\n+      re = new RegExp(s_v);\n+      if (re.test(stem))\n+        w = stem + \"i\";\n+    }\n+\n+    // Step 2\n+    re = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\n+    if (re.test(w)) {\n+      var fp = re.exec(w);\n+      stem = fp[1];\n+      suffix = fp[2];\n+      re = new RegExp(mgr0);\n+      if (re.test(stem))\n+        w = stem + step2list[suffix];\n+    }\n+\n+    // Step 3\n+    re = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\n+    if (re.test(w)) {\n+      var fp = re.exec(w);\n+      stem = fp[1];\n+      suffix = fp[2];\n+      re = new RegExp(mgr0);\n+      if (re.test(stem))\n+        w = stem + step3list[suffix];\n+    }\n+\n+    // Step 4\n+    re = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\n+    re2 = /^(.+?)(s|t)(ion)$/;\n+    if (re.test(w)) {\n+      var fp = re.exec(w);\n+      stem = fp[1];\n+      re = new RegExp(mgr1);\n+      if (re.test(stem))\n+        w = stem;\n+    }\n+    else if (re2.test(w)) {\n+      var fp = re2.exec(w);\n+      stem = fp[1] + fp[2];\n+      re2 = new RegExp(mgr1);\n+      if (re2.test(stem))\n+        w = stem;\n+    }\n+\n+    // Step 5\n+    re = /^(.+?)e$/;\n+    if (re.test(w)) {\n+      var fp = re.exec(w);\n+      stem = fp[1];\n+      re = new RegExp(mgr1);\n+      re2 = new RegExp(meq1);\n+      re3 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n+      if (re.test(stem) || (re2.test(stem) && !(re3.test(stem))))\n+        w = stem;\n+    }\n+    re = /ll$/;\n+    re2 = new RegExp(mgr1);\n+    if (re.test(w) && re2.test(w)) {\n+      re = /.$/;\n+      w = w.replace(re,\"\");\n+    }\n+\n+    // and turn initial Y back to y\n+    if (firstch == \"y\")\n+      w = firstch.toLowerCase() + w.substr(1);\n+    return w;\n+  }\n+}\n+\ndiff --git a/test_svg_nested/_build/_static/minus.png b/test_svg_nested/_build/_static/minus.png\nnew file mode 100644\nindex 000000000..d96755fda\nBinary files /dev/null and b/test_svg_nested/_build/_static/minus.png differ\ndiff --git a/test_svg_nested/_build/_static/plus.png b/test_svg_nested/_build/_static/plus.png\nnew file mode 100644\nindex 000000000..7107cec93\nBinary files /dev/null and b/test_svg_nested/_build/_static/plus.png differ\ndiff --git a/test_svg_nested/_build/_static/pygments.css b/test_svg_nested/_build/_static/pygments.css\nnew file mode 100644\nindex 000000000..04a41742e\n--- /dev/null\n+++ b/test_svg_nested/_build/_static/pygments.css\n@@ -0,0 +1,84 @@\n+pre { line-height: 125%; }\n+td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n+span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n+td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n+span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n+.highlight .hll { background-color: #ffffcc }\n+.highlight { background: #f8f8f8; }\n+.highlight .c { color: #8f5902; font-style: italic } /* Comment */\n+.highlight .err { color: #a40000; border: 1px solid #ef2929 } /* Error */\n+.highlight .g { color: #000000 } /* Generic */\n+.highlight .k { color: #004461; font-weight: bold } /* Keyword */\n+.highlight .l { color: #000000 } /* Literal */\n+.highlight .n { color: #000000 } /* Name */\n+.highlight .o { color: #582800 } /* Operator */\n+.highlight .x { color: #000000 } /* Other */\n+.highlight .p { color: #000000; font-weight: bold } /* Punctuation */\n+.highlight .ch { color: #8f5902; font-style: italic } /* Comment.Hashbang */\n+.highlight .cm { color: #8f5902; font-style: italic } /* Comment.Multiline */\n+.highlight .cp { color: #8f5902 } /* Comment.Preproc */\n+.highlight .cpf { color: #8f5902; font-style: italic } /* Comment.PreprocFile */\n+.highlight .c1 { color: #8f5902; font-style: italic } /* Comment.Single */\n+.highlight .cs { color: #8f5902; font-style: italic } /* Comment.Special */\n+.highlight .gd { color: #a40000 } /* Generic.Deleted */\n+.highlight .ge { color: #000000; font-style: italic } /* Generic.Emph */\n+.highlight .ges { color: #000000 } /* Generic.EmphStrong */\n+.highlight .gr { color: #ef2929 } /* Generic.Error */\n+.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n+.highlight .gi { color: #00A000 } /* Generic.Inserted */\n+.highlight .go { color: #888888 } /* Generic.Output */\n+.highlight .gp { color: #745334 } /* Generic.Prompt */\n+.highlight .gs { color: #000000; font-weight: bold } /* Generic.Strong */\n+.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n+.highlight .gt { color: #a40000; font-weight: bold } /* Generic.Traceback */\n+.highlight .kc { color: #004461; font-weight: bold } /* Keyword.Constant */\n+.highlight .kd { color: #004461; font-weight: bold } /* Keyword.Declaration */\n+.highlight .kn { color: #004461; font-weight: bold } /* Keyword.Namespace */\n+.highlight .kp { color: #004461; font-weight: bold } /* Keyword.Pseudo */\n+.highlight .kr { color: #004461; font-weight: bold } /* Keyword.Reserved */\n+.highlight .kt { color: #004461; font-weight: bold } /* Keyword.Type */\n+.highlight .ld { color: #000000 } /* Literal.Date */\n+.highlight .m { color: #990000 } /* Literal.Number */\n+.highlight .s { color: #4e9a06 } /* Literal.String */\n+.highlight .na { color: #c4a000 } /* Name.Attribute */\n+.highlight .nb { color: #004461 } /* Name.Builtin */\n+.highlight .nc { color: #000000 } /* Name.Class */\n+.highlight .no { color: #000000 } /* Name.Constant */\n+.highlight .nd { color: #888888 } /* Name.Decorator */\n+.highlight .ni { color: #ce5c00 } /* Name.Entity */\n+.highlight .ne { color: #cc0000; font-weight: bold } /* Name.Exception */\n+.highlight .nf { color: #000000 } /* Name.Function */\n+.highlight .nl { color: #f57900 } /* Name.Label */\n+.highlight .nn { color: #000000 } /* Name.Namespace */\n+.highlight .nx { color: #000000 } /* Name.Other */\n+.highlight .py { color: #000000 } /* Name.Property */\n+.highlight .nt { color: #004461; font-weight: bold } /* Name.Tag */\n+.highlight .nv { color: #000000 } /* Name.Variable */\n+.highlight .ow { color: #004461; font-weight: bold } /* Operator.Word */\n+.highlight .pm { color: #000000; font-weight: bold } /* Punctuation.Marker */\n+.highlight .w { color: #f8f8f8 } /* Text.Whitespace */\n+.highlight .mb { color: #990000 } /* Literal.Number.Bin */\n+.highlight .mf { color: #990000 } /* Literal.Number.Float */\n+.highlight .mh { color: #990000 } /* Literal.Number.Hex */\n+.highlight .mi { color: #990000 } /* Literal.Number.Integer */\n+.highlight .mo { color: #990000 } /* Literal.Number.Oct */\n+.highlight .sa { color: #4e9a06 } /* Literal.String.Affix */\n+.highlight .sb { color: #4e9a06 } /* Literal.String.Backtick */\n+.highlight .sc { color: #4e9a06 } /* Literal.String.Char */\n+.highlight .dl { color: #4e9a06 } /* Literal.String.Delimiter */\n+.highlight .sd { color: #8f5902; font-style: italic } /* Literal.String.Doc */\n+.highlight .s2 { color: #4e9a06 } /* Literal.String.Double */\n+.highlight .se { color: #4e9a06 } /* Literal.String.Escape */\n+.highlight .sh { color: #4e9a06 } /* Literal.String.Heredoc */\n+.highlight .si { color: #4e9a06 } /* Literal.String.Interpol */\n+.highlight .sx { color: #4e9a06 } /* Literal.String.Other */\n+.highlight .sr { color: #4e9a06 } /* Literal.String.Regex */\n+.highlight .s1 { color: #4e9a06 } /* Literal.String.Single */\n+.highlight .ss { color: #4e9a06 } /* Literal.String.Symbol */\n+.highlight .bp { color: #3465a4 } /* Name.Builtin.Pseudo */\n+.highlight .fm { color: #000000 } /* Name.Function.Magic */\n+.highlight .vc { color: #000000 } /* Name.Variable.Class */\n+.highlight .vg { color: #000000 } /* Name.Variable.Global */\n+.highlight .vi { color: #000000 } /* Name.Variable.Instance */\n+.highlight .vm { color: #000000 } /* Name.Variable.Magic */\n+.highlight .il { color: #990000 } /* Literal.Number.Integer.Long */\n\\ No newline at end of file\ndiff --git a/test_svg_nested/_build/_static/searchtools.js b/test_svg_nested/_build/_static/searchtools.js\nnew file mode 100644\nindex 000000000..97d56a74d\n--- /dev/null\n+++ b/test_svg_nested/_build/_static/searchtools.js\n@@ -0,0 +1,566 @@\n+/*\n+ * searchtools.js\n+ * ~~~~~~~~~~~~~~~~\n+ *\n+ * Sphinx JavaScript utilities for the full-text search.\n+ *\n+ * :copyright: Copyright 2007-2023 by the Sphinx team, see AUTHORS.\n+ * :license: BSD, see LICENSE for details.\n+ *\n+ */\n+\"use strict\";\n+\n+/**\n+ * Simple result scoring code.\n+ */\n+if (typeof Scorer === \"undefined\") {\n+  var Scorer = {\n+    // Implement the following function to further tweak the score for each result\n+    // The function takes a result array [docname, title, anchor, descr, score, filename]\n+    // and returns the new score.\n+    /*\n+    score: result => {\n+      const [docname, title, anchor, descr, score, filename] = result\n+      return score\n+    },\n+    */\n+\n+    // query matches the full name of an object\n+    objNameMatch: 11,\n+    // or matches in the last dotted part of the object name\n+    objPartialMatch: 6,\n+    // Additive scores depending on the priority of the object\n+    objPrio: {\n+      0: 15, // used to be importantResults\n+      1: 5, // used to be objectResults\n+      2: -5, // used to be unimportantResults\n+    },\n+    //  Used when the priority is not in the mapping.\n+    objPrioDefault: 0,\n+\n+    // query found in title\n+    title: 15,\n+    partialTitle: 7,\n+    // query found in terms\n+    term: 5,\n+    partialTerm: 2,\n+  };\n+}\n+\n+const _removeChildren = (element) => {\n+  while (element && element.lastChild) element.removeChild(element.lastChild);\n+};\n+\n+/**\n+ * See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions#escaping\n+ */\n+const _escapeRegExp = (string) =>\n+  string.replace(/[.*+\\-?^${}()|[\\]\\\\]/g, \"\\\\$&\"); // $& means the whole matched string\n+\n+const _displayItem = (item, searchTerms) => {\n+  const docBuilder = DOCUMENTATION_OPTIONS.BUILDER;\n+  const docUrlRoot = DOCUMENTATION_OPTIONS.URL_ROOT;\n+  const docFileSuffix = DOCUMENTATION_OPTIONS.FILE_SUFFIX;\n+  const docLinkSuffix = DOCUMENTATION_OPTIONS.LINK_SUFFIX;\n+  const showSearchSummary = DOCUMENTATION_OPTIONS.SHOW_SEARCH_SUMMARY;\n+\n+  const [docName, title, anchor, descr, score, _filename] = item;\n+\n+  let listItem = document.createElement(\"li\");\n+  let requestUrl;\n+  let linkUrl;\n+  if (docBuilder === \"dirhtml\") {\n+    // dirhtml builder\n+    let dirname = docName + \"/\";\n+    if (dirname.match(/\\/index\\/$/))\n+      dirname = dirname.substring(0, dirname.length - 6);\n+    else if (dirname === \"index/\") dirname = \"\";\n+    requestUrl = docUrlRoot + dirname;\n+    linkUrl = requestUrl;\n+  } else {\n+    // normal html builders\n+    requestUrl = docUrlRoot + docName + docFileSuffix;\n+    linkUrl = docName + docLinkSuffix;\n+  }\n+  let linkEl = listItem.appendChild(document.createElement(\"a\"));\n+  linkEl.href = linkUrl + anchor;\n+  linkEl.dataset.score = score;\n+  linkEl.innerHTML = title;\n+  if (descr)\n+    listItem.appendChild(document.createElement(\"span\")).innerHTML =\n+      \" (\" + descr + \")\";\n+  else if (showSearchSummary)\n+    fetch(requestUrl)\n+      .then((responseData) => responseData.text())\n+      .then((data) => {\n+        if (data)\n+          listItem.appendChild(\n+            Search.makeSearchSummary(data, searchTerms)\n+          );\n+      });\n+  Search.output.appendChild(listItem);\n+};\n+const _finishSearch = (resultCount) => {\n+  Search.stopPulse();\n+  Search.title.innerText = _(\"Search Results\");\n+  if (!resultCount)\n+    Search.status.innerText = Documentation.gettext(\n+      \"Your search did not match any documents. Please make sure that all words are spelled correctly and that you've selected enough categories.\"\n+    );\n+  else\n+    Search.status.innerText = _(\n+      `Search finished, found ${resultCount} page(s) matching the search query.`\n+    );\n+};\n+const _displayNextItem = (\n+  results,\n+  resultCount,\n+  searchTerms\n+) => {\n+  // results left, load the summary and display it\n+  // this is intended to be dynamic (don't sub resultsCount)\n+  if (results.length) {\n+    _displayItem(results.pop(), searchTerms);\n+    setTimeout(\n+      () => _displayNextItem(results, resultCount, searchTerms),\n+      5\n+    );\n+  }\n+  // search finished, update title and status message\n+  else _finishSearch(resultCount);\n+};\n+\n+/**\n+ * Default splitQuery function. Can be overridden in ``sphinx.search`` with a\n+ * custom function per language.\n+ *\n+ * The regular expression works by splitting the string on consecutive characters\n+ * that are not Unicode letters, numbers, underscores, or emoji characters.\n+ * This is the same as ``\\W+`` in Python, preserving the surrogate pair area.\n+ */\n+if (typeof splitQuery === \"undefined\") {\n+  var splitQuery = (query) => query\n+      .split(/[^\\p{Letter}\\p{Number}_\\p{Emoji_Presentation}]+/gu)\n+      .filter(term => term)  // remove remaining empty strings\n+}\n+\n+/**\n+ * Search Module\n+ */\n+const Search = {\n+  _index: null,\n+  _queued_query: null,\n+  _pulse_status: -1,\n+\n+  htmlToText: (htmlString) => {\n+    const htmlElement = new DOMParser().parseFromString(htmlString, 'text/html');\n+    htmlElement.querySelectorAll(\".headerlink\").forEach((el) => { el.remove() });\n+    const docContent = htmlElement.querySelector('[role=\"main\"]');\n+    if (docContent !== undefined) return docContent.textContent;\n+    console.warn(\n+      \"Content block not found. Sphinx search tries to obtain it via '[role=main]'. Could you check your theme or template.\"\n+    );\n+    return \"\";\n+  },\n+\n+  init: () => {\n+    const query = new URLSearchParams(window.location.search).get(\"q\");\n+    document\n+      .querySelectorAll('input[name=\"q\"]')\n+      .forEach((el) => (el.value = query));\n+    if (query) Search.performSearch(query);\n+  },\n+\n+  loadIndex: (url) =>\n+    (document.body.appendChild(document.createElement(\"script\")).src = url),\n+\n+  setIndex: (index) => {\n+    Search._index = index;\n+    if (Search._queued_query !== null) {\n+      const query = Search._queued_query;\n+      Search._queued_query = null;\n+      Search.query(query);\n+    }\n+  },\n+\n+  hasIndex: () => Search._index !== null,\n+\n+  deferQuery: (query) => (Search._queued_query = query),\n+\n+  stopPulse: () => (Search._pulse_status = -1),\n+\n+  startPulse: () => {\n+    if (Search._pulse_status >= 0) return;\n+\n+    const pulse = () => {\n+      Search._pulse_status = (Search._pulse_status + 1) % 4;\n+      Search.dots.innerText = \".\".repeat(Search._pulse_status);\n+      if (Search._pulse_status >= 0) window.setTimeout(pulse, 500);\n+    };\n+    pulse();\n+  },\n+\n+  /**\n+   * perform a search for something (or wait until index is loaded)\n+   */\n+  performSearch: (query) => {\n+    // create the required interface elements\n+    const searchText = document.createElement(\"h2\");\n+    searchText.textContent = _(\"Searching\");\n+    const searchSummary = document.createElement(\"p\");\n+    searchSummary.classList.add(\"search-summary\");\n+    searchSummary.innerText = \"\";\n+    const searchList = document.createElement(\"ul\");\n+    searchList.classList.add(\"search\");\n+\n+    const out = document.getElementById(\"search-results\");\n+    Search.title = out.appendChild(searchText);\n+    Search.dots = Search.title.appendChild(document.createElement(\"span\"));\n+    Search.status = out.appendChild(searchSummary);\n+    Search.output = out.appendChild(searchList);\n+\n+    const searchProgress = document.getElementById(\"search-progress\");\n+    // Some themes don't use the search progress node\n+    if (searchProgress) {\n+      searchProgress.innerText = _(\"Preparing search...\");\n+    }\n+    Search.startPulse();\n+\n+    // index already loaded, the browser was quick!\n+    if (Search.hasIndex()) Search.query(query);\n+    else Search.deferQuery(query);\n+  },\n+\n+  /**\n+   * execute search (requires search index to be loaded)\n+   */\n+  query: (query) => {\n+    const filenames = Search._index.filenames;\n+    const docNames = Search._index.docnames;\n+    const titles = Search._index.titles;\n+    const allTitles = Search._index.alltitles;\n+    const indexEntries = Search._index.indexentries;\n+\n+    // stem the search terms and add them to the correct list\n+    const stemmer = new Stemmer();\n+    const searchTerms = new Set();\n+    const excludedTerms = new Set();\n+    const highlightTerms = new Set();\n+    const objectTerms = new Set(splitQuery(query.toLowerCase().trim()));\n+    splitQuery(query.trim()).forEach((queryTerm) => {\n+      const queryTermLower = queryTerm.toLowerCase();\n+\n+      // maybe skip this \"word\"\n+      // stopwords array is from language_data.js\n+      if (\n+        stopwords.indexOf(queryTermLower) !== -1 ||\n+        queryTerm.match(/^\\d+$/)\n+      )\n+        return;\n+\n+      // stem the word\n+      let word = stemmer.stemWord(queryTermLower);\n+      // select the correct list\n+      if (word[0] === \"-\") excludedTerms.add(word.substr(1));\n+      else {\n+        searchTerms.add(word);\n+        highlightTerms.add(queryTermLower);\n+      }\n+    });\n+\n+    if (SPHINX_HIGHLIGHT_ENABLED) {  // set in sphinx_highlight.js\n+      localStorage.setItem(\"sphinx_highlight_terms\", [...highlightTerms].join(\" \"))\n+    }\n+\n+    // console.debug(\"SEARCH: searching for:\");\n+    // console.info(\"required: \", [...searchTerms]);\n+    // console.info(\"excluded: \", [...excludedTerms]);\n+\n+    // array of [docname, title, anchor, descr, score, filename]\n+    let results = [];\n+    _removeChildren(document.getElementById(\"search-progress\"));\n+\n+    const queryLower = query.toLowerCase();\n+    for (const [title, foundTitles] of Object.entries(allTitles)) {\n+      if (title.toLowerCase().includes(queryLower) && (queryLower.length >= title.length/2)) {\n+        for (const [file, id] of foundTitles) {\n+          let score = Math.round(100 * queryLower.length / title.length)\n+          results.push([\n+            docNames[file],\n+            titles[file] !== title ? `${titles[file]} > ${title}` : title,\n+            id !== null ? \"#\" + id : \"\",\n+            null,\n+            score,\n+            filenames[file],\n+          ]);\n+        }\n+      }\n+    }\n+\n+    // search for explicit entries in index directives\n+    for (const [entry, foundEntries] of Object.entries(indexEntries)) {\n+      if (entry.includes(queryLower) && (queryLower.length >= entry.length/2)) {\n+        for (const [file, id] of foundEntries) {\n+          let score = Math.round(100 * queryLower.length / entry.length)\n+          results.push([\n+            docNames[file],\n+            titles[file],\n+            id ? \"#\" + id : \"\",\n+            null,\n+            score,\n+            filenames[file],\n+          ]);\n+        }\n+      }\n+    }\n+\n+    // lookup as object\n+    objectTerms.forEach((term) =>\n+      results.push(...Search.performObjectSearch(term, objectTerms))\n+    );\n+\n+    // lookup as search terms in fulltext\n+    results.push(...Search.performTermsSearch(searchTerms, excludedTerms));\n+\n+    // let the scorer override scores with a custom scoring function\n+    if (Scorer.score) results.forEach((item) => (item[4] = Scorer.score(item)));\n+\n+    // now sort the results by score (in opposite order of appearance, since the\n+    // display function below uses pop() to retrieve items) and then\n+    // alphabetically\n+    results.sort((a, b) => {\n+      const leftScore = a[4];\n+      const rightScore = b[4];\n+      if (leftScore === rightScore) {\n+        // same score: sort alphabetically\n+        const leftTitle = a[1].toLowerCase();\n+        const rightTitle = b[1].toLowerCase();\n+        if (leftTitle === rightTitle) return 0;\n+        return leftTitle > rightTitle ? -1 : 1; // inverted is intentional\n+      }\n+      return leftScore > rightScore ? 1 : -1;\n+    });\n+\n+    // remove duplicate search results\n+    // note the reversing of results, so that in the case of duplicates, the highest-scoring entry is kept\n+    let seen = new Set();\n+    results = results.reverse().reduce((acc, result) => {\n+      let resultStr = result.slice(0, 4).concat([result[5]]).map(v => String(v)).join(',');\n+      if (!seen.has(resultStr)) {\n+        acc.push(result);\n+        seen.add(resultStr);\n+      }\n+      return acc;\n+    }, []);\n+\n+    results = results.reverse();\n+\n+    // for debugging\n+    //Search.lastresults = results.slice();  // a copy\n+    // console.info(\"search results:\", Search.lastresults);\n+\n+    // print the results\n+    _displayNextItem(results, results.length, searchTerms);\n+  },\n+\n+  /**\n+   * search for object names\n+   */\n+  performObjectSearch: (object, objectTerms) => {\n+    const filenames = Search._index.filenames;\n+    const docNames = Search._index.docnames;\n+    const objects = Search._index.objects;\n+    const objNames = Search._index.objnames;\n+    const titles = Search._index.titles;\n+\n+    const results = [];\n+\n+    const objectSearchCallback = (prefix, match) => {\n+      const name = match[4]\n+      const fullname = (prefix ? prefix + \".\" : \"\") + name;\n+      const fullnameLower = fullname.toLowerCase();\n+      if (fullnameLower.indexOf(object) < 0) return;\n+\n+      let score = 0;\n+      const parts = fullnameLower.split(\".\");\n+\n+      // check for different match types: exact matches of full name or\n+      // \"last name\" (i.e. last dotted part)\n+      if (fullnameLower === object || parts.slice(-1)[0] === object)\n+        score += Scorer.objNameMatch;\n+      else if (parts.slice(-1)[0].indexOf(object) > -1)\n+        score += Scorer.objPartialMatch; // matches in last name\n+\n+      const objName = objNames[match[1]][2];\n+      const title = titles[match[0]];\n+\n+      // If more than one term searched for, we require other words to be\n+      // found in the name/title/description\n+      const otherTerms = new Set(objectTerms);\n+      otherTerms.delete(object);\n+      if (otherTerms.size > 0) {\n+        const haystack = `${prefix} ${name} ${objName} ${title}`.toLowerCase();\n+        if (\n+          [...otherTerms].some((otherTerm) => haystack.indexOf(otherTerm) < 0)\n+        )\n+          return;\n+      }\n+\n+      let anchor = match[3];\n+      if (anchor === \"\") anchor = fullname;\n+      else if (anchor === \"-\") anchor = objNames[match[1]][1] + \"-\" + fullname;\n+\n+      const descr = objName + _(\", in \") + title;\n+\n+      // add custom score for some objects according to scorer\n+      if (Scorer.objPrio.hasOwnProperty(match[2]))\n+        score += Scorer.objPrio[match[2]];\n+      else score += Scorer.objPrioDefault;\n+\n+      results.push([\n+        docNames[match[0]],\n+        fullname,\n+        \"#\" + anchor,\n+        descr,\n+        score,\n+        filenames[match[0]],\n+      ]);\n+    };\n+    Object.keys(objects).forEach((prefix) =>\n+      objects[prefix].forEach((array) =>\n+        objectSearchCallback(prefix, array)\n+      )\n+    );\n+    return results;\n+  },\n+\n+  /**\n+   * search for full-text terms in the index\n+   */\n+  performTermsSearch: (searchTerms, excludedTerms) => {\n+    // prepare search\n+    const terms = Search._index.terms;\n+    const titleTerms = Search._index.titleterms;\n+    const filenames = Search._index.filenames;\n+    const docNames = Search._index.docnames;\n+    const titles = Search._index.titles;\n+\n+    const scoreMap = new Map();\n+    const fileMap = new Map();\n+\n+    // perform the search on the required terms\n+    searchTerms.forEach((word) => {\n+      const files = [];\n+      const arr = [\n+        { files: terms[word], score: Scorer.term },\n+        { files: titleTerms[word], score: Scorer.title },\n+      ];\n+      // add support for partial matches\n+      if (word.length > 2) {\n+        const escapedWord = _escapeRegExp(word);\n+        Object.keys(terms).forEach((term) => {\n+          if (term.match(escapedWord) && !terms[word])\n+            arr.push({ files: terms[term], score: Scorer.partialTerm });\n+        });\n+        Object.keys(titleTerms).forEach((term) => {\n+          if (term.match(escapedWord) && !titleTerms[word])\n+            arr.push({ files: titleTerms[word], score: Scorer.partialTitle });\n+        });\n+      }\n+\n+      // no match but word was a required one\n+      if (arr.every((record) => record.files === undefined)) return;\n+\n+      // found search word in contents\n+      arr.forEach((record) => {\n+        if (record.files === undefined) return;\n+\n+        let recordFiles = record.files;\n+        if (recordFiles.length === undefined) recordFiles = [recordFiles];\n+        files.push(...recordFiles);\n+\n+        // set score for the word in each file\n+        recordFiles.forEach((file) => {\n+          if (!scoreMap.has(file)) scoreMap.set(file, {});\n+          scoreMap.get(file)[word] = record.score;\n+        });\n+      });\n+\n+      // create the mapping\n+      files.forEach((file) => {\n+        if (fileMap.has(file) && fileMap.get(file).indexOf(word) === -1)\n+          fileMap.get(file).push(word);\n+        else fileMap.set(file, [word]);\n+      });\n+    });\n+\n+    // now check if the files don't contain excluded terms\n+    const results = [];\n+    for (const [file, wordList] of fileMap) {\n+      // check if all requirements are matched\n+\n+      // as search terms with length < 3 are discarded\n+      const filteredTermCount = [...searchTerms].filter(\n+        (term) => term.length > 2\n+      ).length;\n+      if (\n+        wordList.length !== searchTerms.size &&\n+        wordList.length !== filteredTermCount\n+      )\n+        continue;\n+\n+      // ensure that none of the excluded terms is in the search result\n+      if (\n+        [...excludedTerms].some(\n+          (term) =>\n+            terms[term] === file ||\n+            titleTerms[term] === file ||\n+            (terms[term] || []).includes(file) ||\n+            (titleTerms[term] || []).includes(file)\n+        )\n+      )\n+        break;\n+\n+      // select one (max) score for the file.\n+      const score = Math.max(...wordList.map((w) => scoreMap.get(file)[w]));\n+      // add result to the result list\n+      results.push([\n+        docNames[file],\n+        titles[file],\n+        \"\",\n+        null,\n+        score,\n+        filenames[file],\n+      ]);\n+    }\n+    return results;\n+  },\n+\n+  /**\n+   * helper function to return a node containing the\n+   * search summary for a given text. keywords is a list\n+   * of stemmed words.\n+   */\n+  makeSearchSummary: (htmlText, keywords) => {\n+    const text = Search.htmlToText(htmlText);\n+    if (text === \"\") return null;\n+\n+    const textLower = text.toLowerCase();\n+    const actualStartPosition = [...keywords]\n+      .map((k) => textLower.indexOf(k.toLowerCase()))\n+      .filter((i) => i > -1)\n+      .slice(-1)[0];\n+    const startWithContext = Math.max(actualStartPosition - 120, 0);\n+\n+    const top = startWithContext === 0 ? \"\" : \"...\";\n+    const tail = startWithContext + 240 < text.length ? \"...\" : \"\";\n+\n+    let summary = document.createElement(\"p\");\n+    summary.classList.add(\"context\");\n+    summary.textContent = top + text.substr(startWithContext, 240).trim() + tail;\n+\n+    return summary;\n+  },\n+};\n+\n+_ready(Search.init);\ndiff --git a/test_svg_nested/_build/_static/sphinx_highlight.js b/test_svg_nested/_build/_static/sphinx_highlight.js\nnew file mode 100644\nindex 000000000..aae669d7e\n--- /dev/null\n+++ b/test_svg_nested/_build/_static/sphinx_highlight.js\n@@ -0,0 +1,144 @@\n+/* Highlighting utilities for Sphinx HTML documentation. */\n+\"use strict\";\n+\n+const SPHINX_HIGHLIGHT_ENABLED = true\n+\n+/**\n+ * highlight a given string on a node by wrapping it in\n+ * span elements with the given class name.\n+ */\n+const _highlight = (node, addItems, text, className) => {\n+  if (node.nodeType === Node.TEXT_NODE) {\n+    const val = node.nodeValue;\n+    const parent = node.parentNode;\n+    const pos = val.toLowerCase().indexOf(text);\n+    if (\n+      pos >= 0 &&\n+      !parent.classList.contains(className) &&\n+      !parent.classList.contains(\"nohighlight\")\n+    ) {\n+      let span;\n+\n+      const closestNode = parent.closest(\"body, svg, foreignObject\");\n+      const isInSVG = closestNode && closestNode.matches(\"svg\");\n+      if (isInSVG) {\n+        span = document.createElementNS(\"http://www.w3.org/2000/svg\", \"tspan\");\n+      } else {\n+        span = document.createElement(\"span\");\n+        span.classList.add(className);\n+      }\n+\n+      span.appendChild(document.createTextNode(val.substr(pos, text.length)));\n+      parent.insertBefore(\n+        span,\n+        parent.insertBefore(\n+          document.createTextNode(val.substr(pos + text.length)),\n+          node.nextSibling\n+        )\n+      );\n+      node.nodeValue = val.substr(0, pos);\n+\n+      if (isInSVG) {\n+        const rect = document.createElementNS(\n+          \"http://www.w3.org/2000/svg\",\n+          \"rect\"\n+        );\n+        const bbox = parent.getBBox();\n+        rect.x.baseVal.value = bbox.x;\n+        rect.y.baseVal.value = bbox.y;\n+        rect.width.baseVal.value = bbox.width;\n+        rect.height.baseVal.value = bbox.height;\n+        rect.setAttribute(\"class\", className);\n+        addItems.push({ parent: parent, target: rect });\n+      }\n+    }\n+  } else if (node.matches && !node.matches(\"button, select, textarea\")) {\n+    node.childNodes.forEach((el) => _highlight(el, addItems, text, className));\n+  }\n+};\n+const _highlightText = (thisNode, text, className) => {\n+  let addItems = [];\n+  _highlight(thisNode, addItems, text, className);\n+  addItems.forEach((obj) =>\n+    obj.parent.insertAdjacentElement(\"beforebegin\", obj.target)\n+  );\n+};\n+\n+/**\n+ * Small JavaScript module for the documentation.\n+ */\n+const SphinxHighlight = {\n+\n+  /**\n+   * highlight the search words provided in localstorage in the text\n+   */\n+  highlightSearchWords: () => {\n+    if (!SPHINX_HIGHLIGHT_ENABLED) return;  // bail if no highlight\n+\n+    // get and clear terms from localstorage\n+    const url = new URL(window.location);\n+    const highlight =\n+        localStorage.getItem(\"sphinx_highlight_terms\")\n+        || url.searchParams.get(\"highlight\")\n+        || \"\";\n+    localStorage.removeItem(\"sphinx_highlight_terms\")\n+    url.searchParams.delete(\"highlight\");\n+    window.history.replaceState({}, \"\", url);\n+\n+    // get individual terms from highlight string\n+    const terms = highlight.toLowerCase().split(/\\s+/).filter(x => x);\n+    if (terms.length === 0) return; // nothing to do\n+\n+    // There should never be more than one element matching \"div.body\"\n+    const divBody = document.querySelectorAll(\"div.body\");\n+    const body = divBody.length ? divBody[0] : document.querySelector(\"body\");\n+    window.setTimeout(() => {\n+      terms.forEach((term) => _highlightText(body, term, \"highlighted\"));\n+    }, 10);\n+\n+    const searchBox = document.getElementById(\"searchbox\");\n+    if (searchBox === null) return;\n+    searchBox.appendChild(\n+      document\n+        .createRange()\n+        .createContextualFragment(\n+          '<p class=\"highlight-link\">' +\n+            '<a href=\"javascript:SphinxHighlight.hideSearchWords()\">' +\n+            _(\"Hide Search Matches\") +\n+            \"</a></p>\"\n+        )\n+    );\n+  },\n+\n+  /**\n+   * helper function to hide the search marks again\n+   */\n+  hideSearchWords: () => {\n+    document\n+      .querySelectorAll(\"#searchbox .highlight-link\")\n+      .forEach((el) => el.remove());\n+    document\n+      .querySelectorAll(\"span.highlighted\")\n+      .forEach((el) => el.classList.remove(\"highlighted\"));\n+    localStorage.removeItem(\"sphinx_highlight_terms\")\n+  },\n+\n+  initEscapeListener: () => {\n+    // only install a listener if it is really needed\n+    if (!DOCUMENTATION_OPTIONS.ENABLE_SEARCH_SHORTCUTS) return;\n+\n+    document.addEventListener(\"keydown\", (event) => {\n+      // bail for input elements\n+      if (BLACKLISTED_KEY_CONTROL_ELEMENTS.has(document.activeElement.tagName)) return;\n+      // bail with special keys\n+      if (event.shiftKey || event.altKey || event.ctrlKey || event.metaKey) return;\n+      if (DOCUMENTATION_OPTIONS.ENABLE_SEARCH_SHORTCUTS && (event.key === \"Escape\")) {\n+        SphinxHighlight.hideSearchWords();\n+        event.preventDefault();\n+      }\n+    });\n+  },\n+};\n+\n+_ready(SphinxHighlight.highlightSearchWords);\n+_ready(SphinxHighlight.initEscapeListener);\ndiff --git a/test_svg_nested/_build/genindex.html b/test_svg_nested/_build/genindex.html\nnew file mode 100644\nindex 000000000..ae1eb414b\n--- /dev/null\n+++ b/test_svg_nested/_build/genindex.html\n@@ -0,0 +1,100 @@\n+<!DOCTYPE html>\n+\n+<html lang=\"en\">\n+  <head>\n+    <meta charset=\"utf-8\" />\n+    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n+    <title>Index &#8212; Test  documentation</title>\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"_static/pygments.css?v=d1102ebc\" />\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"_static/alabaster.css?v=12dfc556\" />\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"_static/graphviz.css?v=eafc0fe6\" />\n+    <script data-url_root=\"./\" id=\"documentation_options\" src=\"_static/documentation_options.js?v=b3ba4146\"></script>\n+    <script src=\"_static/doctools.js?v=888ff710\"></script>\n+    <script src=\"_static/sphinx_highlight.js?v=4825356b\"></script>\n+    <link rel=\"index\" title=\"Index\" href=\"#\" />\n+    <link rel=\"search\" title=\"Search\" href=\"search.html\" />\n+   \n+  <link rel=\"stylesheet\" href=\"_static/custom.css\" type=\"text/css\" />\n+  \n+\n+  \n+  \n+\n+  </head><body>\n+  \n+\n+    <div class=\"document\">\n+      <div class=\"documentwrapper\">\n+        <div class=\"bodywrapper\">\n+          \n+\n+          <div class=\"body\" role=\"main\">\n+            \n+\n+<h1 id=\"index\">Index</h1>\n+\n+<div class=\"genindex-jumpbox\">\n+ \n+</div>\n+\n+\n+          </div>\n+          \n+        </div>\n+      </div>\n+      <div class=\"sphinxsidebar\" role=\"navigation\" aria-label=\"main navigation\">\n+        <div class=\"sphinxsidebarwrapper\">\n+<h1 class=\"logo\"><a href=\"index.html\">Test</a></h1>\n+\n+\n+\n+\n+\n+\n+\n+\n+<h3>Navigation</h3>\n+\n+<div class=\"relations\">\n+<h3>Related Topics</h3>\n+<ul>\n+  <li><a href=\"index.html\">Documentation overview</a><ul>\n+  </ul></li>\n+</ul>\n+</div>\n+<div id=\"searchbox\" style=\"display: none\" role=\"search\">\n+  <h3 id=\"searchlabel\">Quick search</h3>\n+    <div class=\"searchformwrapper\">\n+    <form class=\"search\" action=\"search.html\" method=\"get\">\n+      <input type=\"text\" name=\"q\" aria-labelledby=\"searchlabel\" autocomplete=\"off\" autocorrect=\"off\" autocapitalize=\"off\" spellcheck=\"false\"/>\n+      <input type=\"submit\" value=\"Go\" />\n+    </form>\n+    </div>\n+</div>\n+<script>document.getElementById('searchbox').style.display = \"block\"</script>\n+\n+\n+\n+\n+\n+\n+\n+\n+        </div>\n+      </div>\n+      <div class=\"clearer\"></div>\n+    </div>\n+    <div class=\"footer\">\n+      &#169;.\n+      \n+      |\n+      Powered by <a href=\"https://www.sphinx-doc.org/\">Sphinx 7.2.0</a>\n+      &amp; <a href=\"https://alabaster.readthedocs.io\">Alabaster 0.7.16</a>\n+      \n+    </div>\n+\n+    \n+\n+    \n+  </body>\n+</html>\n\\ No newline at end of file\ndiff --git a/test_svg_nested/_build/index.html b/test_svg_nested/_build/index.html\nnew file mode 100644\nindex 000000000..a99d1e8e0\n--- /dev/null\n+++ b/test_svg_nested/_build/index.html\n@@ -0,0 +1,102 @@\n+<!DOCTYPE html>\n+\n+<html lang=\"en\">\n+  <head>\n+    <meta charset=\"utf-8\" />\n+    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n+\n+    <title>Test Root Index &#8212; Test  documentation</title>\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"_static/pygments.css?v=d1102ebc\" />\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"_static/alabaster.css?v=12dfc556\" />\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"_static/graphviz.css?v=eafc0fe6\" />\n+    <script data-url_root=\"./\" id=\"documentation_options\" src=\"_static/documentation_options.js?v=b3ba4146\"></script>\n+    <script src=\"_static/doctools.js?v=888ff710\"></script>\n+    <script src=\"_static/sphinx_highlight.js?v=4825356b\"></script>\n+    <link rel=\"index\" title=\"Index\" href=\"genindex.html\" />\n+    <link rel=\"search\" title=\"Search\" href=\"search.html\" />\n+   \n+  <link rel=\"stylesheet\" href=\"_static/custom.css\" type=\"text/css\" />\n+  \n+\n+  \n+  \n+\n+  </head><body>\n+  \n+\n+    <div class=\"document\">\n+      <div class=\"documentwrapper\">\n+        <div class=\"bodywrapper\">\n+          \n+\n+          <div class=\"body\" role=\"main\">\n+            \n+  <section id=\"test-root-index\">\n+<h1>Test Root Index<a class=\"headerlink\" href=\"#test-root-index\" title=\"Permalink to this heading\">\u00b6</a></h1>\n+<p>This is the root index.</p>\n+</section>\n+\n+\n+          </div>\n+          \n+        </div>\n+      </div>\n+      <div class=\"sphinxsidebar\" role=\"navigation\" aria-label=\"main navigation\">\n+        <div class=\"sphinxsidebarwrapper\">\n+<h1 class=\"logo\"><a href=\"#\">Test</a></h1>\n+\n+\n+\n+\n+\n+\n+\n+\n+<h3>Navigation</h3>\n+\n+<div class=\"relations\">\n+<h3>Related Topics</h3>\n+<ul>\n+  <li><a href=\"#\">Documentation overview</a><ul>\n+  </ul></li>\n+</ul>\n+</div>\n+<div id=\"searchbox\" style=\"display: none\" role=\"search\">\n+  <h3 id=\"searchlabel\">Quick search</h3>\n+    <div class=\"searchformwrapper\">\n+    <form class=\"search\" action=\"search.html\" method=\"get\">\n+      <input type=\"text\" name=\"q\" aria-labelledby=\"searchlabel\" autocomplete=\"off\" autocorrect=\"off\" autocapitalize=\"off\" spellcheck=\"false\"/>\n+      <input type=\"submit\" value=\"Go\" />\n+    </form>\n+    </div>\n+</div>\n+<script>document.getElementById('searchbox').style.display = \"block\"</script>\n+\n+\n+\n+\n+\n+\n+\n+\n+        </div>\n+      </div>\n+      <div class=\"clearer\"></div>\n+    </div>\n+    <div class=\"footer\">\n+      &#169;.\n+      \n+      |\n+      Powered by <a href=\"https://www.sphinx-doc.org/\">Sphinx 7.2.0</a>\n+      &amp; <a href=\"https://alabaster.readthedocs.io\">Alabaster 0.7.16</a>\n+      \n+      |\n+      <a href=\"_sources/index.rst.txt\"\n+          rel=\"nofollow\">Page source</a>\n+    </div>\n+\n+    \n+\n+    \n+  </body>\n+</html>\n\\ No newline at end of file\ndiff --git a/test_svg_nested/_build/objects.inv b/test_svg_nested/_build/objects.inv\nnew file mode 100644\nindex 000000000..c1b517a62\nBinary files /dev/null and b/test_svg_nested/_build/objects.inv differ\ndiff --git a/test_svg_nested/_build/search.html b/test_svg_nested/_build/search.html\nnew file mode 100644\nindex 000000000..fd1a74cf9\n--- /dev/null\n+++ b/test_svg_nested/_build/search.html\n@@ -0,0 +1,119 @@\n+<!DOCTYPE html>\n+\n+<html lang=\"en\">\n+  <head>\n+    <meta charset=\"utf-8\" />\n+    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n+    <title>Search &#8212; Test  documentation</title>\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"_static/pygments.css?v=d1102ebc\" />\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"_static/alabaster.css?v=12dfc556\" />\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"_static/graphviz.css?v=eafc0fe6\" />\n+    \n+    <script data-url_root=\"./\" id=\"documentation_options\" src=\"_static/documentation_options.js?v=b3ba4146\"></script>\n+    <script src=\"_static/doctools.js?v=888ff710\"></script>\n+    <script src=\"_static/sphinx_highlight.js?v=4825356b\"></script>\n+    <script src=\"_static/searchtools.js\"></script>\n+    <script src=\"_static/language_data.js\"></script>\n+    <link rel=\"index\" title=\"Index\" href=\"genindex.html\" />\n+    <link rel=\"search\" title=\"Search\" href=\"#\" />\n+  <script src=\"searchindex.js\" defer></script>\n+  \n+   \n+  <link rel=\"stylesheet\" href=\"_static/custom.css\" type=\"text/css\" />\n+  \n+\n+  \n+  \n+\n+\n+  </head><body>\n+  \n+\n+    <div class=\"document\">\n+      <div class=\"documentwrapper\">\n+        <div class=\"bodywrapper\">\n+          \n+\n+          <div class=\"body\" role=\"main\">\n+            \n+  <h1 id=\"search-documentation\">Search</h1>\n+  \n+  <noscript>\n+  <div class=\"admonition warning\">\n+  <p>\n+    Please activate JavaScript to enable the search\n+    functionality.\n+  </p>\n+  </div>\n+  </noscript>\n+  \n+  \n+  <p>\n+    Searching for multiple words only shows matches that contain\n+    all words.\n+  </p>\n+  \n+  \n+  <form action=\"\" method=\"get\">\n+    <input type=\"text\" name=\"q\" aria-labelledby=\"search-documentation\" value=\"\" autocomplete=\"off\" autocorrect=\"off\" autocapitalize=\"off\" spellcheck=\"false\"/>\n+    <input type=\"submit\" value=\"search\" />\n+    <span id=\"search-progress\" style=\"padding-left: 10px\"></span>\n+  </form>\n+  \n+  \n+  \n+  <div id=\"search-results\">\n+  \n+  </div>\n+  \n+\n+          </div>\n+          \n+        </div>\n+      </div>\n+      <div class=\"sphinxsidebar\" role=\"navigation\" aria-label=\"main navigation\">\n+        <div class=\"sphinxsidebarwrapper\">\n+<h1 class=\"logo\"><a href=\"index.html\">Test</a></h1>\n+\n+\n+\n+\n+\n+\n+\n+\n+<h3>Navigation</h3>\n+\n+<div class=\"relations\">\n+<h3>Related Topics</h3>\n+<ul>\n+  <li><a href=\"index.html\">Documentation overview</a><ul>\n+  </ul></li>\n+</ul>\n+</div>\n+\n+\n+\n+\n+\n+\n+\n+\n+        </div>\n+      </div>\n+      <div class=\"clearer\"></div>\n+    </div>\n+    <div class=\"footer\">\n+      &#169;.\n+      \n+      |\n+      Powered by <a href=\"https://www.sphinx-doc.org/\">Sphinx 7.2.0</a>\n+      &amp; <a href=\"https://alabaster.readthedocs.io\">Alabaster 0.7.16</a>\n+      \n+    </div>\n+\n+    \n+\n+    \n+  </body>\n+</html>\n\\ No newline at end of file\ndiff --git a/test_svg_nested/_build/searchindex.js b/test_svg_nested/_build/searchindex.js\nnew file mode 100644\nindex 000000000..3450f45f5\n--- /dev/null\n+++ b/test_svg_nested/_build/searchindex.js\n@@ -0,0 +1 @@\n+Search.setIndex({\"docnames\": [\"index\", \"subdir/index\"], \"filenames\": [\"index.rst\", \"subdir/index.rst\"], \"titles\": [\"Test Root Index\", \"Subdir Index\"], \"terms\": {\"thi\": [0, 1], \"i\": [0, 1], \"subdirectori\": 1}, \"objects\": {}, \"objtypes\": {}, \"objnames\": {}, \"titleterms\": {\"test\": 0, \"root\": 0, \"index\": [0, 1], \"subdir\": 1}, \"envversion\": {\"sphinx.domains.c\": 3, \"sphinx.domains.changeset\": 1, \"sphinx.domains.citation\": 1, \"sphinx.domains.cpp\": 9, \"sphinx.domains.index\": 1, \"sphinx.domains.javascript\": 3, \"sphinx.domains.math\": 2, \"sphinx.domains.python\": 4, \"sphinx.domains.rst\": 2, \"sphinx.domains.std\": 2, \"sphinx\": 58}, \"alltitles\": {\"Test Root Index\": [[0, \"test-root-index\"]], \"Subdir Index\": [[1, \"subdir-index\"]]}, \"indexentries\": {}})\n\\ No newline at end of file\ndiff --git a/test_svg_nested/_build/subdir/index.html b/test_svg_nested/_build/subdir/index.html\nnew file mode 100644\nindex 000000000..89c22d653\n--- /dev/null\n+++ b/test_svg_nested/_build/subdir/index.html\n@@ -0,0 +1,102 @@\n+<!DOCTYPE html>\n+\n+<html lang=\"en\">\n+  <head>\n+    <meta charset=\"utf-8\" />\n+    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n+\n+    <title>Subdir Index &#8212; Test  documentation</title>\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"../_static/pygments.css?v=d1102ebc\" />\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"../_static/alabaster.css?v=12dfc556\" />\n+    <link rel=\"stylesheet\" type=\"text/css\" href=\"../_static/graphviz.css?v=eafc0fe6\" />\n+    <script data-url_root=\"../\" id=\"documentation_options\" src=\"../_static/documentation_options.js?v=b3ba4146\"></script>\n+    <script src=\"../_static/doctools.js?v=888ff710\"></script>\n+    <script src=\"../_static/sphinx_highlight.js?v=4825356b\"></script>\n+    <link rel=\"index\" title=\"Index\" href=\"../genindex.html\" />\n+    <link rel=\"search\" title=\"Search\" href=\"../search.html\" />\n+   \n+  <link rel=\"stylesheet\" href=\"../_static/custom.css\" type=\"text/css\" />\n+  \n+\n+  \n+  \n+\n+  </head><body>\n+  \n+\n+    <div class=\"document\">\n+      <div class=\"documentwrapper\">\n+        <div class=\"bodywrapper\">\n+          \n+\n+          <div class=\"body\" role=\"main\">\n+            \n+  <section id=\"subdir-index\">\n+<h1>Subdir Index<a class=\"headerlink\" href=\"#subdir-index\" title=\"Permalink to this heading\">\u00b6</a></h1>\n+<p>This is in a subdirectory.</p>\n+</section>\n+\n+\n+          </div>\n+          \n+        </div>\n+      </div>\n+      <div class=\"sphinxsidebar\" role=\"navigation\" aria-label=\"main navigation\">\n+        <div class=\"sphinxsidebarwrapper\">\n+<h1 class=\"logo\"><a href=\"../index.html\">Test</a></h1>\n+\n+\n+\n+\n+\n+\n+\n+\n+<h3>Navigation</h3>\n+\n+<div class=\"relations\">\n+<h3>Related Topics</h3>\n+<ul>\n+  <li><a href=\"../index.html\">Documentation overview</a><ul>\n+  </ul></li>\n+</ul>\n+</div>\n+<div id=\"searchbox\" style=\"display: none\" role=\"search\">\n+  <h3 id=\"searchlabel\">Quick search</h3>\n+    <div class=\"searchformwrapper\">\n+    <form class=\"search\" action=\"../search.html\" method=\"get\">\n+      <input type=\"text\" name=\"q\" aria-labelledby=\"searchlabel\" autocomplete=\"off\" autocorrect=\"off\" autocapitalize=\"off\" spellcheck=\"false\"/>\n+      <input type=\"submit\" value=\"Go\" />\n+    </form>\n+    </div>\n+</div>\n+<script>document.getElementById('searchbox').style.display = \"block\"</script>\n+\n+\n+\n+\n+\n+\n+\n+\n+        </div>\n+      </div>\n+      <div class=\"clearer\"></div>\n+    </div>\n+    <div class=\"footer\">\n+      &#169;.\n+      \n+      |\n+      Powered by <a href=\"https://www.sphinx-doc.org/\">Sphinx 7.2.0</a>\n+      &amp; <a href=\"https://alabaster.readthedocs.io\">Alabaster 0.7.16</a>\n+      \n+      |\n+      <a href=\"../_sources/subdir/index.rst.txt\"\n+          rel=\"nofollow\">Page source</a>\n+    </div>\n+\n+    \n+\n+    \n+  </body>\n+</html>\n\\ No newline at end of file\ndiff --git a/test_svg_nested/conf.py b/test_svg_nested/conf.py\nnew file mode 100644\nindex 000000000..e9c5e386f\n--- /dev/null\n+++ b/test_svg_nested/conf.py\n@@ -0,0 +1,3 @@\n+project = 'Test'\n+extensions = ['sphinx.ext.inheritance_diagram']\n+graphviz_output_format = 'svg'\ndiff --git a/test_svg_nested/index.rst b/test_svg_nested/index.rst\nnew file mode 100644\nindex 000000000..78b073e36\n--- /dev/null\n+++ b/test_svg_nested/index.rst\n@@ -0,0 +1,7 @@\n+============================\n+Test Root Index\n+============================\n+\n+This is the root index.\n+\n+.. inheritance-diagram:: dict str list\ndiff --git a/test_svg_nested/subdir/index.rst b/test_svg_nested/subdir/index.rst\nnew file mode 100644\nindex 000000000..c0a877365\n--- /dev/null\n+++ b/test_svg_nested/subdir/index.rst\n@@ -0,0 +1,7 @@\n+============================\n+Subdir Index\n+============================\n+\n+This is in a subdirectory.\n+\n+.. inheritance-diagram:: dict str list\n"}
{"instance_id": "django__django-13195", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/contrib/messages/storage/cookie.py b/django/contrib/messages/storage/cookie.py\nindex 78256ca3b2..895ec59fbf 100644\n--- a/django/contrib/messages/storage/cookie.py\n+++ b/django/contrib/messages/storage/cookie.py\n@@ -92,7 +92,13 @@ class CookieStorage(BaseStorage):\n                 samesite=settings.SESSION_COOKIE_SAMESITE,\n             )\n         else:\n-            response.delete_cookie(self.cookie_name, domain=settings.SESSION_COOKIE_DOMAIN)\n+            response.delete_cookie(\n+                self.cookie_name,\n+                domain=settings.SESSION_COOKIE_DOMAIN,\n+                samesite=settings.SESSION_COOKIE_SAMESITE,\n+                httponly=settings.SESSION_COOKIE_HTTPONLY or None,\n+                secure=settings.SESSION_COOKIE_SECURE or None,\n+            )\n \n     def _store(self, messages, response, remove_oldest=True, *args, **kwargs):\n         \"\"\"\ndiff --git a/django/contrib/sessions/middleware.py b/django/contrib/sessions/middleware.py\nindex 63013eef7a..87bbf46ee6 100644\n--- a/django/contrib/sessions/middleware.py\n+++ b/django/contrib/sessions/middleware.py\n@@ -42,6 +42,9 @@ class SessionMiddleware(MiddlewareMixin):\n                 settings.SESSION_COOKIE_NAME,\n                 path=settings.SESSION_COOKIE_PATH,\n                 domain=settings.SESSION_COOKIE_DOMAIN,\n+                samesite=settings.SESSION_COOKIE_SAMESITE,\n+                httponly=settings.SESSION_COOKIE_HTTPONLY or None,\n+                secure=settings.SESSION_COOKIE_SECURE or None,\n             )\n             patch_vary_headers(response, ('Cookie',))\n         else:\ndiff --git a/django/http/response.py b/django/http/response.py\nindex e00bcacefb..09d915a3b8 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -210,13 +210,19 @@ class HttpResponseBase:\n         value = signing.get_cookie_signer(salt=key + salt).sign(value)\n         return self.set_cookie(key, value, **kwargs)\n \n-    def delete_cookie(self, key, path='/', domain=None):\n+    def delete_cookie(self, key, path='/', domain=None, samesite=None, httponly=False, secure=False):\n+        \"\"\"\n+        Delete a cookie by setting it with an expiry date in the past.\n+\n+        `samesite` should be one of the values supported by `set_cookie`.\n+        \"\"\"\n         # Most browsers ignore the Set-Cookie header if the cookie name starts\n         # with __Host- or __Secure- and the cookie doesn't use the secure flag.\n-        secure = key.startswith(('__Secure-', '__Host-'))\n+        secure = secure or key.startswith(('__Secure-', '__Host-'))\n         self.set_cookie(\n             key, max_age=0, path=path, domain=domain, secure=secure,\n-            expires='Thu, 01 Jan 1970 00:00:00 GMT',\n+            expires='Thu, 01 Jan 1970 00:00:00 GMT', samesite=samesite,\n+            httponly=httponly,\n         )\n \n     # Common methods used by subclasses\ndiff --git a/docs/ref/request-response.txt b/docs/ref/request-response.txt\nindex 705da1842a..f853bb4ca6 100644\n--- a/docs/ref/request-response.txt\n+++ b/docs/ref/request-response.txt\n@@ -890,14 +890,14 @@ Methods\n \n         Using ``samesite='None'`` (string) was allowed.\n \n-.. method:: HttpResponse.delete_cookie(key, path='/', domain=None)\n+.. method:: HttpResponse.delete_cookie(key, path='/', domain=None, samesite=None, httponly=False, secure=False)\n \n     Deletes the cookie with the given key. Fails silently if the key doesn't\n     exist.\n \n-    Due to the way cookies work, ``path`` and ``domain`` should be the same\n-    values you used in ``set_cookie()`` -- otherwise the cookie may not be\n-    deleted.\n+    Due to the way cookies work, ``path``, ``domain``, ``samesite``, and\n+    ``secure`` should be the same values you used in ``set_cookie()`` --\n+    otherwise the cookie may not be deleted.\n \n .. method:: HttpResponse.close()\n \n"}
{"instance_id": "django__django-12308", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..c27628a134 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -398,6 +398,8 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value)\n     elif isinstance(field, models.FileField) and value:\n         return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+    elif isinstance(field, models.JSONField):\n+        return field.formfield().prepare_value(value)\n     else:\n         return display_for_value(value, empty_value_display)\n \n"}
{"instance_id": "django__django-10999", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/utils/dateparse.py b/django/utils/dateparse.py\nindex 8d08b7d1d3..a037758784 100644\n--- a/django/utils/dateparse.py\n+++ b/django/utils/dateparse.py\n@@ -29,7 +29,7 @@ datetime_re = re.compile(\n standard_duration_re = re.compile(\n     r'^'\n     r'(?:(?P<days>-?\\d+) (days?, )?)?'\n-    r'((?:(?P<hours>-?\\d+):)(?=\\d+:\\d+))?'\n+    r'((?:(?P<hours>-?\\d+):)(?=-?\\d+:-?\\d+))?'\n     r'(?:(?P<minutes>-?\\d+):)?'\n     r'(?P<seconds>-?\\d+)'\n     r'(?:\\.(?P<microseconds>\\d{1,6})\\d{0,6})?'\n"}
{"instance_id": "django__django-11141", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/migrations/loader.py b/django/db/migrations/loader.py\nindex 8c308621d2..d075fcc5df 100644\n--- a/django/db/migrations/loader.py\n+++ b/django/db/migrations/loader.py\n@@ -84,11 +84,6 @@ class MigrationLoader:\n                     continue\n                 raise\n             else:\n-                # Empty directories are namespaces.\n-                # getattr() needed on PY36 and older (replace w/attribute access).\n-                if getattr(module, '__file__', None) is None:\n-                    self.unmigrated_apps.add(app_config.label)\n-                    continue\n                 # Module is not a package (e.g. migrations.py).\n                 if not hasattr(module, '__path__'):\n                     self.unmigrated_apps.add(app_config.label)\n"}
{"instance_id": "pydata__xarray-3993", "model_name_or_path": "devchain", "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 2fef3edb..8d306187 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -3481,21 +3481,24 @@ class DataArray(AbstractArray, DataWithCoords):\n         return self._from_temp_dataset(ds)\n \n     def integrate(\n-        self, dim: Union[Hashable, Sequence[Hashable]], datetime_unit: str = None\n+        self, coord: Union[Hashable, Sequence[Hashable]] = None, datetime_unit: str = None,\n+        dim: Union[Hashable, Sequence[Hashable]] = None\n     ) -> \"DataArray\":\n         \"\"\" integrate the array with the trapezoidal rule.\n \n         .. note::\n-            This feature is limited to simple cartesian geometry, i.e. dim\n+            This feature is limited to simple cartesian geometry, i.e. coord\n             must be one dimensional.\n \n         Parameters\n         ----------\n-        dim : hashable, or sequence of hashable\n+        coord : hashable, or sequence of hashable\n             Coordinate(s) used for the integration.\n         datetime_unit : {\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \\\n                          \"ps\", \"fs\", \"as\"}, optional\n             Can be used to specify the unit if datetime coordinate is used.\n+        dim : hashable, or sequence of hashable\n+            Deprecated, use coord instead.\n \n         Returns\n         -------\n@@ -3528,7 +3531,20 @@ class DataArray(AbstractArray, DataWithCoords):\n         array([5.4, 6.6, 7.8])\n         Dimensions without coordinates: y\n         \"\"\"\n-        ds = self._to_temp_dataset().integrate(dim, datetime_unit)\n+        if dim is not None:\n+            if coord is not None:\n+                raise ValueError(\n+                    \"Cannot specify both 'coord' and 'dim'. \"\n+                    \"'dim' has been deprecated, use 'coord' instead.\"\n+                )\n+            warnings.warn(\n+                \"The 'dim' argument has been renamed to 'coord'. \"\n+                \"In a future version of xarray, 'dim' will be removed.\",\n+                FutureWarning,\n+                stacklevel=2,\n+            )\n+            coord = dim\n+        ds = self._to_temp_dataset().integrate(coord, datetime_unit)\n         return self._from_temp_dataset(ds)\n \n     def unify_chunks(self) -> \"DataArray\":\n"}
{"instance_id": "django__django-15732", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex f2ca8c8df9..a6dbd0425b 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -562,6 +562,11 @@ class BaseDatabaseSchemaEditor:\n         }\n         meta_index_names = {constraint.name for constraint in model._meta.indexes}\n         columns = [model._meta.get_field(field).column for field in fields]\n+        # Exclude primary key constraints when searching for unique constraints,\n+        # since a primary key is also unique but should not be removed when\n+        # dropping unique_together constraints.\n+        if constraint_kwargs.get(\"unique\") and constraint_kwargs.get(\"primary_key\") is None:\n+            constraint_kwargs = {**constraint_kwargs, \"primary_key\": False}\n         constraint_names = self._constraint_names(\n             model,\n             columns,\n"}
{"instance_id": "pylint-dev__pylint-7080", "model_name_or_path": "devchain", "model_patch": "diff --git a/pylint/lint/pylinter.py b/pylint/lint/pylinter.py\nindex e2bbf061e..af72f4dd2 100644\n--- a/pylint/lint/pylinter.py\n+++ b/pylint/lint/pylinter.py\n@@ -775,7 +775,7 @@ class PyLinter(\n             modules,\n             self.config.ignore,\n             self.config.ignore_patterns,\n-            self._ignore_paths,\n+            self.config.ignore_paths,\n         )\n         for error in errors:\n             message = modname = error[\"mod\"]\ndiff --git a/test_recursive/src/__init__.py b/test_recursive/src/__init__.py\nnew file mode 100644\nindex 000000000..e374f7cb9\n--- /dev/null\n+++ b/test_recursive/src/__init__.py\n@@ -0,0 +1 @@\n+print(\"init\")\ndiff --git a/test_recursive/src/gen/__init__.py b/test_recursive/src/gen/__init__.py\nnew file mode 100644\nindex 000000000..cb8a8d892\n--- /dev/null\n+++ b/test_recursive/src/gen/__init__.py\n@@ -0,0 +1 @@\n+print(\"gen init\")\ndiff --git a/test_recursive/src/gen/generated.py b/test_recursive/src/gen/generated.py\nnew file mode 100644\nindex 000000000..bb7ad3601\n--- /dev/null\n+++ b/test_recursive/src/gen/generated.py\n@@ -0,0 +1 @@\n+print(\"generated file\")\ndiff --git a/test_recursive/src/regular.py b/test_recursive/src/regular.py\nnew file mode 100644\nindex 000000000..f9d10ef53\n--- /dev/null\n+++ b/test_recursive/src/regular.py\n@@ -0,0 +1 @@\n+print(\"regular file\")\n"}
{"instance_id": "django__django-11477", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex af0508f94e..247e3680c0 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -153,7 +153,7 @@ class RegexPattern(CheckURLMixin):\n             # If there are any named groups, use those as kwargs, ignoring\n             # non-named groups. Otherwise, pass all non-named arguments as\n             # positional arguments.\n-            kwargs = match.groupdict()\n+            kwargs = {k: v for k, v in match.groupdict().items() if v is not None}\n             args = () if kwargs else match.groups()\n             return path[match.end():], args, kwargs\n         return None\n"}
{"instance_id": "matplotlib__matplotlib-25960", "model_name_or_path": "devchain", "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex dab2bc4a5a..8d5bcf430b 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2274,17 +2274,69 @@ class SubFigure(FigureBase):\n             return\n         # need to figure out *where* this subplotspec is.\n         gs = self._subplotspec.get_gridspec()\n+        nrows, ncols = gs.get_geometry()\n+\n+        # Get wspace and hspace from the gridspec, using 0 if not available\n+        # (for GridSpecFromSubplotSpec which stores them as private attributes)\n+        if hasattr(gs, 'wspace'):\n+            wspace = gs.wspace if gs.wspace is not None else 0\n+        else:\n+            wspace = getattr(gs, '_wspace', None)\n+            wspace = wspace if wspace is not None else 0\n+        if hasattr(gs, 'hspace'):\n+            hspace = gs.hspace if gs.hspace is not None else 0\n+        else:\n+            hspace = getattr(gs, '_hspace', None)\n+            hspace = hspace if hspace is not None else 0\n+\n+        # Calculate positions in raw coordinates (0-1 range) with wspace/hspace\n         wr = np.asarray(gs.get_width_ratios())\n         hr = np.asarray(gs.get_height_ratios())\n-        dx = wr[self._subplotspec.colspan].sum() / wr.sum()\n-        dy = hr[self._subplotspec.rowspan].sum() / hr.sum()\n-        x0 = wr[:self._subplotspec.colspan.start].sum() / wr.sum()\n-        y0 = 1 - hr[:self._subplotspec.rowspan.stop].sum() / hr.sum()\n+\n+        # Calculate cell positions accounting for spacing\n+        # This follows the same logic as GridSpecBase.get_grid_positions\n+        # but uses raw coordinates (0-1 range) with the gridspec's wspace/hspace\n+        left = 0.0\n+        right = 1.0\n+        bottom = 0.0\n+        top = 1.0\n+\n+        tot_width = right - left\n+        tot_height = top - bottom\n+\n+        # Calculate positions with spacing\n+        cell_w = tot_width / (ncols + wspace * (ncols - 1))\n+        sep_w = wspace * cell_w\n+        norm_w = cell_w * ncols / wr.sum()\n+        cell_widths = wr * norm_w\n+        sep_widths = np.concatenate([[0], np.repeat(sep_w, ncols - 1)])\n+        cell_ws = np.cumsum(np.column_stack([sep_widths, cell_widths]).flat)\n+\n+        cell_h = tot_height / (nrows + hspace * (nrows - 1))\n+        sep_h = hspace * cell_h\n+        norm_h = cell_h * nrows / hr.sum()\n+        cell_heights = hr * norm_h\n+        sep_heights = np.concatenate([[0], np.repeat(sep_h, nrows - 1)])\n+        cell_hs = np.cumsum(np.column_stack([sep_heights, cell_heights]).flat)\n+\n+        fig_tops, fig_bottoms = (top - cell_hs).reshape((-1, 2)).T\n+        fig_lefts, fig_rights = (left + cell_ws).reshape((-1, 2)).T\n+\n+        # Get the rows and cols for this subplotspec\n+        rows, cols = np.unravel_index(\n+            [self._subplotspec.num1, self._subplotspec.num2], (nrows, ncols))\n+\n+        fig_bottom = fig_bottoms[rows].min()\n+        fig_top = fig_tops[rows].max()\n+        fig_left = fig_lefts[cols].min()\n+        fig_right = fig_rights[cols].max()\n+\n         if self.bbox_relative is None:\n-            self.bbox_relative = Bbox.from_bounds(x0, y0, dx, dy)\n+            self.bbox_relative = Bbox.from_extents(\n+                fig_left, fig_bottom, fig_right, fig_top)\n         else:\n-            self.bbox_relative.p0 = (x0, y0)\n-            self.bbox_relative.p1 = (x0 + dx, y0 + dy)\n+            self.bbox_relative.p0 = (fig_left, fig_bottom)\n+            self.bbox_relative.p1 = (fig_right, fig_top)\n \n     def get_constrained_layout(self):\n         \"\"\"\n"}
{"instance_id": "scikit-learn__scikit-learn-12973", "model_name_or_path": "devchain", "model_patch": "diff --git a/sklearn/linear_model/least_angle.py b/sklearn/linear_model/least_angle.py\nindex 03b34a0dc..191d99b06 100644\n--- a/sklearn/linear_model/least_angle.py\n+++ b/sklearn/linear_model/least_angle.py\n@@ -1479,7 +1479,7 @@ class LassoLarsIC(LassoLars):\n         self.eps = eps\n         self.fit_path = True\n \n-    def fit(self, X, y, copy_X=True):\n+    def fit(self, X, y, copy_X=None):\n         \"\"\"Fit the model using X, y as training data.\n \n         Parameters\n@@ -1490,8 +1490,9 @@ class LassoLarsIC(LassoLars):\n         y : array-like, shape (n_samples,)\n             target values. Will be cast to X's dtype if necessary\n \n-        copy_X : boolean, optional, default True\n+        copy_X : boolean, optional, default None\n             If ``True``, X will be copied; else, it may be overwritten.\n+            If None, the value set during initialization is used.\n \n         Returns\n         -------\n@@ -1500,8 +1501,11 @@ class LassoLarsIC(LassoLars):\n         \"\"\"\n         X, y = check_X_y(X, y, y_numeric=True)\n \n+        if copy_X is None:\n+            copy_X = self.copy_X\n+\n         X, y, Xmean, ymean, Xstd = LinearModel._preprocess_data(\n-            X, y, self.fit_intercept, self.normalize, self.copy_X)\n+            X, y, self.fit_intercept, self.normalize, copy_X)\n         max_iter = self.max_iter\n \n         Gram = self.precompute\n"}
{"instance_id": "matplotlib__matplotlib-23476", "model_name_or_path": "devchain", "model_patch": "diff --git a/lib/matplotlib/backend_bases.py b/lib/matplotlib/backend_bases.py\nindex 9ae2982c62..99d0eee214 100644\n--- a/lib/matplotlib/backend_bases.py\n+++ b/lib/matplotlib/backend_bases.py\n@@ -1653,7 +1653,8 @@ class FigureCanvasBase:\n         self.toolbar = None  # NavigationToolbar2 will set me\n         self._is_idle_drawing = False\n         # We don't want to scale up the figure DPI more than once.\n-        figure._original_dpi = figure.dpi\n+        if not hasattr(figure, '_original_dpi'):\n+            figure._original_dpi = figure.dpi\n         self._device_pixel_ratio = 1\n         super().__init__()  # Typically the GUI widget init (if any).\n \n"}
{"instance_id": "django__django-12741", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/core/management/commands/flush.py b/django/core/management/commands/flush.py\nindex e8ed3967f7..bc8021cf4e 100644\n--- a/django/core/management/commands/flush.py\n+++ b/django/core/management/commands/flush.py\n@@ -60,7 +60,7 @@ Are you sure you want to do this?\n \n         if confirm == 'yes':\n             try:\n-                connection.ops.execute_sql_flush(database, sql_list)\n+                connection.ops.execute_sql_flush(sql_list)\n             except Exception as exc:\n                 raise CommandError(\n                     \"Database %s couldn't be flushed. Possible reasons:\\n\"\ndiff --git a/django/db/backends/base/operations.py b/django/db/backends/base/operations.py\nindex 70ac07ae09..f07580c18b 100644\n--- a/django/db/backends/base/operations.py\n+++ b/django/db/backends/base/operations.py\n@@ -400,9 +400,9 @@ class BaseDatabaseOperations:\n         \"\"\"\n         raise NotImplementedError('subclasses of BaseDatabaseOperations must provide a sql_flush() method')\n \n-    def execute_sql_flush(self, using, sql_list):\n+    def execute_sql_flush(self, sql_list):\n         \"\"\"Execute a list of SQL statements to flush the database.\"\"\"\n-        with transaction.atomic(using=using, savepoint=self.connection.features.can_rollback_ddl):\n+        with transaction.atomic(using=self.connection.alias, savepoint=self.connection.features.can_rollback_ddl):\n             with self.connection.cursor() as cursor:\n                 for sql in sql_list:\n                     cursor.execute(sql)\n"}
{"instance_id": "django__django-15022", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 66f3396a6b..3e51ae5855 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1031,18 +1031,39 @@ class ModelAdmin(BaseModelAdmin):\n         if search_fields and search_term:\n             orm_lookups = [construct_search(str(search_field))\n                            for search_field in search_fields]\n-            for bit in smart_split(search_term):\n-                if bit.startswith(('\"', \"'\")) and bit[0] == bit[-1]:\n-                    bit = unescape_string_literal(bit)\n-                or_queries = models.Q(\n-                    *((orm_lookup, bit) for orm_lookup in orm_lookups),\n-                    _connector=models.Q.OR,\n-                )\n-                queryset = queryset.filter(or_queries)\n-            may_have_duplicates |= any(\n+            # Check if any lookup spawns duplicates (e.g., m2m relationships)\n+            spawns_dupes = any(\n                 lookup_spawns_duplicates(self.opts, search_spec)\n                 for search_spec in orm_lookups\n             )\n+            if spawns_dupes:\n+                # For lookups that spawn duplicates, use separate filter() calls\n+                # to preserve correct semantics (each search term can match\n+                # a different related row)\n+                for bit in smart_split(search_term):\n+                    if bit.startswith(('\"', \"'\")) and bit[0] == bit[-1]:\n+                        bit = unescape_string_literal(bit)\n+                    or_queries = models.Q(\n+                        *((orm_lookup, bit) for orm_lookup in orm_lookups),\n+                        _connector=models.Q.OR,\n+                    )\n+                    queryset = queryset.filter(or_queries)\n+            else:\n+                # For lookups that don't spawn duplicates (e.g., ForeignKey),\n+                # combine all search terms into a single filter() call to avoid\n+                # creating unnecessary JOINs\n+                search_queries = []\n+                for bit in smart_split(search_term):\n+                    if bit.startswith(('\"', \"'\")) and bit[0] == bit[-1]:\n+                        bit = unescape_string_literal(bit)\n+                    or_queries = models.Q(\n+                        *((orm_lookup, bit) for orm_lookup in orm_lookups),\n+                        _connector=models.Q.OR,\n+                    )\n+                    search_queries.append(or_queries)\n+                if search_queries:\n+                    queryset = queryset.filter(*search_queries)\n+            may_have_duplicates |= spawns_dupes\n         return queryset, may_have_duplicates\n \n     def get_preserved_filters(self, request):\n"}
{"instance_id": "django__django-11087", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 3a462f1c4c..436fb11653 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -234,7 +234,7 @@ class Collector:\n         \"\"\"\n         return related.related_model._base_manager.using(self.using).filter(\n             **{\"%s__in\" % related.field.name: objs}\n-        )\n+        ).only(related.related_model._meta.pk.name)\n \n     def instances_with_model(self):\n         for model, instances in self.data.items():\n"}
{"instance_id": "pylint-dev__pylint-4604", "model_name_or_path": "devchain", "model_patch": "diff --git a/pylint/checkers/variables.py b/pylint/checkers/variables.py\nindex 3ddafd599..a890d3e7c 100644\n--- a/pylint/checkers/variables.py\n+++ b/pylint/checkers/variables.py\n@@ -1826,21 +1826,26 @@ class VariablesChecker(BaseChecker):\n             self._type_annotation_names.append(type_annotation.name)\n             return\n \n-        if not isinstance(type_annotation, astroid.Subscript):\n-            return\n+        if isinstance(type_annotation, astroid.Subscript):\n+            if (\n+                isinstance(type_annotation.value, astroid.Attribute)\n+                and isinstance(type_annotation.value.expr, astroid.Name)\n+                and type_annotation.value.expr.name == TYPING_MODULE\n+            ):\n+                self._type_annotation_names.append(TYPING_MODULE)\n+                return\n \n-        if (\n-            isinstance(type_annotation.value, astroid.Attribute)\n-            and isinstance(type_annotation.value.expr, astroid.Name)\n-            and type_annotation.value.expr.name == TYPING_MODULE\n-        ):\n-            self._type_annotation_names.append(TYPING_MODULE)\n+            self._type_annotation_names.extend(\n+                annotation.name\n+                for annotation in type_annotation.nodes_of_class(astroid.Name)\n+            )\n             return\n \n-        self._type_annotation_names.extend(\n-            annotation.name\n-            for annotation in type_annotation.nodes_of_class(astroid.Name)\n-        )\n+        if isinstance(type_annotation, astroid.Attribute):\n+            self._type_annotation_names.extend(\n+                annotation.name\n+                for annotation in type_annotation.nodes_of_class(astroid.Name)\n+            )\n \n     def _store_type_annotation_names(self, node):\n         type_annotation = node.type_annotation\n"}
{"instance_id": "django__django-15252", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1a37c6b7d0..0adc655ff9 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -1,5 +1,5 @@\n from django.apps.registry import Apps\n-from django.db import DatabaseError, models\n+from django.db import DatabaseError, models, router\n from django.utils.functional import classproperty\n from django.utils.timezone import now\n \n@@ -62,6 +62,12 @@ class MigrationRecorder:\n         # in the codebase.\n         if self.has_table():\n             return\n+        # Check if migrations are allowed for this database\n+        if not router.allow_migrate(\n+            self.connection.alias,\n+            self.Migration._meta.app_label,\n+        ):\n+            return\n         # Make the table\n         try:\n             with self.connection.schema_editor() as editor:\n@@ -83,11 +89,23 @@ class MigrationRecorder:\n \n     def record_applied(self, app, name):\n         \"\"\"Record that a migration was applied.\"\"\"\n+        # If migrations are not allowed for this database, do nothing.\n+        if not router.allow_migrate(\n+            self.connection.alias,\n+            self.Migration._meta.app_label,\n+        ):\n+            return\n         self.ensure_schema()\n         self.migration_qs.create(app=app, name=name)\n \n     def record_unapplied(self, app, name):\n         \"\"\"Record that a migration was unapplied.\"\"\"\n+        # If migrations are not allowed for this database, do nothing.\n+        if not router.allow_migrate(\n+            self.connection.alias,\n+            self.Migration._meta.app_label,\n+        ):\n+            return\n         self.ensure_schema()\n         self.migration_qs.filter(app=app, name=name).delete()\n \n"}
{"instance_id": "matplotlib__matplotlib-21568", "model_name_or_path": "devchain", "model_patch": "diff --git a/lib/matplotlib/dates.py b/lib/matplotlib/dates.py\nindex 0766156d64..ac3be8e58b 100644\n--- a/lib/matplotlib/dates.py\n+++ b/lib/matplotlib/dates.py\n@@ -595,8 +595,9 @@ def _wrap_in_tex(text):\n     p = r'([a-zA-Z]+)'\n     ret_text = re.sub(p, r'}$\\1$\\\\mathdefault{', text)\n \n-    # Braces ensure dashes are not spaced like binary operators.\n-    ret_text = '$\\\\mathdefault{'+ret_text.replace('-', '{-}')+'}$'\n+    # Braces ensure symbols are not spaced like binary operators.\n+    ret_text = ret_text.replace('-', '{-}').replace(':', '{:}').replace(' ', r'\\;')\n+    ret_text = '$\\\\mathdefault{' + ret_text + '}$'\n     ret_text = ret_text.replace('$\\\\mathdefault{}$', '')\n     return ret_text\n \n"}
{"instance_id": "sympy__sympy-13877", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/core/exprtools.py b/sympy/core/exprtools.py\nindex 4e0de9ec18..66bc0eb154 100644\n--- a/sympy/core/exprtools.py\n+++ b/sympy/core/exprtools.py\n@@ -1176,7 +1176,10 @@ def do(expr):\n         if p.is_Add:\n             list_args = [do(a) for a in Add.make_args(p)]\n             # get a common negative (if there) which gcd_terms does not remove\n-            if all(a.as_coeff_Mul()[0] < 0 for a in list_args):\n+            def _is_negative_coeff(a):\n+                c = a.as_coeff_Mul()[0]\n+                return c is not S.NaN and c < 0\n+            if all(_is_negative_coeff(a) for a in list_args):\n                 cont = -cont\n                 list_args = [-a for a in list_args]\n             # watch out for exp(-(x+2)) which gcd_terms will change to exp(-x-2)\n"}
{"instance_id": "sympy__sympy-17630", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 95302a05ca..522c62487b 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -164,7 +164,21 @@ def structurally_equal(self, other):\n     def _blockmul(self, other):\n         if (isinstance(other, BlockMatrix) and\n                 self.colblocksizes == other.rowblocksizes):\n-            return BlockMatrix(self.blocks*other.blocks)\n+            blocks = self.blocks*other.blocks\n+            # Replace Zero objects with ZeroMatrix of appropriate dimensions\n+            # to maintain block matrix structure\n+            from sympy.core.numbers import Zero\n+            new_blocks = []\n+            for i in range(blocks.shape[0]):\n+                row = []\n+                for j in range(blocks.shape[1]):\n+                    if isinstance(blocks[i, j], Zero):\n+                        row.append(ZeroMatrix(self.rowblocksizes[i],\n+                                              other.colblocksizes[j]))\n+                    else:\n+                        row.append(blocks[i, j])\n+                new_blocks.append(row)\n+            return BlockMatrix(new_blocks)\n \n         return self * other\n \n"}
{"instance_id": "sympy__sympy-18698", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex c9e77a901f..287f5e3f7a 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -5950,6 +5950,32 @@ def _symbolic_factor_list(expr, opt, method):\n \n                 factors.append((_factors_product(other), exp))\n \n+    # For square-free factorization, combine factors with the same multiplicity > 1\n+    if method == 'sqf' and factors:\n+        from collections import defaultdict\n+        grouped_gt1 = defaultdict(list)\n+        factors_eq1 = []\n+        for f, k in factors:\n+            if k == 1:\n+                # Keep multiplicity 1 factors as they are (they're already square-free)\n+                factors_eq1.append((f, k))\n+            else:\n+                # Group by multiplicity for k > 1\n+                grouped_gt1[k].append(f)\n+\n+        # Rebuild factors list with combined factors for multiplicities > 1\n+        factors = factors_eq1  # Start with multiplicity 1 factors\n+        for k in sorted(grouped_gt1.keys()):\n+            group = grouped_gt1[k]\n+            if len(group) == 1:\n+                factors.append((group[0], k))\n+            else:\n+                # Multiply all factors in this group\n+                result = group[0]\n+                for f in group[1:]:\n+                    result = result.mul(f) if hasattr(result, 'mul') else result * f\n+                factors.append((result, k))\n+\n     return coeff, factors\n \n \n"}
{"instance_id": "django__django-13401", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 28374272f4..bec7a11cc6 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -516,17 +516,32 @@ class Field(RegisterLookupMixin):\n     def __eq__(self, other):\n         # Needed for @total_ordering\n         if isinstance(other, Field):\n-            return self.creation_counter == other.creation_counter\n+            return (self.creation_counter == other.creation_counter and\n+                    getattr(self, 'model', None) == getattr(other, 'model', None))\n         return NotImplemented\n \n     def __lt__(self, other):\n         # This is needed because bisect does not take a comparison function.\n         if isinstance(other, Field):\n-            return self.creation_counter < other.creation_counter\n+            # Order by creation_counter first to preserve the original ordering\n+            # for fields of the same model, then by model to distinguish fields\n+            # from different models. Use model._meta.label_lower for comparison\n+            # to avoid TypeError when comparing model classes directly.\n+            if self.creation_counter != other.creation_counter:\n+                return self.creation_counter < other.creation_counter\n+            self_model = getattr(self, 'model', None)\n+            other_model = getattr(other, 'model', None)\n+            if self_model is None and other_model is None:\n+                return False\n+            if self_model is None:\n+                return True\n+            if other_model is None:\n+                return False\n+            return (self_model._meta.label_lower < other_model._meta.label_lower)\n         return NotImplemented\n \n     def __hash__(self):\n-        return hash(self.creation_counter)\n+        return hash((self.creation_counter, getattr(self, 'model', None)))\n \n     def __deepcopy__(self, memodict):\n         # We don't have to deepcopy very much here, since most things are not\n"}
{"instance_id": "astropy__astropy-14369", "model_name_or_path": "devchain", "model_patch": "diff --git a/astropy/units/format/cds.py b/astropy/units/format/cds.py\nindex 307e987ed6..89888f120e 100644\n--- a/astropy/units/format/cds.py\n+++ b/astropy/units/format/cds.py\n@@ -172,22 +172,38 @@ class CDS(Base):\n         def p_product_of_units(p):\n             \"\"\"\n             product_of_units : unit_expression PRODUCT combined_units\n+                             | unit_expression DIVISION division_sequence\n                              | unit_expression\n             \"\"\"\n             if len(p) == 4:\n-                p[0] = p[1] * p[3]\n+                if isinstance(p[2], str) and p[2] == '.':\n+                    # unit_expression . combined_units -> multiplication\n+                    p[0] = p[1] * p[3]\n+                else:\n+                    # unit_expression / division_sequence -> division\n+                    p[0] = p[1] / p[3]\n             else:\n                 p[0] = p[1]\n \n         def p_division_of_units(p):\n             \"\"\"\n-            division_of_units : DIVISION unit_expression\n-                              | unit_expression DIVISION combined_units\n+            division_of_units : DIVISION division_sequence\n             \"\"\"\n-            if len(p) == 3:\n-                p[0] = p[2] ** -1\n+            # Leading division: / division_sequence -> 1 / division_sequence\n+            p[0] = p[2] ** -1\n+\n+        def p_division_sequence(p):\n+            \"\"\"\n+            division_sequence : unit_expression DIVISION division_sequence\n+                             | unit_expression\n+            \"\"\"\n+            if len(p) == 4:\n+                # unit_expression DIVISION division_sequence\n+                # Accumulate units in the denominator\n+                p[0] = p[1] * p[3]\n             else:\n-                p[0] = p[1] / p[3]\n+                # unit_expression (single unit)\n+                p[0] = p[1]\n \n         def p_unit_expression(p):\n             \"\"\"\ndiff --git a/astropy/units/format/cds_parsetab.py b/astropy/units/format/cds_parsetab.py\nindex 741d41643c..ab9d2d3ce1 100644\n--- a/astropy/units/format/cds_parsetab.py\n+++ b/astropy/units/format/cds_parsetab.py\n@@ -17,9 +17,9 @@ _tabversion = '3.10'\n \n _lr_method = 'LALR'\n \n-_lr_signature = 'CLOSE_BRACKET CLOSE_PAREN DIMENSIONLESS DIVISION OPEN_BRACKET OPEN_PAREN PRODUCT SIGN UFLOAT UINT UNIT X\\n            main : factor combined_units\\n                 | combined_units\\n                 | DIMENSIONLESS\\n                 | OPEN_BRACKET combined_units CLOSE_BRACKET\\n                 | OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET\\n                 | factor\\n            \\n            combined_units : product_of_units\\n                           | division_of_units\\n            \\n            product_of_units : unit_expression PRODUCT combined_units\\n                             | unit_expression\\n            \\n            division_of_units : DIVISION unit_expression\\n                              | unit_expression DIVISION combined_units\\n            \\n            unit_expression : unit_with_power\\n                            | OPEN_PAREN combined_units CLOSE_PAREN\\n            \\n            factor : signed_float X UINT signed_int\\n                   | UINT X UINT signed_int\\n                   | UINT signed_int\\n                   | UINT\\n                   | signed_float\\n            \\n            unit_with_power : UNIT numeric_power\\n                            | UNIT\\n            \\n            numeric_power : sign UINT\\n            \\n            sign : SIGN\\n                 |\\n            \\n            signed_int : SIGN UINT\\n            \\n            signed_float : sign UINT\\n                         | sign UFLOAT\\n            '\n+_lr_signature = 'CLOSE_BRACKET CLOSE_PAREN DIMENSIONLESS DIVISION OPEN_BRACKET OPEN_PAREN PRODUCT SIGN UFLOAT UINT UNIT X\\n            main : factor combined_units\\n                 | combined_units\\n                 | DIMENSIONLESS\\n                 | OPEN_BRACKET combined_units CLOSE_BRACKET\\n                 | OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET\\n                 | factor\\n            \\n            combined_units : product_of_units\\n                           | division_of_units\\n            \\n            product_of_units : unit_expression PRODUCT combined_units\\n                             | unit_expression DIVISION division_sequence\\n                             | unit_expression\\n            \\n            division_of_units : DIVISION division_sequence\\n            \\n            division_sequence : unit_expression DIVISION division_sequence\\n                             | unit_expression\\n            \\n            unit_expression : unit_with_power\\n                            | OPEN_PAREN combined_units CLOSE_PAREN\\n            \\n            factor : signed_float X UINT signed_int\\n                   | UINT X UINT signed_int\\n                   | UINT signed_int\\n                   | UINT\\n                   | signed_float\\n            \\n            unit_with_power : UNIT numeric_power\\n                            | UNIT\\n            \\n            numeric_power : sign UINT\\n            \\n            sign : SIGN\\n                 |\\n            \\n            signed_int : SIGN UINT\\n            \\n            signed_float : sign UINT\\n                         | sign UFLOAT\\n            '\n     \n-_lr_action_items = {'DIMENSIONLESS':([0,5,],[4,19,]),'OPEN_BRACKET':([0,],[5,]),'UINT':([0,10,13,16,20,21,23,31,],[7,24,-23,-24,34,35,36,40,]),'DIVISION':([0,2,5,6,7,11,14,15,16,22,24,25,26,27,30,36,39,40,41,42,],[12,12,12,-19,-18,27,-13,12,-21,-17,-26,-27,12,12,-20,-25,-14,-22,-15,-16,]),'SIGN':([0,7,16,34,35,],[13,23,13,23,23,]),'UFLOAT':([0,10,13,],[-24,25,-23,]),'OPEN_PAREN':([0,2,5,6,7,12,15,22,24,25,26,27,36,41,42,],[15,15,15,-19,-18,15,15,-17,-26,-27,15,15,-25,-15,-16,]),'UNIT':([0,2,5,6,7,12,15,22,24,25,26,27,36,41,42,],[16,16,16,-19,-18,16,16,-17,-26,-27,16,16,-25,-15,-16,]),'$end':([1,2,3,4,6,7,8,9,11,14,16,17,22,24,25,28,30,32,33,36,37,38,39,40,41,42,],[0,-6,-2,-3,-19,-18,-7,-8,-10,-13,-21,-1,-17,-26,-27,-11,-20,-4,-5,-25,-9,-12,-14,-22,-15,-16,]),'X':([6,7,24,25,],[20,21,-26,-27,]),'CLOSE_BRACKET':([8,9,11,14,16,18,19,28,30,37,38,39,40,],[-7,-8,-10,-13,-21,32,33,-11,-20,-9,-12,-14,-22,]),'CLOSE_PAREN':([8,9,11,14,16,28,29,30,37,38,39,40,],[-7,-8,-10,-13,-21,-11,39,-20,-9,-12,-14,-22,]),'PRODUCT':([11,14,16,30,39,40,],[26,-13,-21,-20,-14,-22,]),}\n+_lr_action_items = {'DIMENSIONLESS':([0,5,],[4,19,]),'OPEN_BRACKET':([0,],[5,]),'UINT':([0,10,13,16,20,21,23,32,],[7,24,-25,-26,35,36,37,42,]),'DIVISION':([0,2,5,6,7,11,14,15,16,22,24,25,26,29,31,37,41,42,43,44,],[12,12,12,-21,-20,27,-15,12,-23,-19,-28,-29,12,40,-22,-27,-16,-24,-17,-18,]),'SIGN':([0,7,16,35,36,],[13,23,13,23,23,]),'UFLOAT':([0,10,13,],[-26,25,-25,]),'OPEN_PAREN':([0,2,5,6,7,12,15,22,24,25,26,27,37,40,43,44,],[15,15,15,-21,-20,15,15,-19,-28,-29,15,15,-27,15,-17,-18,]),'UNIT':([0,2,5,6,7,12,15,22,24,25,26,27,37,40,43,44,],[16,16,16,-21,-20,16,16,-19,-28,-29,16,16,-27,16,-17,-18,]),'$end':([1,2,3,4,6,7,8,9,11,14,16,17,22,24,25,28,29,31,33,34,37,38,39,41,42,43,44,45,],[0,-6,-2,-3,-21,-20,-7,-8,-11,-15,-23,-1,-19,-28,-29,-12,-14,-22,-4,-5,-27,-9,-10,-16,-24,-17,-18,-13,]),'X':([6,7,24,25,],[20,21,-28,-29,]),'CLOSE_BRACKET':([8,9,11,14,16,18,19,28,29,31,38,39,41,42,45,],[-7,-8,-11,-15,-23,33,34,-12,-14,-22,-9,-10,-16,-24,-13,]),'CLOSE_PAREN':([8,9,11,14,16,28,29,30,31,38,39,41,42,45,],[-7,-8,-11,-15,-23,-12,-14,41,-22,-9,-10,-16,-24,-13,]),'PRODUCT':([11,14,16,31,41,42,],[26,-15,-23,-22,-16,-24,]),}\n \n _lr_action = {}\n for _k, _v in _lr_action_items.items():\n@@ -28,7 +28,7 @@ for _k, _v in _lr_action_items.items():\n       _lr_action[_x][_k] = _y\n del _lr_action_items\n \n-_lr_goto_items = {'main':([0,],[1,]),'factor':([0,],[2,]),'combined_units':([0,2,5,15,26,27,],[3,17,18,29,37,38,]),'signed_float':([0,],[6,]),'product_of_units':([0,2,5,15,26,27,],[8,8,8,8,8,8,]),'division_of_units':([0,2,5,15,26,27,],[9,9,9,9,9,9,]),'sign':([0,16,],[10,31,]),'unit_expression':([0,2,5,12,15,26,27,],[11,11,11,28,11,11,11,]),'unit_with_power':([0,2,5,12,15,26,27,],[14,14,14,14,14,14,14,]),'signed_int':([7,34,35,],[22,41,42,]),'numeric_power':([16,],[30,]),}\n+_lr_goto_items = {'main':([0,],[1,]),'factor':([0,],[2,]),'combined_units':([0,2,5,15,26,],[3,17,18,30,38,]),'signed_float':([0,],[6,]),'product_of_units':([0,2,5,15,26,],[8,8,8,8,8,]),'division_of_units':([0,2,5,15,26,],[9,9,9,9,9,]),'sign':([0,16,],[10,32,]),'unit_expression':([0,2,5,12,15,26,27,40,],[11,11,11,29,11,11,29,29,]),'unit_with_power':([0,2,5,12,15,26,27,40,],[14,14,14,14,14,14,14,14,]),'signed_int':([7,35,36,],[22,43,44,]),'division_sequence':([12,27,40,],[28,39,45,]),'numeric_power':([16,],[31,]),}\n \n _lr_goto = {}\n for _k, _v in _lr_goto_items.items():\n@@ -38,31 +38,33 @@ for _k, _v in _lr_goto_items.items():\n del _lr_goto_items\n _lr_productions = [\n   (\"S' -> main\",\"S'\",1,None,None,None),\n-  ('main -> factor combined_units','main',2,'p_main','cds.py',156),\n-  ('main -> combined_units','main',1,'p_main','cds.py',157),\n-  ('main -> DIMENSIONLESS','main',1,'p_main','cds.py',158),\n-  ('main -> OPEN_BRACKET combined_units CLOSE_BRACKET','main',3,'p_main','cds.py',159),\n-  ('main -> OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET','main',3,'p_main','cds.py',160),\n-  ('main -> factor','main',1,'p_main','cds.py',161),\n-  ('combined_units -> product_of_units','combined_units',1,'p_combined_units','cds.py',174),\n-  ('combined_units -> division_of_units','combined_units',1,'p_combined_units','cds.py',175),\n-  ('product_of_units -> unit_expression PRODUCT combined_units','product_of_units',3,'p_product_of_units','cds.py',181),\n-  ('product_of_units -> unit_expression','product_of_units',1,'p_product_of_units','cds.py',182),\n-  ('division_of_units -> DIVISION unit_expression','division_of_units',2,'p_division_of_units','cds.py',191),\n-  ('division_of_units -> unit_expression DIVISION combined_units','division_of_units',3,'p_division_of_units','cds.py',192),\n-  ('unit_expression -> unit_with_power','unit_expression',1,'p_unit_expression','cds.py',201),\n-  ('unit_expression -> OPEN_PAREN combined_units CLOSE_PAREN','unit_expression',3,'p_unit_expression','cds.py',202),\n-  ('factor -> signed_float X UINT signed_int','factor',4,'p_factor','cds.py',211),\n-  ('factor -> UINT X UINT signed_int','factor',4,'p_factor','cds.py',212),\n-  ('factor -> UINT signed_int','factor',2,'p_factor','cds.py',213),\n-  ('factor -> UINT','factor',1,'p_factor','cds.py',214),\n-  ('factor -> signed_float','factor',1,'p_factor','cds.py',215),\n-  ('unit_with_power -> UNIT numeric_power','unit_with_power',2,'p_unit_with_power','cds.py',232),\n-  ('unit_with_power -> UNIT','unit_with_power',1,'p_unit_with_power','cds.py',233),\n-  ('numeric_power -> sign UINT','numeric_power',2,'p_numeric_power','cds.py',242),\n-  ('sign -> SIGN','sign',1,'p_sign','cds.py',248),\n-  ('sign -> <empty>','sign',0,'p_sign','cds.py',249),\n-  ('signed_int -> SIGN UINT','signed_int',2,'p_signed_int','cds.py',258),\n-  ('signed_float -> sign UINT','signed_float',2,'p_signed_float','cds.py',264),\n-  ('signed_float -> sign UFLOAT','signed_float',2,'p_signed_float','cds.py',265),\n+  ('main -> factor combined_units','main',2,'p_main','cds.py',148),\n+  ('main -> combined_units','main',1,'p_main','cds.py',149),\n+  ('main -> DIMENSIONLESS','main',1,'p_main','cds.py',150),\n+  ('main -> OPEN_BRACKET combined_units CLOSE_BRACKET','main',3,'p_main','cds.py',151),\n+  ('main -> OPEN_BRACKET DIMENSIONLESS CLOSE_BRACKET','main',3,'p_main','cds.py',152),\n+  ('main -> factor','main',1,'p_main','cds.py',153),\n+  ('combined_units -> product_of_units','combined_units',1,'p_combined_units','cds.py',167),\n+  ('combined_units -> division_of_units','combined_units',1,'p_combined_units','cds.py',168),\n+  ('product_of_units -> unit_expression PRODUCT combined_units','product_of_units',3,'p_product_of_units','cds.py',174),\n+  ('product_of_units -> unit_expression DIVISION division_sequence','product_of_units',3,'p_product_of_units','cds.py',175),\n+  ('product_of_units -> unit_expression','product_of_units',1,'p_product_of_units','cds.py',176),\n+  ('division_of_units -> DIVISION division_sequence','division_of_units',2,'p_division_of_units','cds.py',190),\n+  ('division_sequence -> unit_expression DIVISION division_sequence','division_sequence',3,'p_division_sequence','cds.py',197),\n+  ('division_sequence -> unit_expression','division_sequence',1,'p_division_sequence','cds.py',198),\n+  ('unit_expression -> unit_with_power','unit_expression',1,'p_unit_expression','cds.py',210),\n+  ('unit_expression -> OPEN_PAREN combined_units CLOSE_PAREN','unit_expression',3,'p_unit_expression','cds.py',211),\n+  ('factor -> signed_float X UINT signed_int','factor',4,'p_factor','cds.py',220),\n+  ('factor -> UINT X UINT signed_int','factor',4,'p_factor','cds.py',221),\n+  ('factor -> UINT signed_int','factor',2,'p_factor','cds.py',222),\n+  ('factor -> UINT','factor',1,'p_factor','cds.py',223),\n+  ('factor -> signed_float','factor',1,'p_factor','cds.py',224),\n+  ('unit_with_power -> UNIT numeric_power','unit_with_power',2,'p_unit_with_power','cds.py',239),\n+  ('unit_with_power -> UNIT','unit_with_power',1,'p_unit_with_power','cds.py',240),\n+  ('numeric_power -> sign UINT','numeric_power',2,'p_numeric_power','cds.py',249),\n+  ('sign -> SIGN','sign',1,'p_sign','cds.py',255),\n+  ('sign -> <empty>','sign',0,'p_sign','cds.py',256),\n+  ('signed_int -> SIGN UINT','signed_int',2,'p_signed_int','cds.py',265),\n+  ('signed_float -> sign UINT','signed_float',2,'p_signed_float','cds.py',271),\n+  ('signed_float -> sign UFLOAT','signed_float',2,'p_signed_float','cds.py',272),\n ]\n"}
{"instance_id": "django__django-12325", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 8ea6c05ef9..2498eeb545 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -204,7 +204,11 @@ class ModelBase(type):\n             for field in base._meta.local_fields:\n                 if isinstance(field, OneToOneField):\n                     related = resolve_relation(new_class, field.remote_field.model)\n-                    parent_links[make_model_tuple(related)] = field\n+                    key = make_model_tuple(related)\n+                    # Prefer fields with parent_link=True when there are\n+                    # multiple OneToOneFields to the same parent.\n+                    if key not in parent_links or field.remote_field.parent_link:\n+                        parent_links[key] = field\n \n         # Track fields inherited from base models.\n         inherited_attributes = set()\ndiff --git a/test_settings.py b/test_settings.py\nnew file mode 100644\nindex 0000000000..9782119717\n--- /dev/null\n+++ b/test_settings.py\n@@ -0,0 +1,5 @@\n+\n+SECRET_KEY = 'test'\n+INSTALLED_APPS = []\n+DATABASES = {'default': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': ':memory:'}}\n+USE_TZ = True\n"}
{"instance_id": "pylint-dev__pylint-7277", "model_name_or_path": "devchain", "model_patch": "diff --git a/pylint/__init__.py b/pylint/__init__.py\nindex 9f3dd74e6..044045cfb 100644\n--- a/pylint/__init__.py\n+++ b/pylint/__init__.py\n@@ -86,8 +86,8 @@ def modify_sys_path() -> None:\n     stdlib or pylint's own modules.\n     CPython issue: https://bugs.python.org/issue33053\n \n-    - Remove the first entry. This will always be either \"\" or the working directory\n-    - Remove the working directory from the second and third entries\n+    - Remove the first entry if it is \"\", \".\" or the working directory.\n+    - Remove any additional \"\" or \".\" entries that would be added\n       if PYTHONPATH includes a \":\" at the beginning or the end.\n       https://github.com/PyCQA/pylint/issues/3636\n       Don't remove it if PYTHONPATH contains the cwd or '.' as the entry will\n@@ -96,13 +96,42 @@ def modify_sys_path() -> None:\n       if pylint is installed in an editable configuration (as the last item).\n       https://github.com/PyCQA/pylint/issues/4161\n     \"\"\"\n-    sys.path.pop(0)\n-    env_pythonpath = os.environ.get(\"PYTHONPATH\", \"\")\n     cwd = os.getcwd()\n-    if env_pythonpath.startswith(\":\") and env_pythonpath not in (f\":{cwd}\", \":.\"):\n+    env_pythonpath = os.environ.get(\"PYTHONPATH\", \"\")\n+\n+    # Remove the first entry only if it's the current working directory indicator\n+    first_was_removed = False\n+    if sys.path and sys.path[0] in (\"\", \".\", cwd):\n         sys.path.pop(0)\n+        first_was_removed = True\n+\n+    # Handle additional cwd entries that PYTHONPATH might add\n+    # (when PYTHONPATH starts or ends with \":\")\n+    if env_pythonpath.startswith(\":\") and env_pythonpath not in (f\":{cwd}\", \":.\"):\n+        # PYTHONPATH starting with \":\" adds an empty string at the start.\n+        # Remove empty strings from the appropriate position.\n+        if first_was_removed:\n+            # First element was removed, empty strings are now at the front\n+            for _ in range(2):\n+                if sys.path and sys.path[0] in (\"\", \".\", cwd):\n+                    sys.path.pop(0)\n+                else:\n+                    break\n+        else:\n+            # First element was preserved (custom path), empty strings start at position 1\n+            for _ in range(2):\n+                if len(sys.path) > 1 and sys.path[1] in (\"\", \".\", cwd):\n+                    sys.path.pop(1)\n+                else:\n+                    break\n     elif env_pythonpath.endswith(\":\") and env_pythonpath not in (f\"{cwd}:\", \".:\"):\n-        sys.path.pop(1)\n+        # PYTHONPATH ending with \":\" adds an empty string after the first entry.\n+        # Remove empty strings from position 1 (up to 2 total).\n+        for _ in range(2):\n+            if len(sys.path) > 1 and sys.path[1] in (\"\", \".\", cwd):\n+                sys.path.pop(1)\n+            else:\n+                break\n \n \n version = __version__\n"}
{"instance_id": "pylint-dev__pylint-4551", "model_name_or_path": "devchain", "model_patch": "diff --git a/pylint/pyreverse/inspector.py b/pylint/pyreverse/inspector.py\nindex 8fa122022..7d9d28e28 100644\n--- a/pylint/pyreverse/inspector.py\n+++ b/pylint/pyreverse/inspector.py\n@@ -166,6 +166,10 @@ class Linker(IdGeneratorMixIn, utils.LocalsVisitor):\n             for assignattr in assignattrs:\n                 if not isinstance(assignattr, astroid.Unknown):\n                     self.handle_assignattr_type(assignattr, node)\n+        # handle type annotations (AnnAssign nodes)\n+        for child in node.body:\n+            if isinstance(child, astroid.AnnAssign):\n+                self.visit_annassign(child)\n         # resolve implemented interface\n         try:\n             node.implements = list(interfaces(node, self.inherited_interfaces))\n@@ -236,6 +240,82 @@ class Linker(IdGeneratorMixIn, utils.LocalsVisitor):\n         except astroid.InferenceError:\n             pass\n \n+        # Check if the assigned value has a type annotation in the function parameters\n+        # This handles cases like: self.a = a where 'a' has a type annotation\n+        try:\n+            # Get the parent Assign node which contains the assigned value\n+            assign_node = node.parent\n+            if isinstance(assign_node, astroid.Assign) and isinstance(assign_node.value, astroid.Name):\n+                assigned_name = assign_node.value.name\n+                # Check if this is inside a function\n+                frame = assign_node.frame()\n+                if isinstance(frame, astroid.FunctionDef):\n+                    args = frame.args\n+                    if args:\n+                        # Find the index of this parameter\n+                        for i, arg in enumerate(args.args):\n+                            if arg.name == assigned_name:\n+                                # Check if there's a type annotation for this parameter\n+                                if i < len(args.annotations) and args.annotations[i] is not None:\n+                                    annotation = args.annotations[i]\n+                                    # Infer the type from the annotation\n+                                    try:\n+                                        types = set()\n+                                        for inferred in annotation.infer():\n+                                            if inferred is not astroid.Uninferable:\n+                                                types.add(inferred)\n+                                        if types:\n+                                            current = set(parent.instance_attrs_type[node.attrname])\n+                                            parent.instance_attrs_type[node.attrname] = list(current | types)\n+                                    except astroid.InferenceError:\n+                                        pass\n+                                break\n+        except (AttributeError, IndexError, astroid.InferenceError):\n+            pass\n+\n+    def visit_annassign(self, node):\n+        \"\"\"visit an astroid.AnnAssign node and handle type annotations.\"\"\"\n+        # Get the frame (class) containing this annotation\n+        frame = node.frame()\n+        if not isinstance(frame, astroid.ClassDef):\n+            return\n+\n+        # Ensure the class has been visited and has instance_attrs_type\n+        if not hasattr(frame, \"instance_attrs_type\"):\n+            self.visit_classdef(frame)\n+\n+        # Extract the variable name from the annotation target\n+        target = node.target\n+        # Determine the type dictionary to use and the attribute name\n+        if isinstance(target, astroid.AssignName):\n+            # Class-level annotation like: a: str\n+            # Store in locals_type\n+            name = target.name\n+            type_dict = frame.locals_type\n+        elif isinstance(target, astroid.AssignAttr):\n+            # Instance attribute annotation like: self.a: str\n+            # Store in instance_attrs_type\n+            name = target.attrname\n+            type_dict = frame.instance_attrs_type\n+        else:\n+            return\n+\n+        # Extract the type from the annotation\n+        if node.annotation is not None:\n+            try:\n+                # Try to infer the type from the annotation\n+                types = set()\n+                for inferred in node.annotation.infer():\n+                    if inferred is not astroid.Uninferable:\n+                        types.add(inferred)\n+\n+                # If we have inferred types, add them to the appropriate dictionary\n+                if types:\n+                    current = set(type_dict[name])\n+                    type_dict[name] = list(current | types)\n+            except astroid.InferenceError:\n+                pass\n+\n     def visit_import(self, node):\n         \"\"\"visit an astroid.Import node\n \n"}
{"instance_id": "psf__requests-5414", "model_name_or_path": "devchain", "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex fe22ff45..b808a139 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -20,6 +20,7 @@ from urllib3.exceptions import ClosedPoolError\n from urllib3.exceptions import ConnectTimeoutError\n from urllib3.exceptions import HTTPError as _HTTPError\n from urllib3.exceptions import InvalidHeader as _InvalidHeader\n+from urllib3.exceptions import LocationParseError\n from urllib3.exceptions import MaxRetryError\n from urllib3.exceptions import NewConnectionError\n from urllib3.exceptions import ProxyError as _ProxyError\n@@ -524,6 +525,9 @@ class HTTPAdapter(BaseAdapter):\n         except _ProxyError as e:\n             raise ProxyError(e)\n \n+        except LocationParseError as e:\n+            raise InvalidURL(\"URL has an invalid label.\", request=request)\n+\n         except (_SSLError, _HTTPError) as e:\n             if isinstance(e, _SSLError):\n                 # This branch is for urllib3 versions earlier than v1.22\n"}
{"instance_id": "django__django-12406", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..a92f75ca72 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -13,7 +13,8 @@ from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, SelectMultiple,\n+    CheckboxSelectMultiple, HiddenInput, MultipleHiddenInput,\n+    RadioSelect, SelectMultiple,\n )\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n@@ -1185,7 +1186,12 @@ class ModelChoiceField(ChoiceField):\n                  required=True, widget=None, label=None, initial=None,\n                  help_text='', to_field_name=None, limit_choices_to=None,\n                  **kwargs):\n-        if required and (initial is not None):\n+        # RadioSelect and CheckboxSelectMultiple use an inherent unfilled state\n+        # for empty values (no button checked), so empty_label shouldn't be\n+        # included when the field is required. The widget can be a class or an\n+        # instance, so check both with issubclass/isinstance.\n+        widget_type = widget if isinstance(widget, type) else type(widget) if widget else None\n+        if required and (initial is not None or (widget_type is not None and issubclass(widget_type, (RadioSelect, CheckboxSelectMultiple)))):\n             self.empty_label = None\n         else:\n             self.empty_label = empty_label\n"}
{"instance_id": "astropy__astropy-13236", "model_name_or_path": "devchain", "model_patch": "diff --git a/astropy/table/table.py b/astropy/table/table.py\nindex 5afe2127a3..bf6345b9b1 100644\n--- a/astropy/table/table.py\n+++ b/astropy/table/table.py\n@@ -1243,6 +1243,11 @@ class Table:\n         # mixin class\n         if (not isinstance(data, Column) and not data_is_mixin\n                 and isinstance(data, np.ndarray) and len(data.dtype) > 1):\n+            warnings.warn(\"Passing a structured ndarray to a Table is \"\n+                          \"deprecated. In future, this will be added as a \"\n+                          \"Column. To avoid this warning, wrap the data in \"\n+                          \"a Column explicitly.\",\n+                          FutureWarning, stacklevel=3)\n             data = data.view(NdarrayMixin)\n             data_is_mixin = True\n \n"}
{"instance_id": "django__django-14792", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/backends/postgresql/operations.py b/django/db/backends/postgresql/operations.py\nindex 8d19872bea..2a55e60977 100644\n--- a/django/db/backends/postgresql/operations.py\n+++ b/django/db/backends/postgresql/operations.py\n@@ -44,6 +44,13 @@ class DatabaseOperations(BaseDatabaseOperations):\n         return \"DATE_TRUNC('%s', %s)\" % (lookup_type, field_name)\n \n     def _prepare_tzname_delta(self, tzname):\n+        # PostgreSQL's AT TIME ZONE operator interprets:\n+        # - '-10' as UTC+10 (east of UTC)\n+        # - '+10' as UTC-10 (west of UTC)\n+        # IANA names like 'Etc/GMT-10' use POSIX convention (sign reversed),\n+        # so extract just the offset (e.g., '-10' from 'Etc/GMT-10').\n+        if tzname.startswith('Etc/GMT') and len(tzname) > 7 and tzname[7] in '+-':\n+            return tzname[7:]\n         if '+' in tzname:\n             return tzname.replace('+', '-')\n         elif '-' in tzname:\n"}
{"instance_id": "sympy__sympy-20916", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/printing/conventions.py b/sympy/printing/conventions.py\nindex 9a3be6bbe9..5e3aa1ab54 100644\n--- a/sympy/printing/conventions.py\n+++ b/sympy/printing/conventions.py\n@@ -7,7 +7,7 @@\n from collections.abc import Iterable\n from sympy import Derivative\n \n-_name_with_digits_p = re.compile(r'^([a-zA-Z]+)([0-9]+)$')\n+_name_with_digits_p = re.compile(r'^([^\\W\\d_]+)([0-9]+)$')\n \n \n def split_super_sub(text):\n"}
{"instance_id": "django__django-14011", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..897ddf2a73 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -80,6 +80,17 @@ class WSGIServer(simple_server.WSGIServer):\n class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n     \"\"\"A threaded version of the WSGIServer\"\"\"\n     daemon_threads = True\n+    block_on_close = True\n+\n+    def process_request_thread(self, request, client_address):\n+        \"\"\"Override to close database connections after handling a request.\"\"\"\n+        try:\n+            super().process_request_thread(request, client_address)\n+        finally:\n+            from django.db import connections\n+            from django.db.backends.base.base import BaseDatabaseWrapper\n+            for conn in connections.all():\n+                BaseDatabaseWrapper.close(conn)\n \n \n class ServerHandler(simple_server.ServerHandler):\ndiff --git a/django/test/testcases.py b/django/test/testcases.py\nindex 92f566b7b0..e1668f023b 100644\n--- a/django/test/testcases.py\n+++ b/django/test/testcases.py\n@@ -1511,7 +1511,15 @@ class LiveServerThread(threading.Thread):\n             self.error = e\n             self.is_ready.set()\n         finally:\n-            connections.close_all()\n+            self._close_connections()\n+\n+    def _close_connections(self):\n+        \"\"\"Close database connections, including those to in-memory databases.\"\"\"\n+        for conn in connections.all():\n+            # Force close for in-memory databases which normally ignore\n+            # close requests to prevent data loss.\n+            from django.db.backends.base.base import BaseDatabaseWrapper\n+            BaseDatabaseWrapper.close(conn)\n \n     def _create_server(self):\n         return self.server_class(\n"}
{"instance_id": "django__django-16560", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/models/constraints.py b/django/db/models/constraints.py\nindex 075ecee1be..0178467783 100644\n--- a/django/db/models/constraints.py\n+++ b/django/db/models/constraints.py\n@@ -19,10 +19,12 @@ __all__ = [\"BaseConstraint\", \"CheckConstraint\", \"Deferrable\", \"UniqueConstraint\"\n class BaseConstraint:\n     default_violation_error_message = _(\"Constraint \u201c%(name)s\u201d is violated.\")\n     violation_error_message = None\n+    default_violation_error_code = None\n+    violation_error_code = None\n \n     # RemovedInDjango60Warning: When the deprecation ends, replace with:\n-    # def __init__(self, *, name, violation_error_message=None):\n-    def __init__(self, *args, name=None, violation_error_message=None):\n+    # def __init__(self, *, name, violation_error_message=None, violation_error_code=None):\n+    def __init__(self, *args, name=None, violation_error_message=None, violation_error_code=None):\n         # RemovedInDjango60Warning.\n         if name is None and not args:\n             raise TypeError(\n@@ -34,6 +36,10 @@ class BaseConstraint:\n             self.violation_error_message = violation_error_message\n         else:\n             self.violation_error_message = self.default_violation_error_message\n+        if violation_error_code is not None:\n+            self.violation_error_code = violation_error_code\n+        else:\n+            self.violation_error_code = self.default_violation_error_code\n         # RemovedInDjango60Warning.\n         if args:\n             warnings.warn(\n@@ -42,7 +48,7 @@ class BaseConstraint:\n                 RemovedInDjango60Warning,\n                 stacklevel=2,\n             )\n-            for arg, attr in zip(args, [\"name\", \"violation_error_message\"]):\n+            for arg, attr in zip(args, [\"name\", \"violation_error_message\", \"violation_error_code\"]):\n                 if arg:\n                     setattr(self, attr, arg)\n \n@@ -74,6 +80,11 @@ class BaseConstraint:\n             and self.violation_error_message != self.default_violation_error_message\n         ):\n             kwargs[\"violation_error_message\"] = self.violation_error_message\n+        if (\n+            self.violation_error_code is not None\n+            and self.violation_error_code != self.default_violation_error_code\n+        ):\n+            kwargs[\"violation_error_code\"] = self.violation_error_code\n         return (path, (), kwargs)\n \n     def clone(self):\n@@ -82,13 +93,13 @@ class BaseConstraint:\n \n \n class CheckConstraint(BaseConstraint):\n-    def __init__(self, *, check, name, violation_error_message=None):\n+    def __init__(self, *, check, name, violation_error_message=None, violation_error_code=None):\n         self.check = check\n         if not getattr(check, \"conditional\", False):\n             raise TypeError(\n                 \"CheckConstraint.check must be a Q instance or boolean expression.\"\n             )\n-        super().__init__(name=name, violation_error_message=violation_error_message)\n+        super().__init__(name=name, violation_error_message=violation_error_message, violation_error_code=violation_error_code)\n \n     def _get_check_sql(self, model, schema_editor):\n         query = Query(model=model, alias_cols=False)\n@@ -112,12 +123,14 @@ class CheckConstraint(BaseConstraint):\n         against = instance._get_field_value_map(meta=model._meta, exclude=exclude)\n         try:\n             if not Q(self.check).check(against, using=using):\n-                raise ValidationError(self.get_violation_error_message())\n+                raise ValidationError(\n+                    self.get_violation_error_message(), code=self.violation_error_code\n+                )\n         except FieldError:\n             pass\n \n     def __repr__(self):\n-        return \"<%s: check=%s name=%s%s>\" % (\n+        return \"<%s: check=%s name=%s%s%s>\" % (\n             self.__class__.__qualname__,\n             self.check,\n             repr(self.name),\n@@ -127,6 +140,12 @@ class CheckConstraint(BaseConstraint):\n                 or self.violation_error_message == self.default_violation_error_message\n                 else \" violation_error_message=%r\" % self.violation_error_message\n             ),\n+            (\n+                \"\"\n+                if self.violation_error_code is None\n+                or self.violation_error_code == self.default_violation_error_code\n+                else \" violation_error_code=%r\" % self.violation_error_code\n+            ),\n         )\n \n     def __eq__(self, other):\n@@ -135,6 +154,7 @@ class CheckConstraint(BaseConstraint):\n                 self.name == other.name\n                 and self.check == other.check\n                 and self.violation_error_message == other.violation_error_message\n+                and self.violation_error_code == other.violation_error_code\n             )\n         return super().__eq__(other)\n \n@@ -164,6 +184,7 @@ class UniqueConstraint(BaseConstraint):\n         include=None,\n         opclasses=(),\n         violation_error_message=None,\n+        violation_error_code=None,\n     ):\n         if not name:\n             raise ValueError(\"A unique constraint must be named.\")\n@@ -213,7 +234,7 @@ class UniqueConstraint(BaseConstraint):\n             F(expression) if isinstance(expression, str) else expression\n             for expression in expressions\n         )\n-        super().__init__(name=name, violation_error_message=violation_error_message)\n+        super().__init__(name=name, violation_error_message=violation_error_message, violation_error_code=violation_error_code)\n \n     @property\n     def contains_expressions(self):\n@@ -293,7 +314,7 @@ class UniqueConstraint(BaseConstraint):\n         )\n \n     def __repr__(self):\n-        return \"<%s:%s%s%s%s%s%s%s%s>\" % (\n+        return \"<%s:%s%s%s%s%s%s%s%s%s>\" % (\n             self.__class__.__qualname__,\n             \"\" if not self.fields else \" fields=%s\" % repr(self.fields),\n             \"\" if not self.expressions else \" expressions=%s\" % repr(self.expressions),\n@@ -308,6 +329,12 @@ class UniqueConstraint(BaseConstraint):\n                 or self.violation_error_message == self.default_violation_error_message\n                 else \" violation_error_message=%r\" % self.violation_error_message\n             ),\n+            (\n+                \"\"\n+                if self.violation_error_code is None\n+                or self.violation_error_code == self.default_violation_error_code\n+                else \" violation_error_code=%r\" % self.violation_error_code\n+            ),\n         )\n \n     def __eq__(self, other):\n@@ -321,6 +348,7 @@ class UniqueConstraint(BaseConstraint):\n                 and self.opclasses == other.opclasses\n                 and self.expressions == other.expressions\n                 and self.violation_error_message == other.violation_error_message\n+                and self.violation_error_code == other.violation_error_code\n             )\n         return super().__eq__(other)\n \n@@ -385,7 +413,9 @@ class UniqueConstraint(BaseConstraint):\n         if not self.condition:\n             if queryset.exists():\n                 if self.expressions:\n-                    raise ValidationError(self.get_violation_error_message())\n+                    raise ValidationError(\n+                        self.get_violation_error_message(), code=self.violation_error_code\n+                    )\n                 # When fields are defined, use the unique_error_message() for\n                 # backward compatibility.\n                 for model, constraints in instance.get_constraints():\n@@ -400,6 +430,8 @@ class UniqueConstraint(BaseConstraint):\n                 if (self.condition & Exists(queryset.filter(self.condition))).check(\n                     against, using=using\n                 ):\n-                    raise ValidationError(self.get_violation_error_message())\n+                    raise ValidationError(\n+                        self.get_violation_error_message(), code=self.violation_error_code\n+                    )\n             except FieldError:\n                 pass\n"}
{"instance_id": "django__django-15629", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex fad5560486..817e622054 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1180,7 +1180,9 @@ class ForeignKey(ForeignObject):\n         return self.target_field.rel_db_type(connection=connection)\n \n     def db_parameters(self, connection):\n-        return {\"type\": self.db_type(connection), \"check\": self.db_check(connection)}\n+        db_params = {\"type\": self.db_type(connection), \"check\": self.db_check(connection)}\n+        db_params[\"collation\"] = getattr(self.target_field, \"db_collation\", None)\n+        return db_params\n \n     def convert_empty_strings(self, value, expression, connection):\n         if (not value) and isinstance(value, str):\n"}
{"instance_id": "scikit-learn__scikit-learn-25747", "model_name_or_path": "devchain", "model_patch": "diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..425918f94 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -53,9 +53,9 @@ def _wrap_in_pandas_container(\n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n     if isinstance(data_to_wrap, pd.DataFrame):\n-        if columns is not None:\n+        if columns is not None and len(columns) == len(data_to_wrap.columns):\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        if index is not None and len(index) == len(data_to_wrap.index):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n"}
{"instance_id": "matplotlib__matplotlib-22865", "model_name_or_path": "devchain", "model_patch": "diff --git a/lib/matplotlib/colorbar.py b/lib/matplotlib/colorbar.py\nindex c59b0ac815..6e52a98310 100644\n--- a/lib/matplotlib/colorbar.py\n+++ b/lib/matplotlib/colorbar.py\n@@ -651,8 +651,22 @@ class Colorbar:\n             if not self.drawedges:\n                 if len(self._y) >= self.n_rasterize:\n                     self.solids.set_rasterized(True)\n-        self.dividers.set_segments(\n-            np.dstack([X, Y])[1:-1] if self.drawedges else [])\n+        # Select divider segments based on extend setting:\n+        # - 'neither': skip both outer edges (outline draws them)\n+        # - 'both': draw all edges (need edges at extend boundaries)\n+        # - 'min': skip left edge only\n+        # - 'max': skip right edge only\n+        if self.drawedges:\n+            segments = np.dstack([X, Y])\n+            slice_idx = {\n+                'neither': slice(1, -1),\n+                'both': slice(0, None),\n+                'min': slice(1, None),\n+                'max': slice(0, -1),\n+            }[self.extend]\n+            self.dividers.set_segments(segments[slice_idx])\n+        else:\n+            self.dividers.set_segments([])\n \n     def _add_solids_patches(self, X, Y, C, mappable):\n         hatches = mappable.hatches * len(C)  # Have enough hatches.\ndiff --git a/test_output.png b/test_output.png\nnew file mode 100644\nindex 0000000000..9b28d7e742\nBinary files /dev/null and b/test_output.png differ\ndiff --git a/test_output_fixed.png b/test_output_fixed.png\nnew file mode 100644\nindex 0000000000..d08cc95ca3\nBinary files /dev/null and b/test_output_fixed.png differ\n"}
{"instance_id": "sympy__sympy-14976", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex d06901425d..94f25ecbce 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -331,6 +331,14 @@ def _print_Float(self, e):\n         args = str(tuple(map(int, e._mpf_)))\n         return '{func}({args})'.format(func=self._module_format('mpmath.mpf'), args=args)\n \n+    def _print_Rational(self, expr):\n+        # Wrap rationals with mpmath.mpf to maintain full precision\n+        return '{func}({p})/{func}({q})'.format(\n+            func=self._module_format('mpmath.mpf'),\n+            p=expr.p,\n+            q=expr.q\n+        )\n+\n \n     def _print_uppergamma(self, e):\n         return \"{0}({1}, {2}, {3})\".format(\n"}
{"instance_id": "django__django-14311", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex b6af5f5491..fc90c5a783 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -224,7 +224,14 @@ def get_child_arguments():\n     # see https://docs.python.org/3/reference/import.html#main-spec\n     # __spec__ may not exist, e.g. when running in a Conda env.\n     if getattr(__main__, '__spec__', None) is not None and __main__.__spec__.parent:\n-        args += ['-m', __main__.__spec__.parent]\n+        spec = __main__.__spec__\n+        # If __main__ is the __main__ submodule of a package (e.g., foo.bar.__main__),\n+        # use the parent name (foo.bar). Otherwise, use the module name directly.\n+        if spec.name == '__main__' or spec.name.endswith('.__main__'):\n+            name = spec.parent\n+        else:\n+            name = spec.name\n+        args += ['-m', name]\n         args += sys.argv[1:]\n     elif not py_script.exists():\n         # sys.argv[0] may not exist for several reasons on Windows.\n"}
{"instance_id": "django__django-14376", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/backends/mysql/base.py b/django/db/backends/mysql/base.py\nindex 2c62182d31..8b28a60485 100644\n--- a/django/db/backends/mysql/base.py\n+++ b/django/db/backends/mysql/base.py\n@@ -200,9 +200,9 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n         if settings_dict['USER']:\n             kwargs['user'] = settings_dict['USER']\n         if settings_dict['NAME']:\n-            kwargs['db'] = settings_dict['NAME']\n+            kwargs['database'] = settings_dict['NAME']\n         if settings_dict['PASSWORD']:\n-            kwargs['passwd'] = settings_dict['PASSWORD']\n+            kwargs['password'] = settings_dict['PASSWORD']\n         if settings_dict['HOST'].startswith('/'):\n             kwargs['unix_socket'] = settings_dict['HOST']\n         elif settings_dict['HOST']:\n"}
{"instance_id": "sympy__sympy-18199", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/ntheory/residue_ntheory.py b/sympy/ntheory/residue_ntheory.py\nindex 9a3052d4c3..25fc3e4140 100644\n--- a/sympy/ntheory/residue_ntheory.py\n+++ b/sympy/ntheory/residue_ntheory.py\n@@ -776,6 +776,10 @@ def nthroot_mod(a, n, p, all_roots=False):\n     if not isprime(p):\n         raise NotImplementedError(\"Not implemented for composite p\")\n \n+    if a % p == 0:\n+        # 0**n = 0 = a mod p when a % p == 0\n+        return 0 if not all_roots else [0]\n+\n     if (p - 1) % n == 0:\n         return _nthroot_mod1(a, n, p, all_roots)\n     # The roots of ``x**n - a = 0 (mod p)`` are roots of\n"}
{"instance_id": "django__django-16631", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/contrib/auth/__init__.py b/django/contrib/auth/__init__.py\nindex 155330c596..dc0b5d2521 100644\n--- a/django/contrib/auth/__init__.py\n+++ b/django/contrib/auth/__init__.py\n@@ -199,9 +199,28 @@ def get_user(request):\n             # Verify the session\n             if hasattr(user, \"get_session_auth_hash\"):\n                 session_hash = request.session.get(HASH_SESSION_KEY)\n-                session_hash_verified = session_hash and constant_time_compare(\n-                    session_hash, user.get_session_auth_hash()\n-                )\n+                session_hash_verified = False\n+                if session_hash:\n+                    # Try the current secret key first\n+                    session_hash_verified = constant_time_compare(\n+                        session_hash, user.get_session_auth_hash()\n+                    )\n+                    # If not verified, try the fallback keys\n+                    if not session_hash_verified:\n+                        from django.utils.crypto import salted_hmac\n+\n+                        key_salt = (\n+                            \"django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash\"\n+                        )\n+                        for secret in settings.SECRET_KEY_FALLBACKS:\n+                            if constant_time_compare(\n+                                session_hash,\n+                                salted_hmac(\n+                                    key_salt, user.password, secret=secret, algorithm=\"sha256\"\n+                                ).hexdigest(),\n+                            ):\n+                                session_hash_verified = True\n+                                break\n                 if not session_hash_verified:\n                     request.session.flush()\n                     user = None\n"}
{"instance_id": "django__django-15695", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex d17232e4ec..9f26e94a40 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -953,6 +953,9 @@ class RenameIndex(IndexOperation):\n                         \", \".join(columns),\n                     )\n                 )\n+            # Skip the rename if the index already has the target name\n+            if matching_index_name[0].lower() == self.new_name_lower:\n+                return\n             old_index = models.Index(\n                 fields=self.old_fields,\n                 name=matching_index_name[0],\n@@ -967,7 +970,26 @@ class RenameIndex(IndexOperation):\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         if self.old_fields:\n-            # Backward operation with unnamed index is a no-op.\n+            model = to_state.apps.get_model(app_label, self.model_name)\n+            if not self.allow_migrate_model(schema_editor.connection.alias, model):\n+                return\n+            # Find the index in from_state (after rename) with name=new_name\n+            from_model_state = from_state.models[app_label, self.model_name_lower]\n+            old_index = from_model_state.get_index_by_name(self.new_name)\n+            # Generate the auto-generated name for the index using the same\n+            # algorithm as used for index_together indexes (digest length=8)\n+            columns = [\n+                model._meta.get_field(field).column for field in self.old_fields\n+            ]\n+            auto_generated_name = schema_editor._create_index_name(\n+                model._meta.db_table, columns, suffix=\"_idx\"\n+            )\n+            new_index = models.Index(\n+                fields=self.old_fields,\n+                name=auto_generated_name,\n+            )\n+            # Rename from the new name back to the original auto-generated name\n+            schema_editor.rename_index(model, old_index, new_index)\n             return\n \n         self.new_name_lower, self.old_name_lower = (\n"}
{"instance_id": "sympy__sympy-20438", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 3c4aa86e36..5a39fb3933 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -865,6 +865,13 @@ def __len__(self):\n     def __bool__(self):\n         return all([bool(s) for s in self.sets])\n \n+    def _eval_is_subset(self, other):\n+        # Check if all elements of the ProductSet are in the other set\n+        # If the ProductSet is iterable (all components are finite),\n+        # check each element individually\n+        if self.is_iterable:\n+            return fuzzy_and(other._contains(el) for el in self)\n+\n \n class Interval(Set, EvalfMixin):\n     \"\"\"\n"}
{"instance_id": "sympy__sympy-20428", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/polys/densetools.py b/sympy/polys/densetools.py\nindex f057824642..d298c3c750 100644\n--- a/sympy/polys/densetools.py\n+++ b/sympy/polys/densetools.py\n@@ -1197,6 +1197,7 @@ def dup_clear_denoms(f, K0, K1=None, convert=False):\n \n     if not K1.is_one(common):\n         f = dup_mul_ground(f, common, K0)\n+        f = dup_strip(f)\n \n     if not convert:\n         return common, f\n@@ -1251,6 +1252,7 @@ def dmp_clear_denoms(f, u, K0, K1=None, convert=False):\n \n     if not K1.is_one(common):\n         f = dmp_mul_ground(f, common, u, K0)\n+        f = dmp_strip(f, u)\n \n     if not convert:\n         return common, f\ndiff --git a/sympy/polys/domains/expressiondomain.py b/sympy/polys/domains/expressiondomain.py\nindex 1ce2316dc6..3813fa394d 100644\n--- a/sympy/polys/domains/expressiondomain.py\n+++ b/sympy/polys/domains/expressiondomain.py\n@@ -120,7 +120,7 @@ def __ne__(f, g):\n             return not f == g\n \n         def __bool__(f):\n-            return f.ex != 0\n+            return not f.ex.is_zero\n \n         def gcd(f, g):\n             from sympy.polys import gcd\n"}
{"instance_id": "django__django-11848", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..0b7246fb87 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,14 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n-                year += 1900\n+            # RFC 7231: interpret two-digit years that appear to be more than\n+            # 50 years in the future as representing the most recent year in\n+            # the past that had the same last two digits.\n+            current_year = datetime.datetime.now().year\n+            current_century = (current_year // 100) * 100\n+            year = current_century + year\n+            if year - current_year > 50:\n+                year -= 100\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n"}
{"instance_id": "django__django-11728", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/contrib/admindocs/utils.py b/django/contrib/admindocs/utils.py\nindex 1ce4594501..a296cae5ad 100644\n--- a/django/contrib/admindocs/utils.py\n+++ b/django/contrib/admindocs/utils.py\n@@ -180,6 +180,11 @@ def replace_named_groups(pattern):\n             elif val == ')' and prev_char != '\\\\':\n                 unmatched_open_brackets -= 1\n             prev_char = val\n+        else:\n+            # The loop didn't break. If brackets are balanced, this is a\n+            # trailing group (e.g., r'(?P<a>\\w+)' or r'foo/(?P<b>\\w+)').\n+            if unmatched_open_brackets == 0:\n+                group_pattern_and_name.append((pattern[start:end + idx + 1], group_name))\n \n     # Replace the string for named capture groups with their group names.\n     for group_pattern, group_name in group_pattern_and_name:\n@@ -193,7 +198,12 @@ def replace_unnamed_groups(pattern):\n     1. ^(?P<a>\\w+)/b/(\\w+)$ ==> ^(?P<a>\\w+)/b/<var>$\n     2. ^(?P<a>\\w+)/b/((x|y)\\w+)$ ==> ^(?P<a>\\w+)/b/<var>$\n     \"\"\"\n-    unnamed_group_indices = [m.start(0) for m in unnamed_group_matcher.finditer(pattern)]\n+    # Get positions of named groups to exclude them from unnamed group processing.\n+    named_group_starts = {m.start(0) for m in named_group_matcher.finditer(pattern)}\n+    unnamed_group_indices = [\n+        m.start(0) for m in unnamed_group_matcher.finditer(pattern)\n+        if m.start(0) not in named_group_starts\n+    ]\n     # Indices of the start of unnamed capture groups.\n     group_indices = []\n     # Loop over the start indices of the groups.\n@@ -212,6 +222,11 @@ def replace_unnamed_groups(pattern):\n             elif val == ')' and prev_char != '\\\\':\n                 unmatched_open_brackets -= 1\n             prev_char = val\n+        else:\n+            # The loop didn't break. If brackets are balanced, this is a\n+            # trailing group (e.g., r'(\\w+)' or r'foo/(\\w+)').\n+            if unmatched_open_brackets == 0:\n+                group_indices.append((start, start + 1 + idx + 1))\n \n     # Remove unnamed group matches inside other unnamed capture groups.\n     group_start_end_indices = []\n@@ -229,7 +244,10 @@ def replace_unnamed_groups(pattern):\n         for start, end in group_start_end_indices:\n             if prev_end:\n                 final_pattern.append(pattern[prev_end:start])\n-            final_pattern.append(pattern[:start] + '<var>')\n+                final_pattern.append('<var>')\n+            else:\n+                # First group: include the prefix before the group.\n+                final_pattern.append(pattern[:start] + '<var>')\n             prev_end = end\n         final_pattern.append(pattern[prev_end:])\n         return ''.join(final_pattern)\n"}
{"instance_id": "django__django-14140", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex ae0f886107..43c93ce455 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -84,14 +84,10 @@ class Q(tree.Node):\n         path = '%s.%s' % (self.__class__.__module__, self.__class__.__name__)\n         if path.startswith('django.db.models.query_utils'):\n             path = path.replace('django.db.models.query_utils', 'django.db.models')\n-        args, kwargs = (), {}\n-        if len(self.children) == 1 and not isinstance(self.children[0], Q):\n-            child = self.children[0]\n-            kwargs = {child[0]: child[1]}\n-        else:\n-            args = tuple(self.children)\n-            if self.connector != self.default:\n-                kwargs = {'_connector': self.connector}\n+        args = tuple(self.children)\n+        kwargs = {}\n+        if self.connector != self.default:\n+            kwargs['_connector'] = self.connector\n         if self.negated:\n             kwargs['_negated'] = True\n         return path, args, kwargs\n"}
{"instance_id": "sphinx-doc__sphinx-7440", "model_name_or_path": "devchain", "model_patch": "diff --git a/sphinx/domains/std.py b/sphinx/domains/std.py\nindex d820cfe5c..759620c91 100644\n--- a/sphinx/domains/std.py\n+++ b/sphinx/domains/std.py\n@@ -275,7 +275,7 @@ def split_term_classifiers(line: str) -> List[Optional[str]]:\n \n def make_glossary_term(env: \"BuildEnvironment\", textnodes: Iterable[Node], index_key: str,\n                        source: str, lineno: int, node_id: str = None,\n-                       document: nodes.document = None) -> nodes.term:\n+                       document: nodes.document = None, old_termtext: str = None) -> nodes.term:\n     # get a text-only representation of the term and register it\n     # as a cross-reference target\n     term = nodes.term('', '', *textnodes)\n@@ -305,7 +305,11 @@ def make_glossary_term(env: \"BuildEnvironment\", textnodes: Iterable[Node], index\n         term['ids'].append(node_id)\n \n     std = cast(StandardDomain, env.get_domain('std'))\n-    std.note_object('term', termtext.lower(), node_id, location=term)\n+    # For i18n, update_object replaces the old term with the new translated term\n+    if old_termtext is not None:\n+        std.update_object('term', old_termtext, termtext, node_id)\n+    else:\n+        std.note_object('term', termtext, node_id, location=term)\n \n     # add an index entry too\n     indexnode = addnodes.index()\n@@ -663,6 +667,17 @@ class StandardDomain(Domain):\n                       RemovedInSphinx50Warning)\n         self.objects[objtype, name] = (docname, labelid)\n \n+    def update_object(self, objtype: str, old_name: str, new_name: str, labelid: str) -> None:\n+        \"\"\"Update an object with a new name (used for i18n glossary term translation).\n+\n+        .. versionadded:: 3.0.2\n+        \"\"\"\n+        # Remove the old entry if it exists\n+        if (objtype, old_name) in self.objects:\n+            del self.objects[objtype, old_name]\n+        # Add the new entry (without duplicate warning since this is an update)\n+        self.objects[objtype, new_name] = (self.env.docname, labelid)\n+\n     @property\n     def progoptions(self) -> Dict[Tuple[str, str], Tuple[str, str]]:\n         return self.data.setdefault('progoptions', {})  # (program, name) -> docname, labelid\n@@ -928,9 +943,25 @@ class StandardDomain(Domain):\n                           node: pending_xref, contnode: Element) -> Element:\n         objtypes = self.objtypes_for_role(typ) or []\n         for objtype in objtypes:\n-            if (objtype, target) in self.objects:\n-                docname, labelid = self.objects[objtype, target]\n-                break\n+            # For glossary terms, perform case-insensitive lookup\n+            if objtype == 'term':\n+                # First try exact match\n+                if (objtype, target) in self.objects:\n+                    docname, labelid = self.objects[objtype, target]\n+                    break\n+                # Try case-insensitive match\n+                for (stored_objtype, stored_name), (docname2, labelid2) in self.objects.items():\n+                    if stored_objtype == objtype and stored_name.lower() == target.lower():\n+                        docname, labelid = docname2, labelid2\n+                        break  # Break inner loop\n+                else:\n+                    # No match found in inner loop\n+                    continue  # Continue to next objtype\n+                break  # Break outer loop if inner loop found a match\n+            else:\n+                if (objtype, target) in self.objects:\n+                    docname, labelid = self.objects[objtype, target]\n+                    break\n         else:\n             docname, labelid = '', ''\n         if not docname:\n@@ -951,14 +982,30 @@ class StandardDomain(Domain):\n                 results.append(('std:' + role, res))\n         # all others\n         for objtype in self.object_types:\n-            key = (objtype, target)\n+            # For glossary terms, perform case-insensitive lookup\n             if objtype == 'term':\n+                # First try lowercase (for backwards compatibility)\n                 key = (objtype, ltarget)\n-            if key in self.objects:\n-                docname, labelid = self.objects[key]\n-                results.append(('std:' + self.role_for_objtype(objtype),\n-                                make_refnode(builder, fromdocname, docname,\n-                                             labelid, contnode)))\n+                if key in self.objects:\n+                    docname, labelid = self.objects[key]\n+                    results.append(('std:' + self.role_for_objtype(objtype),\n+                                    make_refnode(builder, fromdocname, docname,\n+                                                 labelid, contnode)))\n+                else:\n+                    # Try case-insensitive match\n+                    for (stored_objtype, stored_name), (docname2, labelid2) in self.objects.items():\n+                        if stored_objtype == objtype and stored_name.lower() == ltarget:\n+                            results.append(('std:' + self.role_for_objtype(objtype),\n+                                            make_refnode(builder, fromdocname, docname2,\n+                                                         labelid2, contnode)))\n+                            break\n+            else:\n+                key = (objtype, target)\n+                if key in self.objects:\n+                    docname, labelid = self.objects[key]\n+                    results.append(('std:' + self.role_for_objtype(objtype),\n+                                    make_refnode(builder, fromdocname, docname,\n+                                                 labelid, contnode)))\n         return results\n \n     def get_objects(self) -> Iterator[Tuple[str, str, str, str, str, int]]:\ndiff --git a/sphinx/transforms/i18n.py b/sphinx/transforms/i18n.py\nindex 34d5b1368..e3d410150 100644\n--- a/sphinx/transforms/i18n.py\n+++ b/sphinx/transforms/i18n.py\n@@ -203,12 +203,15 @@ class Locale(SphinxTransform):\n             # glossary terms update refid\n             if isinstance(node, nodes.term):\n                 for _id in node['ids']:\n+                    # Get the old term text before translation\n+                    old_termtext = node.astext()\n                     parts = split_term_classifiers(msgstr)\n                     patch = publish_msgstr(self.app, parts[0], source,\n                                            node.line, self.config, settings)\n                     patch = make_glossary_term(self.env, patch, parts[1],\n                                                source, node.line, _id,\n-                                               self.document)\n+                                               self.document,\n+                                               old_termtext=old_termtext)\n                     processed = True\n \n             # update leaves with processed nodes\n"}
{"instance_id": "sympy__sympy-17318", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/simplify/radsimp.py b/sympy/simplify/radsimp.py\nindex 216ae26204..de59422669 100644\n--- a/sympy/simplify/radsimp.py\n+++ b/sympy/simplify/radsimp.py\n@@ -1113,6 +1113,8 @@ def _split_gcd(*a):\n     >>> _split_gcd(55, 35, 22, 14, 77, 10)\n     (5, [55, 35, 10], [22, 14, 77])\n     \"\"\"\n+    if not a:\n+        return 1, [], []\n     g = a[0]\n     b1 = [g]\n     b2 = []\n"}
{"instance_id": "django__django-14404", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 59a4a0364d..4effd75415 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -427,7 +427,7 @@ class AdminSite:\n                 pass\n             else:\n                 if getattr(match.func, 'should_append_slash', True):\n-                    return HttpResponsePermanentRedirect(path)\n+                    return HttpResponsePermanentRedirect('%s/' % request.path)\n         raise Http404\n \n     def _build_app_dict(self, request, label=None):\n"}
{"instance_id": "sympy__sympy-18763", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 8743723ea0..6d01be4a11 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -698,7 +698,8 @@ def _print_Derivative(self, expr):\n \n     def _print_Subs(self, subs):\n         expr, old, new = subs.args\n-        latex_expr = self._print(expr)\n+        latex_expr = self.parenthesize(expr, PRECEDENCE[\"Mul\"],\n+                                        strict=True)\n         latex_old = (self._print(e) for e in old)\n         latex_new = (self._print(e) for e in new)\n         latex_subs = r'\\\\ '.join(\n"}
{"instance_id": "django__django-14034", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 65d6a9ec82..629990f5aa 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -1025,6 +1025,15 @@ class MultiValueField(Field):\n             if not value or not [v for v in value if v not in self.empty_values]:\n                 if self.required:\n                     raise ValidationError(self.error_messages['required'], code='required')\n+                # When require_all_fields is False, check if any individual\n+                # field is required and raise a validation error if so.\n+                elif not self.require_all_fields:\n+                    for field in self.fields:\n+                        if field.required:\n+                            raise ValidationError(\n+                                self.error_messages['incomplete'], code='incomplete'\n+                            )\n+                    return self.compress([])\n                 else:\n                     return self.compress([])\n         else:\n"}
{"instance_id": "django__django-16263", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 9735ce10c8..2a8806451e 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -545,11 +545,67 @@ class Query(BaseExpression):\n \n         return dict(zip(outer_query.annotation_select, result))\n \n+    def _get_referenced_annotations(self, expression, annotations, exclude_self=None):\n+        \"\"\"\n+        Return a set of annotation aliases referenced by the given expression.\n+        If exclude_self is provided, don't count self-references to that annotation.\n+        \"\"\"\n+        references = set()\n+        if expression is None:\n+            return references\n+        # If this is a Ref, it directly references an annotation\n+        if isinstance(expression, Ref):\n+            references.add(expression.refs)\n+        # If this is an F expression, check if it references an annotation\n+        elif isinstance(expression, F):\n+            if expression.name in annotations:\n+                references.add(expression.name)\n+        # Check if the expression itself is an annotation (e.g., when used in filters)\n+        elif expression in annotations.values():\n+            # Find the annotation name by expression identity\n+            for alias, annotation in annotations.items():\n+                if annotation is expression:\n+                    # Only count as referenced if not excluding self\n+                    if alias != exclude_self:\n+                        references.add(alias)\n+                    break\n+        # Traverse source expressions to find nested references\n+        if hasattr(expression, \"get_source_expressions\"):\n+            for source in expression.get_source_expressions():\n+                references.update(self._get_referenced_annotations(source, annotations, exclude_self))\n+        return references\n+\n     def get_count(self, using):\n         \"\"\"\n         Perform a COUNT() query using the current filter constraints.\n         \"\"\"\n         obj = self.clone()\n+        # Find annotations that are referenced by filters, ordering, or other annotations.\n+        referenced_annotations = set()\n+        # Check annotations referenced in the where clause (filters).\n+        for child in self.where.children:\n+            referenced_annotations.update(\n+                self._get_referenced_annotations(child, self.annotations)\n+            )\n+        # Check annotations referenced in ordering.\n+        for item in self.order_by:\n+            if isinstance(item, str) and item.lstrip(\"-\") in self.annotations:\n+                referenced_annotations.add(item.lstrip(\"-\"))\n+            elif hasattr(item, \"resolve_expression\"):\n+                referenced_annotations.update(\n+                    self._get_referenced_annotations(item, self.annotations)\n+                )\n+        # Check annotations referenced in other annotations.\n+        for alias, annotation in self.annotations.items():\n+            for ref in self._get_referenced_annotations(annotation, self.annotations, exclude_self=alias):\n+                referenced_annotations.add(ref)\n+        # Remove unreferenced annotations.\n+        for alias in list(obj.annotations.keys()):\n+            if alias not in referenced_annotations:\n+                del obj.annotations[alias]\n+                if obj.annotation_select_mask and alias in obj.annotation_select_mask:\n+                    obj.annotation_select_mask.remove(alias)\n+        obj._annotation_select_cache = None\n         obj.add_annotation(Count(\"*\"), alias=\"__count\", is_summary=True)\n         return obj.get_aggregation(using, [\"__count\"])[\"__count\"]\n \ndiff --git a/test_settings.py b/test_settings.py\nnew file mode 100644\nindex 0000000000..37e29fea5f\n--- /dev/null\n+++ b/test_settings.py\n@@ -0,0 +1,9 @@\n+\n+DATABASES = {\n+    'default': {\n+        'ENGINE': 'django.db.backends.sqlite3',\n+        'NAME': ':memory:',\n+    }\n+}\n+INSTALLED_APPS = []\n+SECRET_KEY = 'test'\n"}
{"instance_id": "matplotlib__matplotlib-23299", "model_name_or_path": "devchain", "model_patch": "diff --git a/lib/matplotlib/pyplot.py b/lib/matplotlib/pyplot.py\nindex e3c66ea67c..3ca5a48242 100644\n--- a/lib/matplotlib/pyplot.py\n+++ b/lib/matplotlib/pyplot.py\n@@ -206,7 +206,7 @@ def _get_backend_mod():\n     return _backend_mod\n \n \n-def switch_backend(newbackend):\n+def switch_backend(newbackend, *, _from_auto_resolution=False):\n     \"\"\"\n     Close all open figures and set the Matplotlib backend.\n \n@@ -222,7 +222,6 @@ def switch_backend(newbackend):\n     global _backend_mod\n     # make sure the init is pulled up so we can assign to it later\n     import matplotlib.backends\n-    close(\"all\")\n \n     if newbackend is rcsetup._auto_backend_sentinel:\n         current_framework = cbook._get_running_interactive_framework()\n@@ -247,7 +246,7 @@ def switch_backend(newbackend):\n         # are of worse quality.\n         for candidate in candidates:\n             try:\n-                switch_backend(candidate)\n+                switch_backend(candidate, _from_auto_resolution=True)\n             except ImportError:\n                 continue\n             else:\n@@ -256,10 +255,14 @@ def switch_backend(newbackend):\n         else:\n             # Switching to Agg should always succeed; if it doesn't, let the\n             # exception propagate out.\n-            switch_backend(\"agg\")\n+            switch_backend(\"agg\", _from_auto_resolution=True)\n             rcParamsOrig[\"backend\"] = \"agg\"\n             return\n \n+    # If we get here, we're actually switching backends (not auto-resolving).\n+    # Only close figures if this is not the result of auto-resolution.\n+    if not _from_auto_resolution:\n+        close(\"all\")\n     backend_mod = importlib.import_module(\n         cbook._backend_module_name(newbackend))\n     canvas_class = backend_mod.FigureCanvas\n"}
{"instance_id": "psf__requests-6028", "model_name_or_path": "devchain", "model_patch": "diff --git a/requests/utils.py b/requests/utils.py\nindex 1c2ae4e0..d834c5f5 100644\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -974,6 +974,11 @@ def prepend_scheme_if_needed(url, new_scheme):\n     if not netloc:\n         netloc, path = path, netloc\n \n+    if auth:\n+        # parse_url doesn't provide the netloc with auth\n+        # so we'll add it ourselves.\n+        netloc = '@'.join([auth, netloc])\n+\n     if scheme is None:\n         scheme = new_scheme\n     if path is None:\n"}
{"instance_id": "sympy__sympy-15976", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/printing/mathml.py b/sympy/printing/mathml.py\nindex 3f8b8d49e0..5a4ef51306 100644\n--- a/sympy/printing/mathml.py\n+++ b/sympy/printing/mathml.py\n@@ -743,11 +743,6 @@ def _print_Sum(self, e):\n         return mrow\n \n     def _print_Symbol(self, sym, style='plain'):\n-        x = self.dom.createElement('mi')\n-\n-        if style == 'bold':\n-            x.setAttribute('mathvariant', 'bold')\n-\n         def join(items):\n             if len(items) > 1:\n                 mrow = self.dom.createElement('mrow')\n@@ -778,28 +773,29 @@ def translate(s):\n         subs = [translate(sub) for sub in subs]\n \n         mname = self.dom.createElement('mi')\n+        if style == 'bold':\n+            mname.setAttribute('mathvariant', 'bold')\n         mname.appendChild(self.dom.createTextNode(name))\n         if len(supers) == 0:\n             if len(subs) == 0:\n-                x.appendChild(self.dom.createTextNode(name))\n+                return mname\n             else:\n                 msub = self.dom.createElement('msub')\n                 msub.appendChild(mname)\n                 msub.appendChild(join(subs))\n-                x.appendChild(msub)\n+                return msub\n         else:\n             if len(subs) == 0:\n                 msup = self.dom.createElement('msup')\n                 msup.appendChild(mname)\n                 msup.appendChild(join(supers))\n-                x.appendChild(msup)\n+                return msup\n             else:\n                 msubsup = self.dom.createElement('msubsup')\n                 msubsup.appendChild(mname)\n                 msubsup.appendChild(join(subs))\n                 msubsup.appendChild(join(supers))\n-                x.appendChild(msubsup)\n-        return x\n+                return msubsup\n \n     def _print_MatrixSymbol(self, sym):\n         return self._print_Symbol(sym, style=self._settings['mat_symbol_style'])\n"}
{"instance_id": "django__django-13344", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 169df6b3cf..e3b8f9d025 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -1,22 +1,69 @@\n import asyncio\n import logging\n-import types\n \n from asgiref.sync import async_to_sync, sync_to_async\n \n from django.conf import settings\n from django.core.exceptions import ImproperlyConfigured, MiddlewareNotUsed\n+from django.core.handlers.exception import convert_exception_to_response, is_coroutine_callable\n from django.core.signals import request_finished\n from django.db import connections, transaction\n from django.urls import get_resolver, set_urlconf\n from django.utils.log import log_response\n from django.utils.module_loading import import_string\n \n-from .exception import convert_exception_to_response\n-\n logger = logging.getLogger('django.request')\n \n \n+class _MiddlewareAsyncAdapter:\n+    \"\"\"\n+    Adapter to make a middleware instance async-capable when its get_response\n+    is async but the middleware's __call__ is not a coroutine function.\n+\n+    This is needed for middlewares that don't inherit from MiddlewareMixin\n+    (which handles async mode automatically via __acall__) but are used in\n+    an async middleware chain.\n+    \"\"\"\n+    __slots__ = ('mw_instance', '_is_coroutine')\n+\n+    def __init__(self, mw_instance):\n+        self.mw_instance = mw_instance\n+        # Mark this adapter as a coroutine function so it's recognized as async\n+        self._is_coroutine = asyncio.coroutines._is_coroutine\n+\n+    def __getattr__(self, name):\n+        # Delegate all attribute access to the wrapped middleware instance\n+        return getattr(self.mw_instance, name)\n+\n+    async def __call__(self, request):\n+        \"\"\"\n+        Async __call__ that always returns an awaitable.\n+        Routes to async mode when get_response is async, otherwise wraps\n+        the sync middleware call in sync_to_async.\n+        \"\"\"\n+        if asyncio.iscoroutinefunction(self.mw_instance.get_response):\n+            # get_response is async - use the async path\n+            response = None\n+            if hasattr(self.mw_instance, 'process_request'):\n+                response = await sync_to_async(\n+                    self.mw_instance.process_request,\n+                    thread_sensitive=True,\n+                )(request)\n+            response = response or await self.mw_instance.get_response(request)\n+            if hasattr(self.mw_instance, 'process_response'):\n+                response = await sync_to_async(\n+                    self.mw_instance.process_response,\n+                    thread_sensitive=True,\n+                )(request, response)\n+            return response\n+        else:\n+            # get_response is sync - wrap the entire middleware call in sync_to_async\n+            return await sync_to_async(\n+                self.mw_instance,\n+                thread_sensitive=True,\n+            )(request)\n+\n+\n class BaseHandler:\n     _view_middleware = None\n     _template_response_middleware = None\n@@ -69,6 +116,17 @@ class BaseHandler:\n                     'Middleware factory %s returned None.' % middleware_path\n                 )\n \n+            # After adapt_method_mode, check if the handler that the middleware receives\n+            # is async. If so, the middleware needs to be async-capable. Wrap it with\n+            # an adapter if its __call__ is not already a coroutine function.\n+            # This is needed for middlewares that don't use MiddlewareMixin but are\n+            # used in an async chain.\n+            handler_is_async_after_adapt = asyncio.iscoroutinefunction(handler) or is_coroutine_callable(handler)\n+            if (handler_is_async_after_adapt and\n+                    not asyncio.iscoroutinefunction(mw_instance) and\n+                    not is_coroutine_callable(mw_instance)):\n+                mw_instance = _MiddlewareAsyncAdapter(mw_instance)\n+\n             if hasattr(mw_instance, 'process_view'):\n                 self._view_middleware.insert(\n                     0,\n@@ -86,7 +144,10 @@ class BaseHandler:\n                 )\n \n             handler = convert_exception_to_response(mw_instance)\n-            handler_is_async = middleware_is_async\n+            # After wrapping the middleware instance, check if the handler is async.\n+            # Use is_coroutine_callable to properly detect MiddlewareMixin instances\n+            # with async get_response.\n+            handler_is_async = is_coroutine_callable(handler)\n \n         # Adapt the top of the stack, if needed.\n         handler = self.adapt_method_mode(is_async, handler, handler_is_async)\ndiff --git a/django/core/handlers/exception.py b/django/core/handlers/exception.py\nindex 98fb46083a..bd1b748d2d 100644\n--- a/django/core/handlers/exception.py\n+++ b/django/core/handlers/exception.py\n@@ -51,6 +51,15 @@ def convert_exception_to_response(get_response):\n         return inner\n \n \n+def is_coroutine_callable(callable):\n+    \"\"\"\n+    Check if the callable will return a coroutine when called.\n+    This is needed for middleware instances (like MiddlewareMixin) that have\n+    an async get_response but __call__ is not a coroutine function.\n+    \"\"\"\n+    return asyncio.iscoroutinefunction(callable) or getattr(callable, '_is_coroutine', None) is asyncio.coroutines._is_coroutine\n+\n+\n def response_for_exception(request, exc):\n     if isinstance(exc, Http404):\n         if settings.DEBUG:\n"}
{"instance_id": "matplotlib__matplotlib-25479", "model_name_or_path": "devchain", "model_patch": "diff --git a/lib/matplotlib/cm.py b/lib/matplotlib/cm.py\nindex 38158db956..35b7a5f95f 100644\n--- a/lib/matplotlib/cm.py\n+++ b/lib/matplotlib/cm.py\n@@ -145,7 +145,9 @@ class ColormapRegistry(Mapping):\n             _api.warn_external(f\"Overwriting the cmap {name!r} \"\n                                \"that was already in the registry.\")\n \n-        self._cmaps[name] = cmap.copy()\n+        cmap_copy = cmap.copy()\n+        cmap_copy.name = name\n+        self._cmaps[name] = cmap_copy\n \n     def unregister(self, name):\n         \"\"\"\n"}
{"instance_id": "django__django-14155", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9b00e24509..f719cfb1b6 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -31,19 +31,26 @@ from .utils import get_callable\n \n class ResolverMatch:\n     def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None, tried=None):\n-        self.func = func\n-        self.args = args\n-        self.kwargs = kwargs\n-        self.url_name = url_name\n-        self.route = route\n-        self.tried = tried\n-\n         # If a URLRegexResolver doesn't have a namespace or app_name, it passes\n         # in an empty value.\n         self.app_names = [x for x in app_names if x] if app_names else []\n         self.app_name = ':'.join(self.app_names)\n         self.namespaces = [x for x in namespaces if x] if namespaces else []\n         self.namespace = ':'.join(self.namespaces)\n+        self.url_name = url_name\n+        self.route = route\n+        self.tried = tried\n+\n+        # Unwrap functools.partial to get the underlying function.\n+        while isinstance(func, functools.partial):\n+            # Merge partial's positional arguments and keyword arguments.\n+            args = func.args + args\n+            kwargs = {**func.keywords, **kwargs} if func.keywords else {**kwargs}\n+            func = func.func\n+\n+        self.func = func\n+        self.args = args\n+        self.kwargs = kwargs\n \n         if not hasattr(func, '__name__'):\n             # A class-based view\n"}
{"instance_id": "django__django-11820", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 3ce711f3f1..c7a0f26c0b 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -1712,7 +1712,8 @@ class Model(metaclass=ModelBase):\n                     if fld.is_relation:\n                         _cls = fld.get_path_info()[-1].to_opts.model\n                 except (FieldDoesNotExist, AttributeError):\n-                    if fld is None or fld.get_transform(part) is None:\n+                    # 'pk' is a valid alias for the primary key.\n+                    if part != 'pk' and (fld is None or fld.get_transform(part) is None):\n                         errors.append(\n                             checks.Error(\n                                 \"'ordering' refers to the nonexistent field, \"\n"}
{"instance_id": "django__django-13809", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/core/management/commands/runserver.py b/django/core/management/commands/runserver.py\nindex d9fb088350..8dddcf33d8 100644\n--- a/django/core/management/commands/runserver.py\n+++ b/django/core/management/commands/runserver.py\n@@ -51,6 +51,10 @@ class Command(BaseCommand):\n             '--noreload', action='store_false', dest='use_reloader',\n             help='Tells Django to NOT use the auto-reloader.',\n         )\n+        parser.add_argument(\n+            '--skip-checks', action='store_true',\n+            help='Skip system checks.',\n+        )\n \n     def execute(self, *args, **options):\n         if options['no_color']:\n@@ -114,8 +118,10 @@ class Command(BaseCommand):\n         shutdown_message = options.get('shutdown_message', '')\n         quit_command = 'CTRL-BREAK' if sys.platform == 'win32' else 'CONTROL-C'\n \n-        self.stdout.write(\"Performing system checks...\\n\\n\")\n-        self.check(display_num_errors=True)\n+        skip_checks = options.get('skip_checks')\n+        if not skip_checks:\n+            self.stdout.write(\"Performing system checks...\\n\\n\")\n+            self.check(display_num_errors=True)\n         # Need to check migrations here, so can't use the\n         # requires_migrations_check attribute.\n         self.check_migrations()\n"}
{"instance_id": "sphinx-doc__sphinx-11510", "model_name_or_path": "devchain", "model_patch": "diff --git a/sphinx/directives/other.py b/sphinx/directives/other.py\nindex 19f7c0a8d..3a6dc546a 100644\n--- a/sphinx/directives/other.py\n+++ b/sphinx/directives/other.py\n@@ -376,7 +376,42 @@ class Include(BaseInclude, SphinxDirective):\n         rel_filename, filename = self.env.relfn2path(self.arguments[0])\n         self.arguments[0] = filename\n         self.env.note_included(filename)\n-        return super().run()\n+\n+        # Patch io.FileInput to emit the source-read event for included files\n+        # This allows extensions to modify the content of included files via the\n+        # source-read event, just like they can for regular documents.\n+        from docutils import io as docutils_io\n+        from os.path import realpath\n+\n+        original_file_input = docutils_io.FileInput\n+        env = self.env\n+        # Normalize the filename for comparison\n+        target_path = realpath(filename)\n+\n+        class PatchedFileInput(original_file_input):\n+            def read(self):\n+                content = super().read()\n+                # Check if this is the included file we're looking for\n+                if hasattr(self, 'source_path'):\n+                    # Normalize both paths for comparison\n+                    try:\n+                        current_path = realpath(str(self.source_path))\n+                        if current_path == target_path:\n+                            docname = env.path2doc(target_path)\n+                            if docname:\n+                                # Emit the source-read event for the included file\n+                                arg = [content]\n+                                env.events.emit('source-read', docname, arg)\n+                                content = arg[0]\n+                    except Exception:\n+                        pass\n+                return content\n+\n+        docutils_io.FileInput = PatchedFileInput\n+        try:\n+            return super().run()\n+        finally:\n+            docutils_io.FileInput = original_file_input\n \n \n def setup(app: Sphinx) -> dict[str, Any]:\n"}
{"instance_id": "django__django-16667", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 842b73e95c..f4bc74b7cd 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -1157,7 +1157,7 @@ class SelectDateWidget(Widget):\n             input_format = formats.sanitize_strftime_format(input_format)\n             try:\n                 date_value = datetime.date(int(y), int(m), int(d))\n-            except ValueError:\n+            except (ValueError, OverflowError):\n                 # Return pseudo-ISO dates with zeros for any unselected values,\n                 # e.g. '2017-0-23'.\n                 return \"%s-%s-%s\" % (y or 0, m or 0, d or 0)\n"}
{"instance_id": "matplotlib__matplotlib-24970", "model_name_or_path": "devchain", "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2d3072da04..c9d13305d7 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -725,6 +725,12 @@ class Colormap:\n                 # Avoid converting large positive values to negative integers.\n                 np.clip(xa, -1, self.N, out=xa)\n                 xa = xa.astype(int)\n+        elif xa.dtype.kind in (\"i\", \"u\"):\n+            # Ensure integer arrays can hold sentinel values (_i_over, _i_under,\n+            # _i_bad) which can be larger than the input dtype can represent.\n+            i_max = np.iinfo(xa.dtype).max\n+            if i_max < self.N + 2:\n+                xa = xa.astype(int)\n         # Set the over-range indices before the under-range;\n         # otherwise the under-range values get converted to over-range.\n         xa[xa > self.N - 1] = self._i_over\n"}
{"instance_id": "pylint-dev__pylint-4661", "model_name_or_path": "devchain", "model_patch": "diff --git a/doc/faq.rst b/doc/faq.rst\nindex c817855f8..4e2181dc7 100644\n--- a/doc/faq.rst\n+++ b/doc/faq.rst\n@@ -93,10 +93,11 @@ localized using the following rules:\n \n * value of the PYLINTHOME environment variable if set\n \n-* \".pylint.d\" subdirectory of the user's home directory if it is found\n-\t(not always findable on Windows platforms)\n+* \"pylint\" subdirectory of the XDG_DATA_HOME directory if set\n+  (following the XDG Base Directory Specification)\n \n-* \".pylint.d\" directory in the current directory\n+* \".pylint.d\" subdirectory of the user's home directory\n+\t(default location for backward compatibility)\n \n 3.3 How do I find the option name (for pylintrc) corresponding to a specific command line option?\n --------------------------------------------------------------------------------------------------------\ndiff --git a/pylint/config/__init__.py b/pylint/config/__init__.py\nindex 84774d0e3..08e2637ab 100644\n--- a/pylint/config/__init__.py\n+++ b/pylint/config/__init__.py\n@@ -63,7 +63,15 @@ if \"PYLINTHOME\" in os.environ:\n elif USER_HOME == \"~\":\n     PYLINT_HOME = \".pylint.d\"\n else:\n-    PYLINT_HOME = os.path.join(USER_HOME, \".pylint.d\")\n+    # Check for XDG Base Directory Specification support\n+    # $XDG_DATA_HOME defines the base directory for user-specific data files\n+    # If $XDG_DATA_HOME is set, use XDG-compliant path\n+    xdg_data_home = os.environ.get(\"XDG_DATA_HOME\", \"\")\n+    if xdg_data_home:\n+        PYLINT_HOME = os.path.join(xdg_data_home, \"pylint\")\n+    else:\n+        # Default to traditional location for backward compatibility\n+        PYLINT_HOME = os.path.join(USER_HOME, \".pylint.d\")\n \n \n def _get_pdata_path(base_name, recurs):\n@@ -110,8 +118,8 @@ ENV_HELP = (\n The following environment variables are used:\n     * PYLINTHOME\n     Path to the directory where persistent data for the run will be stored. If\n-not found, it defaults to ~/.pylint.d/ or .pylint.d (in the current working\n-directory).\n+not found, it defaults to ~/.local/share/pylint/ or .pylint.d (in the current\n+working directory) following the XDG Base Directory Specification.\n     * PYLINTRC\n     Path to the configuration file. See the documentation for the method used\n to search for configuration file.\n"}
{"instance_id": "astropy__astropy-13977", "model_name_or_path": "devchain", "model_patch": "diff --git a/astropy/units/quantity.py b/astropy/units/quantity.py\nindex b98abfafb0..f78fba00d5 100644\n--- a/astropy/units/quantity.py\n+++ b/astropy/units/quantity.py\n@@ -667,7 +667,14 @@ class Quantity(np.ndarray):\n         arrays = []\n         for input_, converter in zip(inputs, converters):\n             input_ = getattr(input_, \"value\", input_)\n-            arrays.append(converter(input_) if converter else input_)\n+            if converter is not None:\n+                try:\n+                    input_ = converter(input_)\n+                except (UnitConversionError, TypeError, ValueError):\n+                    # Cannot convert this input (e.g., incompatible duck array).\n+                    # Return NotImplemented to allow the other operand to try.\n+                    return NotImplemented\n+            arrays.append(input_)\n \n         # Call our superclass's __array_ufunc__\n         result = super().__array_ufunc__(function, method, *arrays, **kwargs)\n"}
{"instance_id": "pydata__xarray-6599", "model_name_or_path": "devchain", "model_patch": "diff --git a/xarray/core/computation.py b/xarray/core/computation.py\nindex 823cbe02..47612dac 100644\n--- a/xarray/core/computation.py\n+++ b/xarray/core/computation.py\n@@ -1930,14 +1930,22 @@ def _ensure_numeric(data: T_Xarray) -> T_Xarray:\n     DataArray or Dataset\n         Variables with datetime64 dtypes converted to float64.\n     \"\"\"\n+    from .dataarray import DataArray\n     from .dataset import Dataset\n \n     def to_floatable(x: DataArray) -> DataArray:\n         if x.dtype.kind in \"mM\":\n+            # For datetime64 ('M'), use datetime offset.\n+            # For timedelta64 ('m'), use timedelta offset.\n+            offset = (\n+                np.timedelta64(0, \"ns\")\n+                if x.dtype.kind == \"m\"\n+                else np.datetime64(\"1970-01-01\")\n+            )\n             return x.copy(\n                 data=datetime_to_numeric(\n                     x.data,\n-                    offset=np.datetime64(\"1970-01-01\"),\n+                    offset=offset,\n                     datetime_unit=\"ns\",\n                 ),\n             )\n@@ -1946,6 +1954,22 @@ def _ensure_numeric(data: T_Xarray) -> T_Xarray:\n     if isinstance(data, Dataset):\n         return data.map(to_floatable)\n     else:\n+        # Special handling for DataArray with datetime64 data and timedelta64 dimension coordinate:\n+        # When evaluating a polynomial at datetime values that have a timedelta64 coordinate,\n+        # use the coordinate values (relative times) instead of the data (absolute timestamps).\n+        if isinstance(data, DataArray) and data.dtype.kind == \"M\":\n+            # Only for 1D case where the dimension coordinate is timedelta64\n+            if data.ndim == 1:\n+                dim = data.dims[0]\n+                if dim in data.coords and data.coords[dim].dtype.kind == \"m\":\n+                    coord_array = data.coords[dim]\n+                    return data.copy(\n+                        data=datetime_to_numeric(\n+                            coord_array.data,\n+                            offset=np.timedelta64(0, \"ns\"),\n+                            datetime_unit=\"ns\",\n+                        ),\n+                    )\n         return to_floatable(data)\n \n \n"}
{"instance_id": "sphinx-doc__sphinx-7462", "model_name_or_path": "devchain", "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 3ca730e30..e3acea4a1 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -100,7 +100,8 @@ def _parse_annotation(annotation: str) -> List[Node]:\n             for elem in node.elts:\n                 result.extend(unparse(elem))\n                 result.append(addnodes.desc_sig_punctuation('', ', '))\n-            result.pop()\n+            if node.elts:\n+                result.pop()\n             result.append(addnodes.desc_sig_punctuation('', ']'))\n             return result\n         elif isinstance(node, ast.Module):\n@@ -118,8 +119,13 @@ def _parse_annotation(annotation: str) -> List[Node]:\n             for elem in node.elts:\n                 result.extend(unparse(elem))\n                 result.append(addnodes.desc_sig_punctuation('', ', '))\n-            result.pop()\n-            return result\n+            if result:\n+                result.pop()\n+                return result\n+            else:\n+                # Empty tuple: return ()\n+                return [addnodes.desc_sig_punctuation('', '('),\n+                        addnodes.desc_sig_punctuation('', ')')]\n         else:\n             raise SyntaxError  # unsupported syntax\n \n"}
{"instance_id": "django__django-14315", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/backends/base/client.py b/django/db/backends/base/client.py\nindex 339f1e863c..8aca821fd2 100644\n--- a/django/db/backends/base/client.py\n+++ b/django/db/backends/base/client.py\n@@ -21,6 +21,5 @@ class BaseDatabaseClient:\n \n     def runshell(self, parameters):\n         args, env = self.settings_to_cmd_args_env(self.connection.settings_dict, parameters)\n-        if env:\n-            env = {**os.environ, **env}\n+        env = {**os.environ, **env} if env else None\n         subprocess.run(args, env=env, check=True)\ndiff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 3effab65a8..0effcc44e6 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -51,7 +51,7 @@ class DatabaseClient(BaseDatabaseClient):\n             env['PGSSLKEY'] = str(sslkey)\n         if passfile:\n             env['PGPASSFILE'] = str(passfile)\n-        return args, env\n+        return args, (env or None)\n \n     def runshell(self, parameters):\n         sigint_handler = signal.getsignal(signal.SIGINT)\n"}
{"instance_id": "mwaskom__seaborn-3069", "model_name_or_path": "devchain", "model_patch": "diff --git a/seaborn/_core/plot.py b/seaborn/_core/plot.py\nindex 4f0290a4..e0c281a1 100644\n--- a/seaborn/_core/plot.py\n+++ b/seaborn/_core/plot.py\n@@ -1475,21 +1475,24 @@ class Plotter:\n \n                 axes_df = self._filter_subplot_data(df, view)\n \n-                with pd.option_context(\"mode.use_inf_as_null\", True):\n-                    if keep_na:\n-                        # The simpler thing to do would be x.dropna().reindex(x.index).\n-                        # But that doesn't work with the way that the subset iteration\n-                        # is written below, which assumes data for grouping vars.\n-                        # Matplotlib (usually?) masks nan data, so this should \"work\".\n-                        # Downstream code can also drop these rows, at some speed cost.\n-                        present = axes_df.notna().all(axis=1)\n-                        nulled = {}\n-                        for axis in \"xy\":\n-                            if axis in axes_df:\n-                                nulled[axis] = axes_df[axis].where(present)\n-                        axes_df = axes_df.assign(**nulled)\n-                    else:\n-                        axes_df = axes_df.dropna()\n+                # pandas 2.0+ removed mode.use_inf_as_null option\n+                # We now need to handle inf values explicitly\n+                axes_df = axes_df.replace([float('inf'), -float('inf')], float('nan'))\n+\n+                if keep_na:\n+                    # The simpler thing to do would be x.dropna().reindex(x.index).\n+                    # But that doesn't work with the way that the subset iteration\n+                    # is written below, which assumes data for grouping vars.\n+                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n+                    # Downstream code can also drop these rows, at some speed cost.\n+                    present = axes_df.notna().all(axis=1)\n+                    nulled = {}\n+                    for axis in \"xy\":\n+                        if axis in axes_df:\n+                            nulled[axis] = axes_df[axis].where(present)\n+                    axes_df = axes_df.assign(**nulled)\n+                else:\n+                    axes_df = axes_df.dropna()\n \n                 subplot_keys = {}\n                 for dim in [\"col\", \"row\"]:\n@@ -1626,12 +1629,17 @@ class Plotter:\n                 self._figure.legends.append(legend)\n \n     def _finalize_figure(self, p: Plot) -> None:\n+        from seaborn._core.scales import Nominal\n \n         for sub in self._subplots:\n             ax = sub[\"ax\"]\n             for axis in \"xy\":\n                 axis_key = sub[axis]\n \n+                # Check if this axis has a Nominal scale\n+                scale = self._scales.get(axis_key)\n+                is_nominal = isinstance(scale, Nominal)\n+\n                 # Axis limits\n                 if axis_key in p._limits:\n                     convert_units = getattr(ax, f\"{axis}axis\").convert_units\n@@ -1644,6 +1652,26 @@ class Plotter:\n                         hi = cast(float, hi) + 0.5\n                     ax.set(**{f\"{axis}lim\": (lo, hi)})\n \n+                # Nominal scales should behave like categorical plots\n+                if is_nominal:\n+                    # Disable grid lines (like categorical plots)\n+                    getattr(ax, f\"{axis}axis\").grid(False)\n+\n+                    # Only set automatic limits if no explicit limits were provided\n+                    if axis_key not in p._limits:\n+                        # Get the number of categories from the number of ticks\n+                        # (matches the approach in categorical.py)\n+                        n = len(getattr(ax, f\"get_{axis}ticks\")())\n+\n+                        # Set limits with +/- 0.5 margin (like categorical plots)\n+                        if axis == \"x\":\n+                            ax.set_xlim(-0.5, n - 0.5, auto=None)\n+                        else:\n+                            # For y axis, set reversed limits directly\n+                            # This matches the behavior in categorical.py:_adjust_cat_axis\n+                            # Note: limits that correspond to previously-inverted y axis\n+                            ax.set_ylim(n - 0.5, -0.5, auto=None)\n+\n         engine_default = None if p._target is not None else \"tight\"\n         layout_engine = p._layout_spec.get(\"engine\", engine_default)\n         set_layout_engine(self._figure, layout_engine)\n"}
{"instance_id": "pytest-dev__pytest-10356", "model_name_or_path": "devchain", "model_patch": "diff --git a/src/_pytest/mark/structures.py b/src/_pytest/mark/structures.py\nindex 800a25c92..a653cc81e 100644\n--- a/src/_pytest/mark/structures.py\n+++ b/src/_pytest/mark/structures.py\n@@ -356,7 +356,25 @@ class MarkDecorator:\n \n \n def get_unpacked_marks(obj: object) -> Iterable[Mark]:\n-    \"\"\"Obtain the unpacked marks that are stored on an object.\"\"\"\n+    \"\"\"Obtain the unpacked marks that are stored on an object.\n+\n+    For classes, this will also collect marks from base classes according to\n+    the MRO (Method Resolution Order).\n+    \"\"\"\n+    # For classes, collect marks from all classes in the MRO\n+    if inspect.isclass(obj):\n+        # Collect marks in MRO order (from most derived to least derived).\n+        # This ensures that marks from derived classes come before marks from\n+        # base classes, consistent with how Python's MRO works.\n+        mark_list = []\n+        for cls in obj.__mro__:\n+            cls_marks = getattr(cls, \"__dict__\", {}).get(\"pytestmark\", [])\n+            if cls_marks:\n+                if not isinstance(cls_marks, list):\n+                    cls_marks = [cls_marks]\n+                mark_list.extend(normalize_mark_list(cls_marks))\n+        return mark_list\n+\n     mark_list = getattr(obj, \"pytestmark\", [])\n     if not isinstance(mark_list, list):\n         mark_list = [mark_list]\n@@ -388,7 +406,14 @@ def store_mark(obj, mark: Mark) -> None:\n     assert isinstance(mark, Mark), mark\n     # Always reassign name to avoid updating pytestmark in a reference that\n     # was only borrowed.\n-    obj.pytestmark = [*get_unpacked_marks(obj), mark]\n+    # Only look at the direct pytestmark attribute in the object's __dict__,\n+    # not inherited marks from parent classes.\n+    existing_mark_list = obj.__dict__.get(\"pytestmark\", [])\n+    if not isinstance(existing_mark_list, list):\n+        existing_mark_list = [existing_mark_list]\n+    # Normalize existing marks to Mark objects\n+    existing_marks = list(normalize_mark_list(existing_mark_list))\n+    obj.pytestmark = [*existing_marks, mark]\n \n \n # Typing for builtin pytest marks. This is cheating; it gives builtin marks\n"}
{"instance_id": "django__django-13513", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/views/debug.py b/django/views/debug.py\nindex bc95cbf6b0..770a774346 100644\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -391,8 +391,9 @@ class ExceptionReporter:\n     def get_traceback_frames(self):\n         def explicit_or_implicit_cause(exc_value):\n             explicit = getattr(exc_value, '__cause__', None)\n+            suppress_context = getattr(exc_value, '__suppress_context__', None)\n             implicit = getattr(exc_value, '__context__', None)\n-            return explicit or implicit\n+            return explicit or (None if suppress_context else implicit)\n \n         # Get the exception and all its causes\n         exceptions = []\n"}
{"instance_id": "django__django-12273", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 844c01e95e..310f61a785 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -569,7 +569,17 @@ class Model(metaclass=ModelBase):\n         return getattr(self, meta.pk.attname)\n \n     def _set_pk_val(self, value):\n-        return setattr(self, self._meta.pk.attname, value)\n+        setattr(self, self._meta.pk.attname, value)\n+        # If the primary key is a link to a parent model (multi-table\n+        # inheritance), also update the value of the parent's primary key.\n+        # This is the reverse of the sync that happens in\n+        # ForwardOneToOneDescriptor.__set__ when setting the parent link.\n+        opts = self._meta\n+        for parent in opts.parents:\n+            link_field = opts.parents[parent]\n+            if link_field and link_field == opts.pk and link_field.remote_field.parent_link:\n+                # The primary key is a parent link, so sync the parent's PK.\n+                setattr(self, parent._meta.pk.attname, value)\n \n     pk = property(_get_pk_val, _set_pk_val)\n \ndiff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex 96409cc67c..3bc752685b 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -151,6 +151,26 @@ class DeferredAttribute:\n             data[field_name] = val\n         return data[field_name]\n \n+    def __set__(self, instance, value):\n+        \"\"\"\n+        Set the value on the instance. If the field is a primary key from an\n+        ancestor model and the instance's class uses multi-table inheritance,\n+        also update the instance's primary key field.\n+        \"\"\"\n+        instance.__dict__[self.field.attname] = value\n+        # If this field is a primary key from an ancestor model, also set the\n+        # value on the descendant model's primary key field. This is required\n+        # for multi-table inheritance where the descendant's primary key is a\n+        # OneToOneField pointing to the ancestor.\n+        if self.field.primary_key:\n+            opts = instance._meta\n+            link_field = opts.get_ancestor_link(self.field.model)\n+            # link_field is the OneToOneField on the descendant that points to\n+            # this ancestor. If this field's model is different from the\n+            # instance's model, we're in a multi-table inheritance scenario.\n+            if link_field and self.field != link_field:\n+                setattr(instance, link_field.attname, value)\n+\n     def _check_parent_chain(self, instance):\n         \"\"\"\n         Check if the field value can be fetched from a parent field already\n"}
{"instance_id": "django__django-16502", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/core/handlers/asgi.py b/django/core/handlers/asgi.py\nindex 39e2abe5a9..e7e9d7c797 100644\n--- a/django/core/handlers/asgi.py\n+++ b/django/core/handlers/asgi.py\n@@ -186,6 +186,18 @@ class ASGIHandler(base.BaseHandler):\n         # chunking).\n         if isinstance(response, FileResponse):\n             response.block_size = self.chunk_size\n+        # Strip the content for HEAD requests, 1xx, 204, and 304 responses\n+        # to ensure compliance with RFC 9112 Section 6.3.\n+        if 100 <= response.status_code < 200 or response.status_code in (204, 304):\n+            if response.streaming:\n+                response.streaming_content = []\n+            else:\n+                response.content = b\"\"\n+        if request.method == \"HEAD\":\n+            if response.streaming:\n+                response.streaming_content = []\n+            else:\n+                response.content = b\"\"\n         # Send the response.\n         await self.send_response(response, send)\n \ndiff --git a/django/core/handlers/wsgi.py b/django/core/handlers/wsgi.py\nindex c2b7cc2b6f..6d2b423242 100644\n--- a/django/core/handlers/wsgi.py\n+++ b/django/core/handlers/wsgi.py\n@@ -135,6 +135,19 @@ class WSGIHandler(base.BaseHandler):\n \n         response._handler_class = self.__class__\n \n+        # Strip the content for HEAD requests, 1xx, 204, and 304 responses\n+        # to ensure compliance with RFC 9112 Section 6.3.\n+        if 100 <= response.status_code < 200 or response.status_code in (204, 304):\n+            if response.streaming:\n+                response.streaming_content = []\n+            else:\n+                response.content = b\"\"\n+        if request.method == \"HEAD\":\n+            if response.streaming:\n+                response.streaming_content = []\n+            else:\n+                response.content = b\"\"\n+\n         status = \"%d %s\" % (response.status_code, response.reason_phrase)\n         response_headers = [\n             *response.items(),\n"}
{"instance_id": "django__django-14725", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 75b0646512..92832ed886 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -478,7 +478,7 @@ class BaseFormSet(RenderableFormMixin):\n def formset_factory(form, formset=BaseFormSet, extra=1, can_order=False,\n                     can_delete=False, max_num=None, validate_max=False,\n                     min_num=None, validate_min=False, absolute_max=None,\n-                    can_delete_extra=True, renderer=None):\n+                    can_delete_extra=True, can_add=True, renderer=None):\n     \"\"\"Return a FormSet for the given form class.\"\"\"\n     if min_num is None:\n         min_num = DEFAULT_MIN_NUM\n@@ -499,6 +499,7 @@ def formset_factory(form, formset=BaseFormSet, extra=1, can_order=False,\n         'can_order': can_order,\n         'can_delete': can_delete,\n         'can_delete_extra': can_delete_extra,\n+        'can_add': can_add,\n         'min_num': min_num,\n         'max_num': max_num,\n         'absolute_max': absolute_max,\ndiff --git a/django/forms/models.py b/django/forms/models.py\nindex 7effb202e3..4eb6f7a96d 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -681,6 +681,20 @@ class BaseModelFormSet(BaseFormSet):\n     save.alters_data = True\n \n     def clean(self):\n+        # Check if new objects are submitted when can_add is False\n+        if not getattr(self, 'can_add', True):\n+            for form in self.extra_forms:\n+                # Ignore extra forms that haven't changed or are marked for deletion\n+                if not form.has_changed():\n+                    continue\n+                if self.can_delete and self._should_delete_form(form):\n+                    continue\n+                # This extra form has changed and is not marked for deletion\n+                # but can_add is False, so raise an error\n+                raise ValidationError(\n+                    \"Please correct the duplicate data below.\",\n+                    code='cant_add',\n+                )\n         self.validate_unique()\n \n     def validate_unique(self):\n@@ -820,6 +834,9 @@ class BaseModelFormSet(BaseFormSet):\n             # object.\n             if self.can_delete and self._should_delete_form(form):\n                 continue\n+            # If can_add is False, don't save new objects.\n+            if not getattr(self, 'can_add', True):\n+                continue\n             self.new_objects.append(self.save_new(form, commit=commit))\n             if not commit:\n                 self.saved_forms.append(form)\n@@ -875,7 +892,8 @@ def modelformset_factory(model, form=ModelForm, formfield_callback=None,\n                          widgets=None, validate_max=False, localized_fields=None,\n                          labels=None, help_texts=None, error_messages=None,\n                          min_num=None, validate_min=False, field_classes=None,\n-                         absolute_max=None, can_delete_extra=True, renderer=None):\n+                         absolute_max=None, can_delete_extra=True, can_add=True,\n+                         renderer=None):\n     \"\"\"Return a FormSet class for the given Django model class.\"\"\"\n     meta = getattr(form, 'Meta', None)\n     if (getattr(meta, 'fields', fields) is None and\n@@ -894,7 +912,7 @@ def modelformset_factory(model, form=ModelForm, formfield_callback=None,\n                               can_order=can_order, can_delete=can_delete,\n                               validate_min=validate_min, validate_max=validate_max,\n                               absolute_max=absolute_max, can_delete_extra=can_delete_extra,\n-                              renderer=renderer)\n+                              can_add=can_add, renderer=renderer)\n     FormSet.model = model\n     return FormSet\n \n@@ -1076,7 +1094,8 @@ def inlineformset_factory(parent_model, model, form=ModelForm,\n                           widgets=None, validate_max=False, localized_fields=None,\n                           labels=None, help_texts=None, error_messages=None,\n                           min_num=None, validate_min=False, field_classes=None,\n-                          absolute_max=None, can_delete_extra=True, renderer=None):\n+                          absolute_max=None, can_delete_extra=True, can_add=True,\n+                          renderer=None):\n     \"\"\"\n     Return an ``InlineFormSet`` for the given kwargs.\n \n@@ -1108,6 +1127,7 @@ def inlineformset_factory(parent_model, model, form=ModelForm,\n         'field_classes': field_classes,\n         'absolute_max': absolute_max,\n         'can_delete_extra': can_delete_extra,\n+        'can_add': can_add,\n         'renderer': renderer,\n     }\n     FormSet = modelformset_factory(model, **kwargs)\n"}
{"instance_id": "pydata__xarray-6992", "model_name_or_path": "devchain", "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 620f32f8..b89792fb 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -365,7 +365,7 @@ class DataVariables(Mapping[Any, \"DataArray\"]):\n         )\n \n     def __len__(self) -> int:\n-        return len(self._dataset._variables) - len(self._dataset._coord_names)\n+        return sum(1 for key in self._dataset._variables if key not in self._dataset._coord_names)\n \n     def __contains__(self, key: Hashable) -> bool:\n         return key in self._dataset._variables and key not in self._dataset._coord_names\n"}
{"instance_id": "mwaskom__seaborn-3187", "model_name_or_path": "devchain", "model_patch": "diff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\nindex 55874bf2..18a55faf 100644\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -379,6 +379,26 @@ class ContinuousBase(Scale):\n             locs = axis.major.locator()\n             locs = locs[(vmin <= locs) & (locs <= vmax)]\n             labels = axis.major.formatter.format_ticks(locs)\n+            # Account for formatter offset (e.g., 1e6) in legend labels\n+            offset = axis.major.formatter.get_offset()\n+            if offset:\n+                # Parse the offset string and combine with labels\n+                # Offset can be '1e6', '\u00d710\u2076', or similar formats\n+                offset_lower = offset.lower()\n+                if 'e' in offset_lower and '\u00d7' not in offset:\n+                    # Format like '1e6' -> append 'e6' to each label\n+                    parts = offset_lower.split('e')\n+                    if len(parts) == 2:\n+                        exponent = parts[1]\n+                        labels = [f\"{label}e{exponent}\" for label in labels]\n+                elif '\u00d710' in offset or 'x10' in offset_lower:\n+                    # Unicode format like '\u00d710\u2076' -> convert to 'e6' format\n+                    import re\n+                    match = re.search(r'[\u00d7x]10(.+)', offset)\n+                    if match:\n+                        superscript_map = str.maketrans('\u2070\u00b9\u00b2\u00b3\u2074\u2075\u2076\u2077\u2078\u2079', '0123456789')\n+                        exponent = match.group(1).translate(superscript_map)\n+                        labels = [f\"{label}e{exponent}\" for label in labels]\n             new._legend = list(locs), list(labels)\n \n         return new\ndiff --git a/seaborn/utils.py b/seaborn/utils.py\nindex 2407853c..f7608715 100644\n--- a/seaborn/utils.py\n+++ b/seaborn/utils.py\n@@ -707,6 +707,27 @@ def locator_to_legend_entries(locator, limits, dtype):\n     formatter.set_locs(raw_levels)\n     formatted_levels = [formatter(x) for x in raw_levels]\n \n+    # Account for formatter offset (e.g., 1e6) in formatted levels\n+    offset = formatter.get_offset()\n+    if offset:\n+        # Parse the offset string and combine with labels\n+        # Offset can be '1e6', '\u00d710\u2076', or similar formats\n+        offset_lower = offset.lower()\n+        if 'e' in offset_lower and '\u00d7' not in offset:\n+            # Format like '1e6' -> append 'e6' to each label\n+            parts = offset_lower.split('e')\n+            if len(parts) == 2:\n+                exponent = parts[1]\n+                formatted_levels = [f\"{label}e{exponent}\" for label in formatted_levels]\n+        elif '\u00d710' in offset or 'x10' in offset_lower:\n+            # Unicode format like '\u00d710\u2076' -> convert to 'e6' format\n+            import re\n+            match = re.search(r'[\u00d7x]10(.+)', offset)\n+            if match:\n+                superscript_map = str.maketrans('\u2070\u00b9\u00b2\u00b3\u2074\u2075\u2076\u2077\u2078\u2079', '0123456789')\n+                exponent = match.group(1).translate(superscript_map)\n+                formatted_levels = [f\"{label}e{exponent}\" for label in formatted_levels]\n+\n     return raw_levels, formatted_levels\n \n \n"}
{"instance_id": "sympy__sympy-13974", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/core/power.py b/sympy/core/power.py\nindex 02ec6480cb..49e52594a9 100644\n--- a/sympy/core/power.py\n+++ b/sympy/core/power.py\n@@ -1062,6 +1062,19 @@ def _eval_expand_multinomial(self, **hints):\n         else:\n             return result\n \n+    def _eval_expand_tensorproduct(self, **hints):\n+        \"\"\"Handle expansion of tensor product powers.\n+        For TensorProduct(A, B)**n where n is an integer, distribute\n+        the power to get TensorProduct(A**n, B**n).\n+        \"\"\"\n+        from sympy.physics.quantum import TensorProduct\n+        base = self.base\n+        exp = self.exp\n+        # Only distribute for integer exponents\n+        if isinstance(base, TensorProduct) and exp.is_integer:\n+            return TensorProduct(*[arg**exp for arg in base.args])\n+        return self\n+\n     def as_real_imag(self, deep=True, **hints):\n         from sympy import atan2, cos, im, re, sin\n         from sympy.polys.polytools import poly\ndiff --git a/sympy/physics/quantum/tensorproduct.py b/sympy/physics/quantum/tensorproduct.py\nindex 9dd10d219e..bb04ea07f6 100644\n--- a/sympy/physics/quantum/tensorproduct.py\n+++ b/sympy/physics/quantum/tensorproduct.py\n@@ -382,7 +382,12 @@ def tensor_product_simp(e, **hints):\n     if isinstance(e, Add):\n         return Add(*[tensor_product_simp(arg) for arg in e.args])\n     elif isinstance(e, Pow):\n-        return tensor_product_simp(e.base) ** e.exp\n+        base = tensor_product_simp(e.base)\n+        exp = e.exp\n+        # If base is a TensorProduct with integer exponent, distribute the power\n+        if isinstance(base, TensorProduct) and exp.is_integer:\n+            return TensorProduct(*[arg**exp for arg in base.args])\n+        return base ** exp\n     elif isinstance(e, Mul):\n         return tensor_product_simp_Mul(e)\n     elif isinstance(e, Commutator):\n"}
{"instance_id": "django__django-15127", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/contrib/messages/storage/base.py b/django/contrib/messages/storage/base.py\nindex 01422066a6..a46c57cd53 100644\n--- a/django/contrib/messages/storage/base.py\n+++ b/django/contrib/messages/storage/base.py\n@@ -38,7 +38,7 @@ class Message:\n \n     @property\n     def level_tag(self):\n-        return LEVEL_TAGS.get(self.level, '')\n+        return utils.get_level_tags().get(self.level, '')\n \n \n class BaseStorage:\n"}
{"instance_id": "sphinx-doc__sphinx-8056", "model_name_or_path": "devchain", "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex b3daa06f1..97a6549f6 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -394,13 +394,19 @@ class GoogleDocstring:\n             _desc = self._strip_empty(_desc)\n             if any(_desc):\n                 _desc = self._fix_field_desc(_desc)\n-                field = ':%s %s: ' % (field_role, _name)\n-                lines.extend(self._format_block(field, _desc))\n-            else:\n-                lines.append(':%s %s:' % (field_role, _name))\n \n-            if _type:\n-                lines.append(':%s %s: %s' % (type_role, _name, _type))\n+            # Handle comma-separated parameter names (e.g., \"x1, x2, x3\")\n+            _names = [n.strip() for n in _name.split(\", \")] if \", \" in _name else [_name]\n+\n+            for _name_item in _names:\n+                if any(_desc):\n+                    field = ':%s %s: ' % (field_role, _name_item)\n+                    lines.extend(self._format_block(field, _desc))\n+                else:\n+                    lines.append(':%s %s:' % (field_role, _name_item))\n+\n+                if _type:\n+                    lines.append(':%s %s: %s' % (type_role, _name_item, _type))\n         return lines + ['']\n \n     def _format_field(self, _name: str, _type: str, _desc: List[str]) -> List[str]:\n"}
{"instance_id": "matplotlib__matplotlib-24870", "model_name_or_path": "devchain", "model_patch": "diff --git a/lib/matplotlib/contour.py b/lib/matplotlib/contour.py\nindex 144eadeae2..e1ecc1fd06 100644\n--- a/lib/matplotlib/contour.py\n+++ b/lib/matplotlib/contour.py\n@@ -1123,7 +1123,13 @@ class ContourSet(cm.ScalarMappable, ContourLabeler):\n         \"\"\"\n         if self.levels is None:\n             if len(args) == 0:\n-                levels_arg = 7  # Default, hard-wired.\n+                # For boolean arrays with line contours, default to [0.5]\n+                # instead of 7 levels. Filled contours require at least 2\n+                # levels, so this auto-detection is not applied to them.\n+                if getattr(self, '_bool_contour', False) and not self.filled:\n+                    levels_arg = [0.5]\n+                else:\n+                    levels_arg = 7  # Default, hard-wired.\n             else:\n                 levels_arg = args[0]\n         else:\n@@ -1447,6 +1453,8 @@ class QuadContourSet(ContourSet):\n             fn = 'contour'\n         nargs = len(args)\n         if nargs <= 2:\n+            # Check if input is boolean before conversion\n+            self._bool_contour = np.asarray(args[0]).dtype == np.bool_\n             z = ma.asarray(args[0], dtype=np.float64)\n             x, y = self._initialize_x_y(z)\n             args = args[1:]\n@@ -1475,6 +1483,8 @@ class QuadContourSet(ContourSet):\n \n         x = np.asarray(x, dtype=np.float64)\n         y = np.asarray(y, dtype=np.float64)\n+        # Check if z is boolean before conversion\n+        self._bool_contour = np.asarray(args[2]).dtype == np.bool_\n         z = ma.asarray(args[2], dtype=np.float64)\n \n         if z.ndim != 2:\n"}
{"instance_id": "django__django-13297", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/backends/sqlite3/base.py b/django/db/backends/sqlite3/base.py\nindex 8a105d4f35..5c6fa96f59 100644\n--- a/django/db/backends/sqlite3/base.py\n+++ b/django/db/backends/sqlite3/base.py\n@@ -23,6 +23,7 @@ from django.utils import timezone\n from django.utils.asyncio import async_unsafe\n from django.utils.dateparse import parse_datetime, parse_time\n from django.utils.duration import duration_microseconds\n+from django.utils.functional import SimpleLazyObject\n from django.utils.regex_helper import _lazy_re_compile\n from django.utils.version import PY38\n \n@@ -77,6 +78,17 @@ Database.register_converter(\"timestamp\", decoder(parse_datetime))\n Database.register_adapter(decimal.Decimal, str)\n \n \n+def adapt_simple_lazy_object(value):\n+    \"\"\"Unwrap SimpleLazyObject before passing to sqlite3.\"\"\"\n+    # Force evaluation of the lazy object by accessing __class__ (a proxy property)\n+    # which triggers _setup() if the object hasn't been evaluated yet.\n+    value.__class__\n+    return value._wrapped\n+\n+\n+Database.register_adapter(SimpleLazyObject, adapt_simple_lazy_object)\n+\n+\n class DatabaseWrapper(BaseDatabaseWrapper):\n     vendor = 'sqlite'\n     display_name = 'SQLite'\ndiff --git a/django/db/backends/sqlite3/operations.py b/django/db/backends/sqlite3/operations.py\nindex 1f77b3109f..0baba2436f 100644\n--- a/django/db/backends/sqlite3/operations.py\n+++ b/django/db/backends/sqlite3/operations.py\n@@ -149,11 +149,31 @@ class DatabaseOperations(BaseDatabaseOperations):\n         if params:\n             if isinstance(params, (list, tuple)):\n                 params = self._quote_params_for_last_executed_query(params)\n+                # Handle SQLite-style ? placeholders by replacing them with %s\n+                # Replace only the expected number of placeholders from left to right\n+                if '?' in sql:\n+                    # Count placeholders in the original SQL and replace only that many\n+                    param_count = sql.count('?')\n+                    if param_count == len(params):\n+                        # Safe to replace all ? with %s since counts match\n+                        return sql.replace('?', '%s') % params\n+                    else:\n+                        # Replace placeholders one at a time from left to right\n+                        result = []\n+                        param_idx = 0\n+                        for char in sql:\n+                            if char == '?' and param_idx < len(params):\n+                                result.append('%s')\n+                                param_idx += 1\n+                            else:\n+                                result.append(char)\n+                        return ''.join(result) % params\n+                return sql % params\n             else:\n                 values = tuple(params.values())\n                 values = self._quote_params_for_last_executed_query(values)\n                 params = dict(zip(params, values))\n-            return sql % params\n+                return sql % params\n         # For consistency with SQLiteCursorWrapper.execute(), just return sql\n         # when there are no parameters. See #13648 and #17158.\n         else:\n"}
{"instance_id": "sympy__sympy-13852", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/functions/special/zeta_functions.py b/sympy/functions/special/zeta_functions.py\nindex b8e2b66195..bb593c685d 100644\n--- a/sympy/functions/special/zeta_functions.py\n+++ b/sympy/functions/special/zeta_functions.py\n@@ -246,16 +246,18 @@ class polylog(Function):\n     >>> polylog(s, -1)\n     -dirichlet_eta(s)\n \n-    If :math:`s` is a negative integer, :math:`0` or :math:`1`, the\n+    If :math:`s` is a negative integer, :math:`0`, :math:`1`, or :math:`2`, the\n     polylogarithm can be expressed using elementary functions. This can be\n     done using expand_func():\n \n     >>> from sympy import expand_func\n     >>> from sympy.abc import z\n     >>> expand_func(polylog(1, z))\n-    -log(z*exp_polar(-I*pi) + 1)\n+    -log(-z + 1)\n     >>> expand_func(polylog(0, z))\n     z/(-z + 1)\n+    >>> expand_func(polylog(2, S(1)/2))\n+    pi**2/12 - log(2)**2/2\n \n     The derivative with respect to :math:`z` can be computed in closed form:\n \n@@ -288,10 +290,14 @@ def _eval_rewrite_as_lerchphi(self, s, z):\n         return z*lerchphi(z, s, 1)\n \n     def _eval_expand_func(self, **hints):\n-        from sympy import log, expand_mul, Dummy, exp_polar, I\n+        from sympy import log, expand_mul, Dummy\n         s, z = self.args\n         if s == 1:\n-            return -log(1 + exp_polar(-I*pi)*z)\n+            return -log(1 - z)\n+        if s == 2 and z == S(1)/2:\n+            return pi**2/12 - log(2)**2/2\n+        if s == 2 and z == -S(1):\n+            return -pi**2/12\n         if s.is_Integer and s <= 0:\n             u = Dummy('u')\n             start = u/(1 - u)\n"}
{"instance_id": "django__django-16950", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 3fa04b821f..dc30d79b5d 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1177,7 +1177,13 @@ class BaseInlineFormSet(BaseModelFormSet):\n                 to_field = self.instance._meta.get_field(kwargs[\"to_field\"])\n             else:\n                 to_field = self.instance._meta.pk\n-            if to_field.has_default():\n+\n+            if to_field.has_default() and (\n+                # Don't ignore a parent's auto-generated key if it's not the\n+                # parent model's pk and form data is provided.\n+                to_field.attname == self.fk.remote_field.model._meta.pk.name\n+                or not form.data\n+            ):\n                 setattr(self.instance, to_field.attname, None)\n \n         form.fields[name] = InlineForeignKeyField(self.instance, **kwargs)\n"}
{"instance_id": "sympy__sympy-22080", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/printing/precedence.py b/sympy/printing/precedence.py\nindex 47ff463faf..088029a127 100644\n--- a/sympy/printing/precedence.py\n+++ b/sympy/printing/precedence.py\n@@ -48,6 +48,7 @@\n     \"KroneckerProduct\": PRECEDENCE[\"Mul\"],\n     \"Equality\": PRECEDENCE[\"Mul\"],\n     \"Unequality\": PRECEDENCE[\"Mul\"],\n+    \"Mod\": PRECEDENCE[\"Add\"],\n }\n \n # Sometimes it's not enough to assign a fixed precedence value to a\n"}
{"instance_id": "pytest-dev__pytest-5840", "model_name_or_path": "devchain", "model_patch": "diff --git a/src/_pytest/config/__init__.py b/src/_pytest/config/__init__.py\nindex 3a0eca546..e36ca7b4f 100644\n--- a/src/_pytest/config/__init__.py\n+++ b/src/_pytest/config/__init__.py\n@@ -435,9 +435,11 @@ class PytestPluginManager(PluginManager):\n         # Use realpath to avoid loading the same conftest twice\n         # with build systems that create build directories containing\n         # symlinks to actual files.\n-        conftestpath = unique_path(conftestpath)\n+        # Use unique_path for deduplication key only (not for import operations)\n+        # because normcase on Windows lowercases paths which can break imports.\n+        conftestpath_key = unique_path(conftestpath)\n         try:\n-            return self._conftestpath2mod[conftestpath]\n+            return self._conftestpath2mod[conftestpath_key]\n         except KeyError:\n             pkgpath = conftestpath.pypkgpath()\n             if pkgpath is None:\n@@ -454,7 +456,7 @@ class PytestPluginManager(PluginManager):\n                 raise ConftestImportFailure(conftestpath, sys.exc_info())\n \n             self._conftest_plugins.add(mod)\n-            self._conftestpath2mod[conftestpath] = mod\n+            self._conftestpath2mod[conftestpath_key] = mod\n             dirpath = conftestpath.dirpath()\n             if dirpath in self._dirpath2confmods:\n                 for path, mods in self._dirpath2confmods.items():\n"}
{"instance_id": "pylint-dev__pylint-8898", "model_name_or_path": "devchain", "model_patch": "diff --git a/pylint/config/argument.py b/pylint/config/argument.py\nindex 30a5fd175..442d9c171 100644\n--- a/pylint/config/argument.py\n+++ b/pylint/config/argument.py\n@@ -111,10 +111,50 @@ def _regex_transformer(value: str) -> Pattern[str]:\n         raise argparse.ArgumentTypeError(msg) from e\n \n \n+def _split_regex_csv(value: str) -> Sequence[str]:\n+    \"\"\"Split a CSV string, but not on commas inside regex constructs.\n+\n+    In regular expressions, curly braces {} are used for quantifiers like {1,3}\n+    and square brackets [] are used for character classes. Commas inside these\n+    constructs should not be treated as delimiters.\n+    \"\"\"\n+    result: list[str] = []\n+    current: list[str] = []\n+    brace_depth = 0  # Track {} for quantifiers\n+    bracket_depth = 0  # Track [] for character classes\n+\n+    for char in value:\n+        if char == \"[\":\n+            bracket_depth += 1\n+            current.append(char)\n+        elif char == \"]\":\n+            bracket_depth = max(0, bracket_depth - 1)\n+            current.append(char)\n+        elif char == \"{\":\n+            brace_depth += 1\n+            current.append(char)\n+        elif char == \"}\":\n+            brace_depth = max(0, brace_depth - 1)\n+            current.append(char)\n+        elif char == \",\" and brace_depth == 0 and bracket_depth == 0:\n+            # Split on comma only when not inside braces or brackets\n+            result.append(\"\".join(current).strip())\n+            current = []\n+        else:\n+            current.append(char)\n+\n+    # Add the last pattern\n+    if current:\n+        result.append(\"\".join(current).strip())\n+\n+    # Filter out empty strings\n+    return [r for r in result if r]\n+\n+\n def _regexp_csv_transfomer(value: str) -> Sequence[Pattern[str]]:\n     \"\"\"Transforms a comma separated list of regular expressions.\"\"\"\n     patterns: list[Pattern[str]] = []\n-    for pattern in _csv_transformer(value):\n+    for pattern in _split_regex_csv(value):\n         patterns.append(_regex_transformer(pattern))\n     return patterns\n \n@@ -122,7 +162,7 @@ def _regexp_csv_transfomer(value: str) -> Sequence[Pattern[str]]:\n def _regexp_paths_csv_transfomer(value: str) -> Sequence[Pattern[str]]:\n     \"\"\"Transforms a comma separated list of regular expressions paths.\"\"\"\n     patterns: list[Pattern[str]] = []\n-    for pattern in _csv_transformer(value):\n+    for pattern in _split_regex_csv(value):\n         patterns.append(\n             re.compile(\n                 str(pathlib.PureWindowsPath(pattern)).replace(\"\\\\\", \"\\\\\\\\\")\n"}
{"instance_id": "django__django-11400", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/contrib/admin/filters.py b/django/contrib/admin/filters.py\nindex d65e01d5e2..a3dd427999 100644\n--- a/django/contrib/admin/filters.py\n+++ b/django/contrib/admin/filters.py\n@@ -194,10 +194,13 @@ class RelatedFieldListFilter(FieldListFilter):\n         return [self.lookup_kwarg, self.lookup_kwarg_isnull]\n \n     def field_choices(self, field, request, model_admin):\n+        other_model = get_model_from_relation(field)\n         ordering = ()\n         related_admin = model_admin.admin_site._registry.get(field.remote_field.model)\n         if related_admin is not None:\n             ordering = related_admin.get_ordering(request)\n+        if not ordering:\n+            ordering = other_model._meta.ordering\n         return field.get_choices(include_blank=False, ordering=ordering)\n \n     def choices(self, changelist):\n@@ -418,5 +421,12 @@ FieldListFilter.register(lambda f: True, AllValuesFieldListFilter)\n \n class RelatedOnlyFieldListFilter(RelatedFieldListFilter):\n     def field_choices(self, field, request, model_admin):\n+        other_model = get_model_from_relation(field)\n+        ordering = ()\n+        related_admin = model_admin.admin_site._registry.get(field.remote_field.model)\n+        if related_admin is not None:\n+            ordering = related_admin.get_ordering(request)\n+        if not ordering:\n+            ordering = other_model._meta.ordering\n         pk_qs = model_admin.get_queryset(request).distinct().values_list('%s__pk' % self.field_path, flat=True)\n-        return field.get_choices(include_blank=False, limit_choices_to={'pk__in': pk_qs})\n+        return field.get_choices(include_blank=False, ordering=ordering, limit_choices_to={'pk__in': pk_qs})\n"}
{"instance_id": "astropy__astropy-13398", "model_name_or_path": "devchain", "model_patch": "diff --git a/astropy/coordinates/builtin_frames/__init__.py b/astropy/coordinates/builtin_frames/__init__.py\nindex 6fd688c285..17b524478e 100644\n--- a/astropy/coordinates/builtin_frames/__init__.py\n+++ b/astropy/coordinates/builtin_frames/__init__.py\n@@ -48,6 +48,7 @@ from . import supergalactic_transforms\n from . import icrs_cirs_transforms\n from . import cirs_observed_transforms\n from . import icrs_observed_transforms\n+from . import itrs_observed_transforms\n from . import intermediate_rotation_transforms\n from . import ecliptic_transforms\n \ndiff --git a/astropy/coordinates/builtin_frames/itrs_observed_transforms.py b/astropy/coordinates/builtin_frames/itrs_observed_transforms.py\nnew file mode 100644\nindex 0000000000..e357b68472\n--- /dev/null\n+++ b/astropy/coordinates/builtin_frames/itrs_observed_transforms.py\n@@ -0,0 +1,118 @@\n+# Licensed under a 3-clause BSD style license - see LICENSE.rst\n+\"\"\"\n+Contains the transformation functions for getting to \"observed\" systems from ITRS.\n+This provides a direct approach to ITRS to Observed transformations that stays\n+within the ITRS, treating ITRS positions as time invariant.\n+\"\"\"\n+\n+import numpy as np\n+\n+from astropy import units as u\n+from astropy.coordinates.baseframe import frame_transform_graph\n+from astropy.coordinates.transformations import FunctionTransformWithFiniteDifference\n+from astropy.coordinates.matrix_utilities import rotation_matrix, matrix_transpose\n+\n+from .itrs import ITRS\n+from .altaz import AltAz\n+from .hadec import HADec\n+from .utils import PIOVER2\n+\n+\n+def itrs_to_observed_mat(observed_frame):\n+    \"\"\"\n+    Create the transformation matrix from ITRS to an observed frame (AltAz or HADec).\n+\n+    Parameters\n+    ----------\n+    observed_frame : AltAz or HADec\n+        The target frame for the transformation.\n+\n+    Returns\n+    -------\n+    matrix : ndarray\n+        The 3x3 transformation matrix.\n+    \"\"\"\n+    lon, lat, height = observed_frame.location.to_geodetic('WGS84')\n+    elong = lon.to_value(u.radian)\n+\n+    if isinstance(observed_frame, AltAz):\n+        # form ITRS to AltAz matrix\n+        elat = lat.to_value(u.radian)\n+        # AltAz frame is left handed\n+        minus_x = np.eye(3)\n+        minus_x[0][0] = -1.0\n+        mat = (minus_x\n+               @ rotation_matrix(PIOVER2 - elat, 'y', unit=u.radian)\n+               @ rotation_matrix(elong, 'z', unit=u.radian))\n+\n+    else:\n+        # form ITRS to HADec matrix\n+        # HADec frame is left handed\n+        minus_y = np.eye(3)\n+        minus_y[1][1] = -1.0\n+        mat = (minus_y\n+               @ rotation_matrix(elong, 'z', unit=u.radian))\n+    return mat\n+\n+\n+@frame_transform_graph.transform(FunctionTransformWithFiniteDifference, ITRS, AltAz)\n+@frame_transform_graph.transform(FunctionTransformWithFiniteDifference, ITRS, HADec)\n+def itrs_to_observed(itrs_coo, observed_frame):\n+    \"\"\"\n+    Transform from ITRS to an observed frame (AltAz or HADec).\n+\n+    This transform treats ITRS coordinates as time invariant, avoiding the\n+    problematic ITRS->ITRS transform that references coordinates to the SSB.\n+    The obstime of the output frame is adopted directly.\n+\n+    Parameters\n+    ----------\n+    itrs_coo : ITRS\n+        The ITRS coordinate to transform.\n+    observed_frame : AltAz or HADec\n+        The target frame.\n+\n+    Returns\n+    -------\n+    observed_coord : AltAz or HADec\n+        The transformed coordinate in the observed frame.\n+    \"\"\"\n+    # Trying to synchronize the obstimes here makes no sense. In fact,\n+    # it's a real gotcha as doing an ITRS->ITRS transform references\n+    # ITRS coordinates, which should be tied to the Earth, to the SSB.\n+    # Instead, we treat ITRS coordinates as time invariant here.\n+\n+    # form the Topocentric ITRS position\n+    topocentric_itrs_repr = (itrs_coo.cartesian\n+                             - observed_frame.location.get_itrs().cartesian)\n+    rep = topocentric_itrs_repr.transform(itrs_to_observed_mat(observed_frame))\n+    return observed_frame.realize_frame(rep)\n+\n+\n+@frame_transform_graph.transform(FunctionTransformWithFiniteDifference, AltAz, ITRS)\n+@frame_transform_graph.transform(FunctionTransformWithFiniteDifference, HADec, ITRS)\n+def observed_to_itrs(observed_coo, itrs_frame):\n+    \"\"\"\n+    Transform from an observed frame (AltAz or HADec) to ITRS.\n+\n+    This transform treats ITRS coordinates as time invariant, avoiding the\n+    problematic ITRS->ITRS transform that references coordinates to the SSB.\n+\n+    Parameters\n+    ----------\n+    observed_coo : AltAz or HADec\n+        The observed coordinate to transform.\n+    itrs_frame : ITRS\n+        The target ITRS frame.\n+\n+    Returns\n+    -------\n+    itrs_coord : ITRS\n+        The transformed coordinate in ITRS.\n+    \"\"\"\n+    # form the Topocentric ITRS position\n+    topocentric_itrs_repr = observed_coo.cartesian.transform(matrix_transpose(\n+                            itrs_to_observed_mat(observed_coo)))\n+    # form the Geocentric ITRS position\n+    rep = topocentric_itrs_repr + observed_coo.location.get_itrs().cartesian\n+    return itrs_frame.realize_frame(rep)\n"}
{"instance_id": "django__django-11206", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/utils/numberformat.py b/django/utils/numberformat.py\nindex 88b35fc435..fb8c3fa3b3 100644\n--- a/django/utils/numberformat.py\n+++ b/django/utils/numberformat.py\n@@ -30,7 +30,12 @@ def format(number, decimal_sep, decimal_pos=None, grouping=0, thousand_sep='',\n         # Format values with more than 200 digits (an arbitrary cutoff) using\n         # scientific notation to avoid high memory usage in {:f}'.format().\n         _, digits, exponent = number.as_tuple()\n-        if abs(exponent) + len(digits) > 200:\n+        # When decimal_pos is given, format the number as '0' with the\n+        # specified number of decimal places if it's smaller than what\n+        # decimal_pos can represent.\n+        if decimal_pos is not None and exponent + len(digits) <= -decimal_pos:\n+            str_number = '0'\n+        elif abs(exponent) + len(digits) > 200:\n             number = '{:e}'.format(number)\n             coefficient, exponent = number.split('e')\n             # Format the coefficient.\ndiff --git a/run_numberformat_tests.py b/run_numberformat_tests.py\nnew file mode 100644\nindex 0000000000..6e66f5b2c3\n--- /dev/null\n+++ b/run_numberformat_tests.py\n@@ -0,0 +1,35 @@\n+import os\n+import sys\n+import django\n+from django.conf import settings\n+\n+# Configure Django settings\n+settings.configure(\n+    DEBUG=True,\n+    SECRET_KEY='test-secret-key-for-numberformat-tests',\n+    USE_L10N=False,\n+    USE_THOUSAND_SEPARATOR=False,\n+    DATABASES={\n+        'default': {\n+            'ENGINE': 'django.db.backends.sqlite3',\n+            'NAME': ':memory:',\n+        }\n+    },\n+    INSTALLED_APPS=[\n+        'django.contrib.contenttypes',\n+        'django.contrib.auth',\n+    ],\n+)\n+django.setup()\n+\n+# Now run the tests\n+import unittest\n+from tests.utils_tests import test_numberformat\n+\n+loader = unittest.TestLoader()\n+suite = loader.loadTestsFromModule(test_numberformat)\n+runner = unittest.TextTestRunner(verbosity=2)\n+result = runner.run(suite)\n+\n+# Exit with appropriate code\n+sys.exit(0 if result.wasSuccessful() else 1)\ndiff --git a/verify_bug_fix.py b/verify_bug_fix.py\nnew file mode 100644\nindex 0000000000..ddecc67a1d\n--- /dev/null\n+++ b/verify_bug_fix.py\n@@ -0,0 +1,31 @@\n+import sys\n+import django\n+from django.conf import settings\n+from decimal import Decimal\n+\n+settings.configure(\n+    DEBUG=True,\n+    SECRET_KEY='test',\n+    USE_L10N=False,\n+    USE_THOUSAND_SEPARATOR=False,\n+)\n+django.setup()\n+\n+from django.utils.numberformat import format as nformat\n+\n+print('=== Bug Fix Verification ===')\n+print()\n+print('Test cases from bug report:')\n+print('nformat(Decimal(\"1e-199\"), \".\", decimal_pos=2):', nformat(Decimal('1e-199'), '.', decimal_pos=2))\n+print('nformat(Decimal(\"1e-200\"), \".\", decimal_pos=2):', nformat(Decimal('1e-200'), '.', decimal_pos=2))\n+print()\n+print('Expected behavior: Both should return \"0.00\"')\n+print()\n+\n+# Check the specific failing test case\n+val = '0.' + '0' * 299 + '1234'\n+print(f'Failing test case: Decimal(\"{val[:20]}...{val[-10:]}\") with decimal_pos=3')\n+result = nformat(Decimal(val), '.', decimal_pos=3)\n+print(f'Result: {result}')\n+print(f'Expected by test: \"1.234e-300\" (old buggy behavior)')\n+print(f'According to bug report: should be \"0.000\" (fixed behavior)')\n"}
{"instance_id": "django__django-11433", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5edbbd376f..5dd74d9390 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -8,6 +8,7 @@ from itertools import chain\n from django.core.exceptions import (\n     NON_FIELD_ERRORS, FieldError, ImproperlyConfigured, ValidationError,\n )\n+from django.core.validators import EMPTY_VALUES\n from django.forms.fields import ChoiceField, Field\n from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n@@ -46,10 +47,12 @@ def construct_instance(form, instance, fields=None, exclude=None):\n             continue\n         if exclude and f.name in exclude:\n             continue\n-        # Leave defaults for fields that aren't in POST data, except for\n-        # checkbox inputs because they don't appear in POST data if not checked.\n+        # If the field has a default and was omitted from POST data, only skip\n+        # if the cleaned_data value is empty. This allows users to override\n+        # defaults by explicitly setting a value in cleaned_data via form.clean().\n         if (f.has_default() and\n-                form[f.name].field.widget.value_omitted_from_data(form.data, form.files, form.add_prefix(f.name))):\n+                form[f.name].field.widget.value_omitted_from_data(form.data, form.files, form.add_prefix(f.name)) and\n+                cleaned_data[f.name] in EMPTY_VALUES):\n             continue\n         # Defer saving file-type fields until after the other fields, so a\n         # callable upload_to can use the values from other fields.\n"}
{"instance_id": "scikit-learn__scikit-learn-26194", "model_name_or_path": "devchain", "model_patch": "diff --git a/sklearn/metrics/_ranking.py b/sklearn/metrics/_ranking.py\nindex 0cdead923..46971298d 100644\n--- a/sklearn/metrics/_ranking.py\n+++ b/sklearn/metrics/_ranking.py\n@@ -1019,7 +1019,8 @@ def roc_curve(\n     thresholds : ndarray of shape = (n_thresholds,)\n         Decreasing thresholds on the decision function used to compute\n         fpr and tpr. `thresholds[0]` represents no instances being predicted\n-        and is arbitrarily set to `max(y_score) + 1`.\n+        and is set to `np.inf` for probability estimates (when `max(y_score) <= 1`)\n+        or `max(y_score) + 1` otherwise.\n \n     See Also\n     --------\n@@ -1056,7 +1057,7 @@ def roc_curve(\n     >>> tpr\n     array([0. , 0.5, 0.5, 1. , 1. ])\n     >>> thresholds\n-    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\n+    array([inf, 0.8 , 0.4 , 0.35, 0.1 ])\n     \"\"\"\n     fps, tps, thresholds = _binary_clf_curve(\n         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight\n@@ -1083,7 +1084,13 @@ def roc_curve(\n     # to make sure that the curve starts at (0, 0)\n     tps = np.r_[0, tps]\n     fps = np.r_[0, fps]\n-    thresholds = np.r_[thresholds[0] + 1, thresholds]\n+    # For probability estimates (where all scores are in [0, 1]),\n+    # use np.inf as the extra threshold to avoid returning thresholds > 1.\n+    # The + 1 rule is appropriate for decision functions but not for probabilities.\n+    if thresholds[0] <= 1:\n+        thresholds = np.r_[np.inf, thresholds]\n+    else:\n+        thresholds = np.r_[thresholds[0] + 1, thresholds]\n \n     if fps[-1] <= 0:\n         warnings.warn(\n"}
{"instance_id": "astropy__astropy-14182", "model_name_or_path": "devchain", "model_patch": "diff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..93b5c14e36 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -57,10 +57,58 @@ class RST(FixedWidth):\n     data_class = SimpleRSTData\n     header_class = SimpleRSTHeader\n \n-    def __init__(self):\n-        super().__init__(delimiter_pad=None, bookend=False)\n+    def __init__(self, header_rows=None):\n+        super().__init__(delimiter_pad=None, bookend=False, header_rows=header_rows)\n \n     def write(self, lines):\n         lines = super().write(lines)\n-        lines = [lines[1]] + lines + [lines[1]]\n-        return lines\n+        # The parent class (FixedWidthData.write()) produces:\n+        # - 0 or more header rows (if header_rows is set)\n+        # - optionally a separator line (if position_line is set)\n+        # - data rows\n+        #\n+        # For RST, we need to add the separator line at the start and end.\n+        # The separator should be based on column widths.\n+\n+        # Get the number of header rows (default to [\"name\"] if not set)\n+        # Note: header_rows is set on self.header.header_rows, not self\n+        header_rows = getattr(self.header, \"header_rows\", [\"name\"])\n+        num_header_rows = len(header_rows)\n+\n+        # Determine the index of the separator line\n+        # If position_line is set in header, a separator will be added after headers\n+        if self.header.position_line is not None:\n+            # Separator is at index num_header_rows\n+            separator_idx = num_header_rows\n+            separator = lines[separator_idx]\n+        else:\n+            # No separator line in output, create one from the first data row\n+            # Find the first data row (after all header rows)\n+            first_data_idx = num_header_rows\n+            if first_data_idx < len(lines):\n+                # Use the first data row to determine column widths\n+                first_data_row = lines[first_data_idx]\n+                # Calculate column widths from the data row\n+                # The data row has format: \"val1 val2 val3\" (space-separated)\n+                # We need to reconstruct the widths\n+                vals = first_data_row.split()\n+                widths = [len(v) for v in vals]\n+                # Create separator using the position_char\n+                separator = self.data.splitter.join(\n+                    [self.header.position_char * w for w in widths], widths\n+                )\n+            else:\n+                # Fallback: shouldn't happen with valid data\n+                separator = \"\"\n+\n+        # Reconstruct the lines for RST format:\n+        # separator, header rows, separator, data rows, separator\n+        result = [separator]\n+        # Add header rows (before the original separator, if present)\n+        result.extend(lines[:separator_idx])\n+        result.append(separator)\n+        # Add data rows (after the original separator)\n+        result.extend(lines[separator_idx + 1 :])\n+        result.append(separator)\n+\n+        return result\n"}
{"instance_id": "sphinx-doc__sphinx-7985", "model_name_or_path": "devchain", "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex dd5317087..577737f32 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -213,7 +213,8 @@ class CheckExternalLinksBuilder(Builder):\n             if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'ftp:')):\n                 return 'unchecked', '', 0\n             elif not uri.startswith(('http:', 'https:')):\n-                return 'local', '', 0\n+                # Check if this is a valid internal reference\n+                return self.check_internal_uri(uri, docname)\n             elif uri in self.good:\n                 return 'working', 'old', 0\n             elif uri in self.broken:\n@@ -337,6 +338,56 @@ class CheckExternalLinksBuilder(Builder):\n         if self.broken:\n             self.app.statuscode = 1\n \n+    def check_internal_uri(self, uri: str, docname: str) -> Tuple[str, str, int]:\n+        \"\"\"Check if an internal URI reference is valid.\n+\n+        Returns tuple of (status, info, code) where:\n+        - status: 'working' if reference exists, 'broken' if not, 'local' if not checkable\n+        - info: error message if broken\n+        - code: 0\n+        \"\"\"\n+        # Check if the URI is a named reference in the standard domain\n+        try:\n+            std_domain = self.env.get_domain('std')\n+\n+            # Check in named labels (explicit references like .. _name: target)\n+            if uri in std_domain.labels:\n+                return 'working', '', 0\n+\n+            # Check in anonymous labels (implicit references)\n+            if uri in std_domain.anonlabels:\n+                return 'working', '', 0\n+        except Exception:\n+            # If we can't check the reference, treat it as local (unchecked)\n+            pass\n+\n+        # Check if the URI is a valid document reference\n+        # Strip .html or . extension if present\n+        doc_ref = uri\n+        if doc_ref.endswith('.html'):\n+            doc_ref = doc_ref[:-5]\n+        elif '.' in doc_ref and '.' not in doc_ref.replace('.', '', doc_ref.count('.') - 1):\n+            # Handle other extensions by removing the last extension\n+            doc_ref = path.splitext(doc_ref)[0]\n+\n+        # Split off anchor if present\n+        if '#' in doc_ref:\n+            doc_ref, anchor = doc_ref.split('#', 1)\n+        else:\n+            anchor = None\n+\n+        # Check if the document exists\n+        if doc_ref in self.env.found_docs:\n+            if anchor:\n+                # If there's an anchor, we can't easily validate it without\n+                # parsing the document's TOC, so treat it as working for now\n+                # (the document exists, even if we can't verify the anchor)\n+                return 'working', '', 0\n+            return 'working', '', 0\n+\n+        # Not found in labels or documents - this is a broken internal link\n+        return 'broken', __(\"Broken link to internal target: %s\") % uri, 0\n+\n     def write_entry(self, what: str, docname: str, filename: str, line: int,\n                     uri: str) -> None:\n         with open(path.join(self.outdir, 'output.txt'), 'a') as output:\n"}
{"instance_id": "django__django-14170", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/db/models/functions/datetime.py b/django/db/models/functions/datetime.py\nindex 90e6f41be0..bbe9fa8c79 100644\n--- a/django/db/models/functions/datetime.py\n+++ b/django/db/models/functions/datetime.py\n@@ -164,12 +164,6 @@ ExtractYear.register_lookup(YearGte)\n ExtractYear.register_lookup(YearLt)\n ExtractYear.register_lookup(YearLte)\n \n-ExtractIsoYear.register_lookup(YearExact)\n-ExtractIsoYear.register_lookup(YearGt)\n-ExtractIsoYear.register_lookup(YearGte)\n-ExtractIsoYear.register_lookup(YearLt)\n-ExtractIsoYear.register_lookup(YearLte)\n-\n \n class Now(Func):\n     template = 'CURRENT_TIMESTAMP'\n"}
{"instance_id": "sympy__sympy-13878", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/stats/crv_types.py b/sympy/stats/crv_types.py\nindex fff7da80ae..394e1e6c91 100644\n--- a/sympy/stats/crv_types.py\n+++ b/sympy/stats/crv_types.py\n@@ -47,7 +47,7 @@\n \n from sympy import (log, sqrt, pi, S, Dummy, Interval, sympify, gamma,\n                    Piecewise, And, Eq, binomial, factorial, Sum, floor, Abs,\n-                   Lambda, Basic, lowergamma, erf, erfc, I)\n+                   Lambda, Basic, lowergamma, uppergamma, erf, erfc, I, asin)\n from sympy import beta as beta_fn\n from sympy import cos, exp, besseli\n from sympy.stats.crv import (SingleContinuousPSpace, SingleContinuousDistribution,\n@@ -150,9 +150,21 @@ def rv(symbol, cls, args):\n class ArcsinDistribution(SingleContinuousDistribution):\n     _argnames = ('a', 'b')\n \n+    @property\n+    def set(self):\n+        return Interval(self.a, self.b)\n+\n     def pdf(self, x):\n         return 1/(pi*sqrt((x - self.a)*(self.b - x)))\n \n+    def _cdf(self, x):\n+        a, b = self.a, self.b\n+        return Piecewise(\n+            (S.Zero, x < a),\n+            (S(2)/pi*asin(sqrt((x - a)/(b - a))), x <= b),\n+            (S.One, True)\n+        )\n+\n def Arcsin(name, a=0, b=1):\n     r\"\"\"\n     Create a Continuous Random Variable with an arcsin distribution.\n@@ -666,10 +678,21 @@ def ChiSquared(name, k):\n class DagumDistribution(SingleContinuousDistribution):\n     _argnames = ('p', 'a', 'b')\n \n+    @property\n+    def set(self):\n+        return Interval(0, oo)\n+\n     def pdf(self, x):\n         p, a, b = self.p, self.a, self.b\n         return a*p/x*((x/b)**(a*p)/(((x/b)**a + 1)**(p + 1)))\n \n+    def _cdf(self, x):\n+        p, a, b = self.p, self.a, self.b\n+        return Piecewise(\n+            ((1 + (x/b)**(-a))**(-p), x > 0),\n+            (S.Zero, True)\n+        )\n+\n \n def Dagum(name, p, a, b):\n     r\"\"\"\n@@ -1042,6 +1065,13 @@ def pdf(self, x):\n         a, s, m = self.a, self.s, self.m\n         return a/s * ((x-m)/s)**(-1-a) * exp(-((x-m)/s)**(-a))\n \n+    def _cdf(self, x):\n+        a, s, m = self.a, self.s, self.m\n+        return Piecewise(\n+            (exp(-((x-m)/s)**(-a)), x > m),\n+            (S.Zero, True)\n+        )\n+\n def Frechet(name, a, s=1, m=0):\n     r\"\"\"\n     Create a continuous random variable with a Frechet distribution.\n@@ -1111,6 +1141,13 @@ def pdf(self, x):\n     def sample(self):\n         return random.gammavariate(self.k, self.theta)\n \n+    def _cdf(self, x):\n+        k, theta = self.k, self.theta\n+        return Piecewise(\n+            (lowergamma(k, x/theta)/gamma(k), x >= 0),\n+            (S.Zero, True)\n+        )\n+\n \n def Gamma(name, k, theta):\n     r\"\"\"\n@@ -1200,6 +1237,13 @@ def pdf(self, x):\n         a, b = self.a, self.b\n         return b**a/gamma(a) * x**(-a-1) * exp(-b/x)\n \n+    def _cdf(self, x):\n+        a, b = self.a, self.b\n+        return Piecewise(\n+            (uppergamma(a, b/x)/gamma(a), x > 0),\n+            (S.Zero, True)\n+        )\n+\n def GammaInverse(name, a, b):\n     r\"\"\"\n     Create a continuous random variable with an inverse Gamma distribution.\n@@ -1374,7 +1418,7 @@ def Gompertz(name, b, eta):\n class KumaraswamyDistribution(SingleContinuousDistribution):\n     _argnames = ('a', 'b')\n \n-    set = Interval(0, oo)\n+    set = Interval(0, 1)\n \n     @staticmethod\n     def check(a, b):\n@@ -1385,6 +1429,14 @@ def pdf(self, x):\n         a, b = self.a, self.b\n         return a * b * x**(a-1) * (1-x**a)**(b-1)\n \n+    def _cdf(self, x):\n+        a, b = self.a, self.b\n+        return Piecewise(\n+            (S.One - (S.One - x**a)**b, And(x >= 0, x <= 1)),\n+            (S.Zero, x < 0),\n+            (S.One, True)\n+        )\n+\n def Kumaraswamy(name, a, b):\n     r\"\"\"\n     Create a Continuous Random Variable with a Kumaraswamy distribution.\n@@ -1445,6 +1497,13 @@ def pdf(self, x):\n         mu, b = self.mu, self.b\n         return 1/(2*b)*exp(-Abs(x - mu)/b)\n \n+    def _cdf(self, x):\n+        mu, b = self.mu, self.b\n+        return Piecewise(\n+            (S.One - S.Half*exp(-(x - mu)/b), x > mu),\n+            (S.Half*exp((x - mu)/b), True)\n+        )\n+\n \n def Laplace(name, mu, b):\n     r\"\"\"\n@@ -1501,6 +1560,10 @@ def pdf(self, x):\n         mu, s = self.mu, self.s\n         return exp(-(x - mu)/s)/(s*(1 + exp(-(x - mu)/s))**2)\n \n+    def _cdf(self, x):\n+        mu, s = self.mu, self.s\n+        return S.One/(S.One + exp(-(x - mu)/s))\n+\n \n def Logistic(name, mu, s):\n     r\"\"\"\n@@ -1711,6 +1774,13 @@ def pdf(self, x):\n         mu, omega = self.mu, self.omega\n         return 2*mu**mu/(gamma(mu)*omega**mu)*x**(2*mu - 1)*exp(-mu/omega*x**2)\n \n+    def _cdf(self, x):\n+        mu, omega = self.mu, self.omega\n+        return Piecewise(\n+            (lowergamma(mu, mu*x**2/omega)/gamma(mu), x >= 0),\n+            (S.Zero, True)\n+        )\n+\n \n def Nakagami(name, mu, omega):\n     r\"\"\"\n@@ -2227,6 +2297,14 @@ def pdf(self, x):\n         nu = self.nu\n         return 1/(sqrt(nu)*beta_fn(S(1)/2, nu/2))*(1 + x**2/nu)**(-(nu + 1)/2)\n \n+    def _cdf(self, x):\n+        from sympy.functions.special.hyper import hyper\n+        nu = self.nu\n+        return Piecewise(\n+            (S.Half + x*gamma((nu + 1)/2)*hyper((S.Half, (nu + 1)/2),\n+                (S(3)/2, ), -x**2/nu)/(sqrt(pi*nu)*gamma(nu/2)), True),\n+        )\n+\n \n def StudentT(name, nu):\n     r\"\"\"\n@@ -2554,6 +2632,15 @@ def pdf(self, x):\n         return 1/factorial(\n             n - 1)*Sum((-1)**k*binomial(n, k)*(x - k)**(n - 1), (k, 0, floor(x)))\n \n+    def _cdf(self, x):\n+        n = self.n\n+        k = Dummy(\"k\")\n+        return Piecewise(\n+            (S.One/factorial(n)*Sum((-1)**k*binomial(n, k)*(x - k)**n, (k, 0, floor(x))), And(x >= 0, x <= n)),\n+            (S.Zero, x < 0),\n+            (S.One, True)\n+        )\n+\n \n \n def UniformSum(name, n):\n"}
{"instance_id": "sphinx-doc__sphinx-10435", "model_name_or_path": "devchain", "model_patch": "diff --git a/sphinx/writers/latex.py b/sphinx/writers/latex.py\nindex e0c7d56f8..22c4538a3 100644\n--- a/sphinx/writers/latex.py\n+++ b/sphinx/writers/latex.py\n@@ -1710,11 +1710,13 @@ class LaTeXTranslator(SphinxTranslator):\n         # TODO: Use nowrap option once LaTeX formatter supports it\n         # https://github.com/pygments/pygments/pull/1343\n         hlcode = hlcode.replace(r'\\begin{Verbatim}[commandchars=\\\\\\{\\}]',\n-                                r'\\sphinxcode{\\sphinxupquote{')\n+                                r'\\sphinxcode{\\sphinxupquote{%')\n         # get consistent trailer\n         hlcode = hlcode.rstrip()[:-14]  # strip \\end{Verbatim}\n+        # suppress whitespace at end of inline code by appending % to last line\n+        hlcode = hlcode.rstrip() + '%'\n         self.body.append(hlcode)\n-        self.body.append('}}')\n+        self.body.append(CR + '}}')\n         raise nodes.SkipNode\n \n     def depart_literal(self, node: Element) -> None:\n"}
{"instance_id": "astropy__astropy-13033", "model_name_or_path": "devchain", "model_patch": "diff --git a/astropy/timeseries/core.py b/astropy/timeseries/core.py\nindex c279f35f87..689273ae24 100644\n--- a/astropy/timeseries/core.py\n+++ b/astropy/timeseries/core.py\n@@ -74,12 +74,19 @@ class BaseTimeSeries(QTable):\n                                  \"as the first column{} but time series has no columns\"\n                                  .format(self.__class__.__name__, required_columns[0], plural))\n \n-            elif self.colnames[:len(required_columns)] != required_columns:\n-\n+            # Check if the first column is wrong - this gives the most specific error\n+            if len(self.colnames) > 0 and self.colnames[0] != required_columns[0]:\n                 raise ValueError(\"{} object is invalid - expected '{}' \"\n                                  \"as the first column{} but found '{}'\"\n                                  .format(self.__class__.__name__, required_columns[0], plural, self.colnames[0]))\n \n+            # Check if any other required columns (beyond the first) are missing\n+            missing_columns = [col for col in required_columns if col not in self.colnames]\n+            if missing_columns:\n+                missing_str = ', '.join(repr(col) for col in missing_columns)\n+                raise ValueError(\"{} object is invalid - missing required column{}: {}\"\n+                                 .format(self.__class__.__name__, 's' if len(missing_columns) > 1 else '', missing_str))\n+\n             if (self._required_columns_relax\n                     and self._required_columns == self.colnames[:len(self._required_columns)]):\n                 self._required_columns_relax = False\n"}
{"instance_id": "sympy__sympy-19495", "model_name_or_path": "devchain", "model_patch": "diff --git a/sympy/sets/conditionset.py b/sympy/sets/conditionset.py\nindex 118eda6f77..c8c70929d9 100644\n--- a/sympy/sets/conditionset.py\n+++ b/sympy/sets/conditionset.py\n@@ -243,7 +243,7 @@ def _eval_subs(self, old, new):\n         cond = self.condition.subs(old, new)\n         base = self.base_set.subs(old, new)\n         if cond is S.true:\n-            return ConditionSet(new, Contains(new, base), base)\n+            return base\n         return self.func(self.sym, cond, base)\n \n     def dummy_eq(self, other, symbol=None):\n"}
{"instance_id": "django__django-16642", "model_name_or_path": "devchain", "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex f62dec8ce9..17e630be37 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -612,6 +612,8 @@ class FileResponse(StreamingHttpResponse):\n                     \"bzip2\": \"application/x-bzip\",\n                     \"gzip\": \"application/gzip\",\n                     \"xz\": \"application/x-xz\",\n+                    \"compress\": \"application/x-compress\",\n+                    \"br\": \"application/x-brotli\",\n                 }.get(encoding, content_type)\n                 self.headers[\"Content-Type\"] = (\n                     content_type or \"application/octet-stream\"\n"}
